---
title: "Linking"
lang: de
date: "`r format(Sys.time(), '%d %B, %Y')`"
format: 
  letterbox-revealjs:
    embed-resources: true
    theme: ../../styles.scss
code-link: true
code-line-numbers: false
execute:
  echo: true
highlight-style: ../../dark.theme
callout-appearance: simple
---

```{r}
library(tidyverse)
source(here::here("R", "plot_functions.R"))
source(here::here("R", "irt_formulas.R"))

```


# Höher parametrisierte IRT Modelle

## Wiederholung 

### 1PL Modell

$$
logit(P(X_{pi}=1)) = \theta_p - \beta_i
$$
- Logit: Transformation unseres linearen Terms, damit die Werte zwischen 0 und 1 liegen. 
- Inverse der logit ist die Logistic function.
- [This is my highlight.]{.highlight}

$$
P(X_{pi}=1) = logistic(\theta_p - \beta_i)
$$

## 1PL exponentielle Form des logistischen Modells

https://www.geo.fu-berlin.de/en/v/soga-r/Basics-of-statistics/Logistic-Regression/The-Logit-Function/index.html
$$
P(X_{pi}=1) = \frac{exp(\theta_p - \beta_i)}{1 + exp(\theta_p - \beta_i)}
$$
$$
P(X_{pi}=1) = \frac{e^{\theta_p - \beta_i}}{1 + e^{\theta_p - \beta_i}}
$$

$$
P(X_{pi}=1) = \frac{1}{1 + e^{-\theta_p + \beta_i}}
$$

## 3PL
Wäre eigentlich schöner in der logit-variante. Was passiert dort aber mit gamma?

$$
P(X_{pi}=1) = \gamma_i + (1-\gamma_i)\frac{exp(\alpha_i(\theta_p - \beta_i)))}{1 + exp(\alpha_i(\theta_p - \beta_i))}
$$
- $\beta_i$: easiness
- $\alpha_i$: discrimination/factor loading/slope
- $\gamma_i$ : guessing probability
 - Kann entweder geschätzt oder gesetzt werden (z.B. bei 4 Antwortmöglichkeiten: $\gamma_i = 1/4 = 0.25$)
- Wenn die Lösungswahrscheinlichkeit auf der rehcten Seite sehr gering ist, ist sie immer noch mind. $\gamma_i$

- Dann werden nacheinander einige der Parameter auf 0 oder 1 gesetzt, sodass ihr Einfluss weggeht. 
- Bürkner Paper


## Shiny App for demonstration?
Auf alle Fälle zeigen, wie es aussieht!

## 2PL

$\gamma_i = 0$

$$
P(X_{pi}=1) = \color{red}{0} + (1-\color{red}{0})\frac{exp(\alpha_i(\theta_p - \beta_i)))}{1 + exp(\alpha_i(\theta_p - \beta_i))}
$$

## 1PL
$\alpha_i = 1$

$$
P(X_{pi}=1) = 0 + (1-0)\frac{exp(\color{red}{1}(\theta_p - \beta_i)))}{1 + exp(\color{red}{1}(\theta_p - \beta_i))}
$$


## Beispielaufgabe
nie -- manchmal -- häufig


# 
<section style="text-align: center;">

[Wie?]{.r-fit-text .highlight}

</section>

# Partial Credit

## 

Grundidee: Den einzelnen Antwortkategorien wird eine [eigene Schwierigkeit]{.highlight} zugeordnet. Dadurch können wir die [Antwortwahrscheinlichkeit]{.highlight} in einer bestimmten [Kategorie]{.highlight} berechnen. 


## Anwendungsbereich
Ordinale Daten (geordnete Antwortkategorien), z.B.:
  - Likert-Skalen
  - Items, die auch mit Teilpunkten bewertet werden können (z.B. Mathe)


## Darstellung

```{r}
#| echo: false

plot_pcm(delta = c(-0.29, 0.95))
```



## Formel

$$
\pi_{pix}= P(X_{pi}=x|\theta_p, \beta_{ik})= \frac{exp[\sum^x_{j=0}(\theta_p-\beta_{ij})]}{1+exp[\sum^k_{j=0}(\theta_p-\beta_{ij})]}
$$
::: aside
- Person $p$
- Item $i$
- Personenscore $x$
:::


## Partial Credit Model
$$
\pi_{pix}= \color{red}{P(X_{pi}=x|\theta_p, \beta_{ik})}= \frac{exp[\sum^x_{j=0}(\theta_p-\beta_{ij})]}{1+exp[\sum^k_{j=0}(\theta_p-\beta_{ij})]}
$$


## Partial Credit Model

$$
\pi_{pix}= P(X_{pi}=x|\theta_p, \beta_{ik})= \frac{exp[\sum^x_{j=0}\color{red}{(\theta_p-\beta_{ij})}]}{1+exp[\sum^k_{j=0}(\theta_p-\beta_{ij})]}
$$


Wichtig:$/beta_{i\color{red}{j}}$ ist jetzt der [Schwellenparameter]{.highlight} der Kategorie $j$ des Items $i$.






## Raw score curve
Das summiert dann über alle Items auf. Vielleicht später noch zeigen. 
```{r}
calc_pcm <- function(theta, delta){
  
  m <- length(delta)  # Anzahl der Kategorien (m + 1 Kategorien)
  probs <- numeric(m + 1)  # Speicher für die Wahrscheinlichkeiten
  
  # Berechnung des Nenners (dieser ist für alle x gleich)
  nenner <- sum(sapply(0:m, function(r){
    exp(sum(sapply(0:r, function(j){
      if(j == 0){
        diff_td <- 0
      }else{
        diff_td <- theta - delta[j]
      }
      return(diff_td)
    })))
  }))
  
  # Berechne die Wahrscheinlichkeiten für alle Kategorien x = 0 bis m
  for (x in 0:m) {
    zaehler <- exp(sum(
      sapply(0:x, function(j){
        if(j == 0){
          diff_td <- 0
        }else{
          diff_td <- theta - delta[j]
        }
        return(diff_td)
      })
    ))
    probs[x + 1] <- zaehler / nenner  # Wahrscheinlichkeit für Kategorie x
  }
  
  # Erwartungswert E(X) berechnen
  E_X <- sum(0:m * probs)
  
  return(list(probs = probs, E_X = E_X))
}

# Beispielrechnung mit theta = 0 und delta = c(-0.29, 0.95)
## Item 1
result_1 <- calc_pcm(theta = 0, delta = c(-0.29, 0.95))

## Item 2
result_2 <- calc_pcm(theta = 0, delta = c(-0.5, 0.78))

E_score <- result_1$E_X + result_2$E_X


```

```{r}
if(!require('ggplot2')) {install.packages('ggplot2'); library(ggplot2)}

# Funktion zur Berechnung des erwarteten Scores (E_score) für verschiedene Theta-Werte
compute_E_score <- function(theta_vals, delta_1, delta_2) {
  results <- data.frame(theta = theta_vals, E_score = numeric(length(theta_vals)))
  
  for (i in 1:length(theta_vals)) {
    theta <- theta_vals[i]
    result_1 <- calc_pcm(theta = theta, delta = delta_1)
    result_2 <- calc_pcm(theta = theta, delta = delta_2)
    
    # Berechne den erwarteten Score E_score für dieses theta
    E_score <- result_1$E_X + result_2$E_X
    results$E_score[i] <- E_score
  }
  
  return(results)
}

# Theta-Werte Bereich definieren
theta_vals <- seq(-3, 3, length.out = 100)

# Schwellenwerte für beide Items
delta_1 <- c(-0.29, 0.95)  # Schwellen für Item 1
delta_2 <- c(-0.5, 0.78)   # Schwellen für Item 2

# Berechne E_score für verschiedene Theta-Werte
results <- compute_E_score(theta_vals, delta_1, delta_2)

# Plotten mit ggplot2
ggplot(results, aes(x = theta, y = E_score)) +
  geom_line(color = "blue", size = 1) +
  labs(title = "Erwarteter Score (E_score) als Funktion von Theta",
       x = "Theta", 
       y = "Erwarteter Score (E_score)") +
   theme_minimal()

```

Reversal vs. non-reversal. 

## Generalized Partial Credit Model?

## Rating Scale Model?

## Beispiele

## Evtl: Wann welches Modell

## Viel Übung
- Eigene Simulation vielleicht hier hin packen. Als Beispiel für Entscheidungsfindung, welches Modell sinn machen könnte!
 
