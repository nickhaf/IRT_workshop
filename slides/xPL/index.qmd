---
title: "Höher parametrisierte IRT Modelle"
format: letterbox-revealjs
title-slide-attributes:
  data-background-image: ./images/green_waves.jpg
  data-background-size: cover
execute:
  echo: false
---

```{r}
library(tidyverse)
source(here::here("R", "plot_functions.R"))
source(here::here("R", "irt_formulas.R"))
```

## Fahrplan


## {background-image="images/equation.jpg" background-size="1225px" }

::: {.absolute left="0%" bottom="2.5%" style="color:#F8F8F8; backdrop-filter: blur(0px); box-shadow: 0 0 0rem 0 rgba(255, 255, 255, 0);"}

Wiederholung: 1PL

:::

## 1PL Modell

$$
logit(P(X_{pi}=1)) = \theta_p - \beta_i
$$

- Logit: Transformation unseres linearen Terms, damit die Werte zwischen 0 und 1 liegen. Wahrscheinlichkeit $p$ durch Gegenwahrscheinlichkeit $1-p$. 
- Inverse der logit ist die logistische Funktion.


## 1PL Modell: Umformen

$$
logit(P(X_{pi}=1)) = \ln\left(\frac{P(X_{pi}=1)}{1-P(X_{pi}=1)}\right) = \theta_p - \beta_i
$$

## 1PL Modell: Umformen


$$
\frac{p_{pi}}{1-p_{pi}} = exp(\theta_p - \beta_i)
$$
\

$$
p_{pi} = exp(\theta_p - \beta_i)*( 1-p_{pi})
$$

::: aside
Mit $p_{pi}$ für $P(X_{pi}=1)$
:::

## 1PL Modell: Umformen


$$
p_{pi} + p_{pi} * exp(\theta_p - \beta_i) = exp(\theta_p - \beta_i)
$$

\

::: {.fragment .fade-in}

$$
p_{pi} + p_{pi} * exp(\theta_p - \beta_i) = exp(\theta_p - \beta_i)
$$ 

:::

\


::: {.fragment .fade-in}

$$
p_{pi}*(1+exp(\theta_p - \beta_i)) = exp(\theta_p - \beta_i)
$$ 

::: 


## 1PL Schreibweise 1


$$
P(X_{pi}=1) = \frac{exp(\theta_p - \beta_i)}{1 + exp(\theta_p - \beta_i)}
$$

::: aside
$P(X_{pi}=1)$ für $p_{pi}$ einsetzen, um die gängige Notation herzustellen
:::

## 1PL Schreibweise 2

$$
P(X_{pi}=1) = \frac{e^{\theta_p - \beta_i}}{1 + e^{\theta_p - \beta_i}}
$$

## 1PL Schreibweise 3

$$
P(X_{pi}=1) = \frac{1}{1 + e^{\color{#9B1B34}{-}\theta_p \color{#9B1B34}{+} \beta_i}}
$$

## Beispiel

$$
\frac{exp(1 - 0.8)}{1 + exp(1 - 0.8)} = 0.55
$$

Wahrscheinlichkeit einer richtigen Antwort über 0.5, wenn $\theta_p > \beta_i$. 

::: aside
- $\theta_p = 1$
- $\beta_i = 0.8$
:::

## Beispiel

$$
\frac{exp(0.8 - 1)}{1 + exp(0.8 - 1)} = 0.45 
$$

Wahrscheinlichkeit einer richtigen Antwort unter 0.5, wenn $\theta_p < \beta_i$. 

::: aside

- $\theta_p = 0.8$
- $\beta_i = 1$

:::


## {background-color="#17161e"}

![](images/equations3.jpg){.absolute top="-12.5%" right="12.5%" height="111%" style="max-height: unset; box-shadow: 0 0 0rem 0 rgba(255, 255, 255, 0);"}

::: {.absolute left="5%" top="2.5%" style="color:#F8F8F8; font-size: 1.5em; text-align: center;"}

Höher parametrisierte 
\ 
IRT Modelle

:::


## Neue Paramter

Wir können Parameter zu diesem Modell hinzufügen, wodurch wir flexibler in der Modellierung werden:

- Schwierigkeit $\beta_i$ (Intercept)

::: {.fragment .fade-in}
- Steigung $\alpha$ (Faktorladung, [Diskriminationsparameter]{.highlight})
:::

::: {.fragment .fade-in}
- [Ratewahrscheinlichkeit]{.highlight} $\gamma_i$ 
:::

## 3PL

$$
P(X_{pi}=1) = \color{#aaa938}{\gamma_i} + (1-\color{#aaa938}{\gamma_i})\frac{exp(\color{#F4BA02}{\alpha_i}(\theta_p - \color{#99D9DD}{\beta_i})))}{1 + exp(\color{#F4BA02}{\alpha_i}(\theta_p - \color{#99D9DD}{\beta_i}))}
$$

- [Schwierigkeit]{.lightblue}
- [Diskriminationsparamter]{.highlight}
- [Ratewahrscheinlichkeit]{.green}
  - z.B. bei 4 Antwortmöglichkeiten: $\gamma_i = 1/4 = 0.25$

## 2PL
$\gamma_i = 0$

$$
P(X_{pi}=1) = \color{#9B1B34}{0} + (1-\color{#9B1B34}{0})\frac{exp(\alpha_i(\theta_p - \beta_i)))}{1 + exp(\alpha_i(\theta_p - \beta_i))}
$$

## 1PL
$\alpha_i = 1$

$$
P(X_{pi}=1) = 0 + (1-0)\frac{exp(\color{#9B1B34}{1}(\theta_p - \beta_i)))}{1 + exp(\color{#9B1B34}{1}(\theta_p - \beta_i))}
$$


## Darstellung

```{ojs}
//| panel: sidebar

viewof alpha1 = Inputs.range(
  [-3, 3], 
  {value: 1, step: .01, label: tex`\alpha`}
)
viewof beta1 = Inputs.range(
  [-3, 3], 
  {value: 0, step: .01, label: tex`\beta`}
)
viewof gamma1 = Inputs.range(
  [0, 1], 
  {value: 0, step: .01, label: tex`\gamma`}
)


```

```{ojs}

line_function = function(alpha, beta, gamma, theta) {
    return gamma + (1 - gamma) * (Math.exp(alpha * (theta - beta)) / (1 + Math.exp(alpha * (theta - beta))));
}

// X-Variable
data = d3.range(-6, 6, 0.01).map((theta) => ({
  x: theta,
  y1: line_function(alpha1, beta1, gamma1, theta),
}));

Plot.plot(
  {
    x: {grid: false, domain: [-6, 6]}, 
    y: {grid: false, domain: [0, 1]},
    marks: [
      Plot.line(data, {x: "x", y: "y1", stroke: "#F4BA02"}),
    ]
  }
)
```

## Simulieren von IRT Daten

::::{.columns}
:::{.column width="30%"}

Jetzt ist ein guter Zeitpunkt, und uns ein sehr mächtiges Werkzeug anzuschauen: [Datensimulation]{.highlight}. 

:::

::: {.column width="70%"}

![](images/simulation.jpg){.absolute top="5%" right="0%" height="70%" style="max-height: unset; box-shadow: 0 0 0rem 0 rgba(255, 255, 255, 0);"}

:::
::::

## Übung

Geht zur [Übung](https://nickhaf.github.io/IRT_workshop/exercises//xPl/simulation.qmd) und probiert euch aus. 


# Welches Modell?

## 1PL vs. 3PL

## Modellfit beurteilen

- Gesamtmodell
- Itemfit
- Personenfit

# Gesamten Modellfit

Es gibt verschiedene Fit-Statistiken, die uns bei Aussagen über den Modellfit helfen, z.B.:

## Deviance
Deviance ist ein Maß für die relative Distanz einer Vorhersage von perfeketer Accuracy.  
Wir können uns die Konvergenzplots anschauen:

```{r}
#| code-fold: true
#| echo: true

library(TAM)

data(data.sim.rasch)

mod_2pl <- tam.mml.2pl(resp = data.sim.rasch, verbose = FALSE, irtmodel = "2PL")

plotDevianceTAM(mod_2pl)
```

## Fit Indices (z.B. AIC, BIC)
Da die Deviance (fast) immer besser wird, je mehr Parameter wir ins Modell mit aufnehmen, bestrafen bestimmte Fit Indices die Anzahl der Parameter.  
Schätzen die out-of-Sample predictive accuracy.  
Es gibt keine Daumenregeln für Cutoff Werte, allerdings können wir die Fit Indices für den Vergleich von genesteten Modellen nutzen. 


```{r}
#| echo: true

summary(tam.modelfit(mod_2pl))
```

## Inferenzstatistisch
Wir könne auch den Likelihood Ratio Test nutzen, um die Modelle zu vergleichen. Er erlaubt zum einen den Vergleich der empirischen und der Modellimplizierten Kovarianzmatrix, aber auch den Vergleich der Kovarianzmatrizen genesteter Modelle. 

:::{.callout-important}
Hängt von der Stichprobengröße ab und hat auch einige weitere Probleme. Sollte deshalb nicht in Isolation genutzt werden, sondern möglichst mit den besprochenen deskriptiven Fitmaßen zusammen. 

:::

## Itemfit
Um den Itemfit zu beurteilen, plotten wir die erwarteten und die beobachteten Itemkurven übereinander: 

```{r}
#| echo: true
#| code-fold: true
#| layout-ncol: 3
#| incldue: false 
#| results: "hide"
#| fig.keep: "all"

invisible(
plot(mod_2pl,
  items = 1:3, 
  type = "items",
  export = FALSE,
  observed = TRUE,
  package = "graphics")
)
```

## Infit/Outfit

```{r}
tam.fit(mod_2pl)

```

## Infit/Outfit
```{r}
#| code-fold: true

# Definieren einer eigenen Plot-Funkktion
plot_infit_outfit <- function(tam_obj){
fit_tam <- tam.fit(tam_obj)$itemfit

fit_plotdat <- fit_tam %>%
  # Als Faktor umwandeln, damit die Sortierung im Plot stimmt
  mutate(Item = factor(parameter, levels = unique(parameter[order(as.numeric(parameter))]))) %>%
  select(Item, Outfit, Infit) %>%
  pivot_longer(cols = c(Outfit, Infit), names_to = "fit", values_to = "value")

ggplot(fit_plotdat, aes(x = value, y = Item)) +
  geom_point(colour = "#F4BA02") +
  facet_grid(. ~ fit, scales = "fixed") +
  xlim(0.4, 1.6) +
  theme_bg() +
  geom_vline(xintercept = 0.5, linetype = "dotted", colour = "#9B1B34") +
  geom_vline(xintercept = 1.5, linetype = "dotted", colour = "#9B1B34")
}

plot_infit_outfit(mod_2pl)
```


# Personfit
Wie gut stimmen die Antwortmuster der Personen mit dem Modell überein?

## Infit Outfit
```{r}
#| code-fold: true

p_fit <- tam.personfit(mod_2pl) %>%
  pivot_longer(cols = c(outfitPerson, infitPerson), names_to = "fit", values_to = "value")

ggplot(p_fit, aes(x = value)) +
  geom_histogram(colour= "#F4BA02", fill = "#01364C", binwidth = 0.1) +
  theme_bg() +
  xlim(0, 2) +
  facet_grid(. ~ fit)
  
```


## Mögliche weitere Fragestellungen
Wir können uns noch viele weitere Dinge mit unseren Modellen anschauen. Sehr hilfreich dabei kann das Paket [ggmirt](https://github.com/masurp/ggmirt) sein, dass eine Vielzahl von praktischen Plots für die Auswertung bereitstellt. 

```{r}
library(ggmirt)
library(mirt)

## Nochmal mit mirt fitten
mod_mirt <- mirt(data.sim.rasch, 1, itemtype = "2PL", verbose = FALSE)
```

## Item Person Map
Ist die Fähigkeitsrange durch die Items gut Abgedeckt?
```{r}
itempersonMap(mod_mirt)
```

## ICC

```{r}
tracePlot(mod_mirt)
```

## ICC

```{r}
tracePlot(mod_mirt, facet = F, legend = T)
```

## Item Information Curves
Wie viel Information steuert jedes Item zur Schätzung von Theta bei? 
```{r}
itemInfoPlot(mod_mirt)
```

## Item Information Curves
```{r}
itemInfoPlot(mod_mirt, facet = T)
```

## Test Information Curve
```{r}
testInfoPlot(mod_mirt, adj_factor = 2)
```

## Mögliche Punkte

:::{.callout-note}
Mehr Parameter müsen nicht immer auch besser sein. Gerade im IRT-Kontext können komplexere Modelle schnell an ihre Grenzen kommen und nicht konvergieren. 
:::

Bei Modellwahl zu beachten:
- [Gewichtung]{.highlight} der Items
- Antwort[skala]{.highlight}
- [Simulation]{.highlight}/Modell[fit]{.highlight}
- [Ziel]{.highlight}

# Was tun bei polytomen Items?

## Beispielaufgabe 

::: center
Ich bin bequem, neige zur Faulheit.
:::
::: small
(trift überhaupt nicht zu) 1 ... 2 ... 3 ... 4 ... 5 (trift voll und ganz zu) 
:::

::: aside

Beispielfrage aus dem [Big-Five-Inventory (BFI-10)](https://zis.gesis.org/skala/Rammstedt-Kemper-Klein-Beierlein-Kovaleva-Big-Five-Inventory-(BFI-10)). 
:::

# 
<section style="text-align: center;">

[Wie?]{.r-fit-text .highlight}

</section>

# Partial Credit

## Grundidee {.center}

Den einzelnen Antwortkategorien wird eine [eigene Schwierigkeit]{.highlight} zugeordnet. Dadurch können wir die [Antwortwahrscheinlichkeit]{.highlight} in einer bestimmten [Kategorie]{.highlight} berechnen. 

## Anwendungsbereich
Ordinale Daten (geordnete Antwortkategorien), z.B.:

  - Likert-Skalen
  - Items, die auch mit Teilpunkten bewertet werden können (z.B. in Mathe)


## Darstellung

```{r}
#| echo: false

plot_pcm(delta = c(-0.29, 0.95))
```



## Formel

$$
\pi_{pix}= P(X_{pi}=x|\theta_p, \beta_{ik})= \frac{exp[\sum^x_{j=0}(\theta_p-\beta_{ij})]}{1+exp[\sum^k_{j=0}(\theta_p-\beta_{ij})]}
$$
::: aside

- Person $p$
- Item $i$
- Personenscore $x$

:::

## Partial Credit Model
$$
\pi_{pix}= \color{#9B1B34}{P(X_{pi}=x|\theta_p, \beta_{ik})}= \frac{exp[\sum^x_{j=0}(\theta_p-\beta_{ij})]}{1+exp[\sum^k_{j=0}(\theta_p-\beta_{ij})]}
$$


## Partial Credit Model

$$
\pi_{pix}= P(X_{pi}=x|\theta_p, \beta_{ik})= \frac{exp[\sum^x_{j=0}\color{#9B1B34}{(\theta_p-\beta_{ij})}]}{1+exp[\sum^k_{j=0}(\theta_p-\beta_{ij})]}
$$


Wichtig:$\beta_{i\color{#9B1B34}{j}}$ ist jetzt der [Schwellenparameter]{.highlight} der Kategorie $j$ des Items $i$.


## Raw score curve

```{r}
# Theta-Werte Bereich definieren
theta_vals <- seq(-3, 3, length.out = 100)

# Schwellenwerte für beide Items
delta_1 <- c(-0.29, 0.95) # Schwellen für Item 1
delta_2 <- c(-0.5, 0.78) # Schwellen für Item 2

# Berechne E_score für verschiedene Theta-Werte
results <- compute_E_score(theta_vals, delta_1, delta_2)

# Plotten mit ggplot2
ggplot(results, aes(x = theta, y = E_score)) +
  geom_line(color = "#9B1B34", size = 1) +
  labs(
    title = "Erwarteter Score als Funktion von Theta",
    x = "Theta",
    y = "Erwarteter Score"
  ) +
  theme_bg()
```

## Übung
Gehe zur [Partial-Credit-Übung]() und bearbeite sie. 


## Bildquellen
- Foto von <a href="https://unsplash.com/de/@pawel_czerwinski?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Pawel Czerwinski</a> auf <a href="https://unsplash.com/de/fotos/ein-schwarzer-und-gruner-abstrakter-hintergrund-mit-wellenformigen-linien-ELaFzBeZ6i0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@roman_lazygeek?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Roman Mager</a> auf <a href="https://unsplash.com/de/fotos/geschriebene-gleichungen-auf-brauner-holztafel-5mZ_M06Fc9g?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- https://www.bing.com/images/create/image-of-a-woman-writing-equations-on-a-window2c-li/1-670bee21dbf4423ca93d0804834a7f46?id=ujHjvSYHngnLxV45OzbrGQ%3d%3d&view=detailv2&idpp=genimg&thId=OIG3.E7px5jYmHkuo3mmm7QIC&skey=wPdVodkEkkpUXZMJ6uYMCEO41l21b_tAfYC2zWMLPmY&FORM=GCRIDP&mode=overlay
- Foto von <a href="https://unsplash.com/de/@crawford?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Crawford Jolly</a> auf <a href="https://unsplash.com/de/fotos/mann-mit-speer-wandmalerei-3IxuF9MCjkA?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@soymeraki?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Javier Allegue Barros</a> auf <a href="https://unsplash.com/de/fotos/silhouette-der-strassenbeschilderung-wahrend-der-goldenen-stunde-C7B-ExXpOIE?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
  
  
