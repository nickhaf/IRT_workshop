---
title: Algemeines Linear Gemischtes Modell (ALGM)
subtitle: "Das Raschmodell als eine Spezialfall des ALGM"
author: "Nicklas Hafiz"
date: "`r format(Sys.time(), '%Y %B, %d')`"
format: letterbox-revealjs
title-slide-attributes:
  data-background-image: ./images/dark_storm.jpg
  data-background-size: cover
---

```{r}
source(here::here("R", "plot_functions.R"))
```


## Überblick
- Generalisiertes Lineares Modell (GLM)
- Linear Mixed Model (LMM) 
- Übertragung auf IRT Kontext

## Generalisiertes Lineares Modell

$$
y = Xb+e
$$

Das funktioniert gut für kontinuierliche Outcomes $y$. Was aber machen wir, wenn wir nur 0 und 1 vorhersagen wollen (wie bei IRT)?   
Dann sind viele Annahmen der linearen Regression verletzt. Außerdem will das Modell auch Werte zwischen 0 und 1 vorhersagen, was ja gar keinen Sinn ergibt. 

## Logistische Regression
Wir können die Prädiktorseite  aber transformieren, damit die Outcome-Werte auf der gewünschten Skala liegen:

$$
E(y) = \mu = g^{-1}(Xb)
$$

::: aside
mit $g$ als Link Funktion und $g^{-1}$ als Inverse der Link Funktion.
:::

## Logistische Regression
Item Response Theorie nutzt die logistische Regression, um die Wahrscheinlichkeit von 0 oder 1 vorherzusagen. Dafür nutzen wir keine linear Funktion, sondern die probit oder logit Funktion als die Link Funktion $g()$ (Darstellbar durch die S-Kurve, die wir schon oft gesehen haben):

$$
g(\mu) = ln\left(\frac{\mu}{1-\mu}\right) = Xb
$$

:::{.callout-note}
Die logit Funktion bringt also unsere Werte auf die logit-Skala, sodass sie zwiscehn 0 und 1 liegen.
:::

::: aside
Die Inverse $g^{-1}$ der logit Funktion ist die logistische Funktion. Das schauen wir uns morgen aber noch einmal an. [Hier](https://www.geo.fu-berlin.de/en/v/soga-r/Basics-of-statistics/Logistic-Regression/The-Logit-Function/index.html) noch eine genauere Erklärung bei Interesse. 

:::

## {background-image="images/hogwarts.jpg" background-size="1250px"}

::: {.absolute left="15%" top="2.5%" style="font-size:2em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255, .0); backdrop-filter: blur(0px); box-shadow: 0 0 1rem 0 rgba(255, 255, 255, 0); border-radius: 5px;"}

Linear Gemischte Modelle

:::

::: aside
Foto von [Mauro Lima](https://unsplash.com/de/@limamauro23?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) auf [Unsplash](https://unsplash.com/de/fotos/eine-burg-aus-felsen-mit-einem-bewolkten-himmel-im-hintergrund-k2TgEJZ65D0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash).

:::


## Beispiel
Wir haben einen Datensatz der Schüler*innen aus verschiedenen Schulen enthält:
```{r}
#| echo: false
#| message: false

library(tidyverse)

## Daten laden
load(here::here("raw_data", "multilevel_data.rda"))


```

```{r}
str(stud_data)
```


:::{.callout-important}
Es fällt direkt auf: Die Daten sind genestet. Schüler*innen sind in Schulen gruppiert. [Wie gehen wir damit um?]{.highlight}
:::

::: aside
Daten aus diesem [Tutorial](https://raffaelevacca.github.io/Intro-multilevel-with-R/)
:::

## Warum dieses Beispiel?

Als kleiner Teaser: genauso wie hier Schüler*innen in Schulen genestet sind, können wir Items als genestet in Personen betrachten.


# Umgang mit genesteten Daten

```{r}
#| echo: false

illustration_dat <- stud_data %>% 
filter(school %in% c("1224", "1288", "1296")) #, "1308", "1317", "1358", "1374", "1433", "1436"))

## Zentrieren
illustration_dat <- illustration_dat %>% 
  mutate(ses_cent = ses - mean(ses))

```


## Option 1: Ignorieren

```{r}
#| echo: false
#
ggplot(data = illustration_dat , aes(x = ses_cent, y = mathach)) +
  geom_point(aes(colour = school)) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
         theme_bg() +
NULL
```

## Option 1: Ignorieren

Generell eher keine gute Idee:

- Die genestete Struktur kann von Interesse sein!
- Wir tun so, als ob wir mehr Informationen hätten, als wir letztendlich haben. Das liegt daran, dass Abhängigkeiten zwischen den Daten bestehen. Konsequenz:    

Standardfehler werden unterschätzt, unsere Inferenzstatistischen Tests werden eher signifikant. 

## Option 2: Aggregieren

```{r}
illustration_dat %>%
  group_by(school) %>%
  summarise(mean_mathach = mean(mathach),
            mean_ses = mean(ses_cent)) %>%
ggplot(aes(x = mean_ses, y = mean_mathach)) +
  geom_point(aes(colour = school)) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Mean Socioeconomic Status",
       y = "Mean Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
    set_colour_scheme() +
         theme_bg() +
NULL


```

## Option 2: Aggregieren


## Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren

```{r}
lm(mathach ~ ses_cent + school + ses_cent*school, data = illustration_dat) %>% 
    coef()
```


## Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren

```{r}
#| eval: false

ggplot(data = illustration_dat , aes(x = ses_cent, y = mathach)) +
  geom_point(aes(colour = school)) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Mean Socioeconomic Status",
       y = "Mean Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
    set_colour_scheme() +
         theme_bg() +
  facet_grid( . ~ school) +
NULL

```

## Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren
- Wird bei vielen Gruppen schnell unübersichtlich (vor allem auch mit verschiedenen Interkationen). 
- Multilevel-Modelle können die Nestung explizieter berücksichtigen.

## Option 4: Multilevel-Modell

```{r}
library(lme4)
mod2 <- lmer(mathach ~ ses_cent + (1|school), data = illustration_dat) 
summary(mod2)
```

## Option 4: Multilevel-Modell

```{r}
ggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school, fill = school)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE) +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
  set_fill_scheme() +
         theme_bg() +
  NULL
```


## Notizen 

Rein Optisch betrachtet scheint es recht wichtig zu sein, auf welche Schule man geht. Die Abweichung von Mittelwert des GesamtSES hat auch einen Einfluss. 

# Gleichungen
## Level 1 Gleichung

Für jede Gruppe j:
$$
y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + e_{ij}
$$

## Level 1 Gleichung 
```{r}
ggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
         theme_bg() +
  NULL
```

## Level-2 Gleichung

$$
\beta_{0j} = \beta_{0}+\zeta_{0j}
$$

$$
\beta_{1j} = \beta_1 + \zeta_{1j}
$$

## Level 2 Gleichung
```{r}
ggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
         theme_bg() +
  NULL
```

## Das gemischte Modell
Jetzt müssen wir nur noch einsetzen:


$$
y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + e_{ij}
$$
$$
\beta_{0j} = \beta_{0}+\zeta_{0j}
$$

$$
\beta_{1j} = \beta_1 + \zeta_{1j}
$$

$$
y_{ij} = \beta_{0}+\beta_1x_{ij} + \zeta_{0j} + \zeta_{1j}x_{ij} + e_{ij}
$$


## 

:::: {.columns}

::: {.column width="50%"}

**Random** effects

\
\

 ![](images/dice.jpg)

:::

::: {.column width="50%"}

::: {layout-ncol=1}

 ![](images/screws.jpg)
 
 \
 \

 **Fixed** effects

:::

:::

::::

## Random und Fixed effects

:::: {.columns}

::: {.column width="50%"}
**Random Effects**

- Annahme eines zugrundeliegenden Gesamtmittelwerts. Von diesem weichen die Gruppen **random** ab. 
- Bei Wiederholung würden wir andere Gruppen ziehen. 
- Partial Pooling: Regularisierung der Extremen Werte in Richtung Gruppenmittelwert. 
<!-- - Anders ausgedrückt: Wir nehmen an, dass die Gruppen aus einer Grundverteilung gezogen wurden. Wir hätten theoretisch aber auch andere Gruppen ziehen können: Wenn wir das Experiment wiederholen, die level auf diesem Faktor werden andere sein.
- Dadurch können wir Informationen aus den Anderen Gruppen ebenfalls nutzen.  -->

:::


::: {.column width="50%"}
**Fixed Effects**

- Hier machen wir diese Annahme einfach nicht. 
- Uns interessieren die tatsächlichen Gruppen, bei Wiederholung würden wird die gleichen ziehen.

:::


::::

## Beispiel

Wir untersuchen den Erfolg von Verhaltenstherapie und Psychoanalyse anhand der Rückfallquote nach einem Jahr.  
Patient*innen müssen hier nach Therapeut*innen genested werden. Dabei können wir die Therapeut*innen als random effects betrachten, wir haben sie ja schließlich nur als Mittel zum Zweck aus der Population an Therapeut*innen gezogen. Die Behandlungsform (Verhaltenstherapie, Psychoanalyse) ist hingegen ein fixed effect, da wir nur diese beiden Behandlungsformen untersuchen wollen.

Anders würde das Ganze aussehen, wenn uns die Erfolgsquote speziell dieser Therapeut*innen interessieren würde. Dann könnten wir sie ebenfalls als fixed effect im Modell mit aufnehmen. 



## lme4

```{r}
#| echo: true
library(lme4)

mod1 <- lmer(mathach ~ ses_cent + (1|school), data = illustration_dat) 
summary(mod1)
```


# Raschmodell als LMM
Warum das Ganze? Es geht doch eigentlich um IRT?

## Raschmodell als Spezialfall von LMM

Wir können die Items genestet in Personen betrachten.

Dafür müssen wir zwei Dinge beachten:
- Link Funktion.  
- Entscheidung über Annahme von fixed/random effects von Personen und Items.

::: aside
- De Boeck and Wilson (2004)
- Doran et al. (2007)
:::


## Link Funktion



## Fixed und Random Effects

- Entwicklung Fragebogen um diesen an verschiedenen Stichproben zu nutzen: Person als random, Items als fixed
- Entwicklung von Items für einen großen Fragenkatalog: Items ebenfalls als random


## Exercise 
- Direkt übertragen auf den IRT-KOntext? Also sagen: Nehmt die Daten aus dem letzten Beispiel und fittet ein LLM Modell. 
- Dann Vergleich mit TAM.


## Prädiktoren
- Beispiel aufgreifen, zeigen, wass man mit diesen Modell noch machen kann. 


## Bildquellen
- Foto von <a href="https://unsplash.com/de/@brenomachado?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Breno Machado</a> auf <a href="https://unsplash.com/de/fotos/fotografie-eines-gewitters-in9-n0JwgZ0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
  

