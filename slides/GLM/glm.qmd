---
title: Allgemeines Linear Gemischtes Modell (ALGM)
format: letterbox-revealjs
title-slide-attributes:
  data-background-image: ./images/dark_storm.jpg
  data-background-size: cover
bibliography: references.bib
---

```{r}
#| echo: false
source(here::here("R", "plot_functions.R"))
```




## Plan 

::::{.columns}
:::{.column width="50%"}
1. Generalisiertes Lineares Modell (GLM)
2. Linear Mixed Model (LMM) 
3. Alles das gleiche? Übertragung auf IRT Kontext
:::

:::{.column width="50%"}
![](images/plan.jpg){.image-right}
:::
::::


## Generalisiertes Lineares Modell

Lineare Regression:

$$
y = Xb+e
$$

Was aber machen wir, wenn wir statt eines kontinuierlichen Outcomes $y$ nur 0 und 1 vorhersagen wollen (wie bei IRT)?   

- Verletzung vieler Annahmen 
- Dass Modell würde auch Werte außerhalb der sinnvollen Range vorhersagen.

## Logistische Regression
Wir können die Prädiktorseite  aber transformieren, damit die Outcome-Werte auf der gewünschten Skala liegen:

$$
E(y) = \mu = g^{-1}(Xb)
$$

::: aside
mit $g$ als Link Funktion und $g^{-1}$ als Inverse der Link Funktion.
:::

## Logistische Regression
IRT nutzt die logistische Regression, um die Wahrscheinlichkeit von 0 oder 1 vorherzusagen.

Link Funktion $g()$: probit oder [logit]{.highlight}, S-Kurve.  
Mit Hilfe der Link Funktion transformieren wir die Outcomes, damit sie auf der gewünschten Skala liegen. 


## Logit-Funktion
$$
g(\mu) = logit(\mu) = ln\left(\frac{\mu}{1-\mu}\right) = Xb
$$
<!-- Wir haben hier die Antwortwahrscheinlichkeit in Logits. Um die Wahrscheinlichkeit auf der interpretierbaren Skala zu erhalten, brauchen wir für Xb das Inverse der Logit-Funktion, also die logistische Funktion. -->

:::{.callout-note}
Die logit Funktion bringt also unsere Werte auf die logit-Skala, sodass sie die Wahrscheinlichkeiten nicht mehr zwischen 0 und 1 liegen.
:::


## Im IRT Fall

$$
logit(P(X_{pi}=1)) = \ln\left(\frac{P(X_{pi}=1)}{1-P(X_{pi}=1)}\right) = \theta_p - \beta_i
$$


$$
P(X_{pi}=1) = g^{-1}(\theta_p - \beta_i)
$$

::: aside
Die Inverse $g^{-1}$ der logit Funktion ist die logistische Funktion $\frac{e^{\mu}}{1+e^{\mu}}$. Das schauen wir uns [morgen](https://nickhaf.github.io/IRT_workshop/slides/xPL/#/pl-modell) aber noch einmal an. Mit Hilfe der logistischen Funktion kommen wir dann von dieser Gleichung auf die bekannte IRT Formel. [Hier](https://www.geo.fu-berlin.de/en/v/soga-r/Basics-of-statistics/Logistic-Regression/The-Logit-Function/index.html) gibt es bei Interesse noch eine genauere Erklärung.  

:::

## {background-image="images/hogwarts.jpg" background-size="1250px"}

::: {.absolute left="15%" top="2.5%" style="font-size:2em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255, .0); backdrop-filter: blur(0px); box-shadow: 0 0 1rem 0 rgba(255, 255, 255, 0); border-radius: 5px;"}

Linear Gemischte Modelle

:::

::: aside
Foto von [Mauro Lima](https://unsplash.com/de/@limamauro23?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) auf [Unsplash](https://unsplash.com/de/fotos/eine-burg-aus-felsen-mit-einem-bewolkten-himmel-im-hintergrund-k2TgEJZ65D0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash).

:::


## Beispiel
Wir haben einen Datensatz der Schüler*innen aus verschiedenen Schulen enthält:
```{r}
#| echo: false
#| message: false

library(tidyverse)

## Daten laden
load(here::here("raw_data", "multilevel_data.rda"))


```

```{r}
str(stud_data)
```


:::{.callout-important}
Es fällt direkt auf: Die Daten sind genestet. Schüler*innen sind in Schulen gruppiert. [Wie gehen wir damit um?]{.highlight}
:::

::: aside
Daten aus diesem [Tutorial](https://raffaelevacca.github.io/Intro-multilevel-with-R/)
:::

## Warum dieses Beispiel? {.center}

Genauso wie hier Schüler*innen in Schulen genestet sind, können wir Items als genestet in Personen betrachten. 


## {background-image="images/groups.jpg" background-size="1225px"}

::: {.absolute right="5%" bottom="7%" style="font-size:1.5em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255 .7); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(255, 255, 255 .5); border-radius: 5px;"}
Umgang mit genesteten Daten
:::

```{r}
#| echo: false

stud_data <- stud_data %>%
  ## zentrieren
  mutate(ses_cent = ses - mean(ses))
  
illustration_dat <- stud_data %>% 
filter(school %in% c("1224", "1288", "1296")) #, "1308", "1317", "1358", "1374", "1433", "1436"))

```


## Option 1: Ignorieren

```{r}
#| echo: false
#
ggplot(data = illustration_dat , aes(x = ses_cent, y = mathach)) +
  geom_point(aes(colour = school)) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
         theme_bg() +
NULL
```

## Option 1: Ignorieren

Generell eher keine gute Idee:

- Die genestete Struktur kann von Interesse sein!
- Wir tun so, als ob wir mehr Informationen hätten, als wir letztendlich haben. Das liegt daran, dass Abhängigkeiten zwischen den Daten bestehen. Konsequenz:    

Standardfehler werden unterschätzt, unsere Inferenzstatistischen Tests werden eher signifikant. 

## Option 2: Aggregieren

```{r}
#| echo: false

illustration_dat %>%
  group_by(school) %>%
  summarise(mean_mathach = mean(mathach),
            mean_ses = mean(ses_cent)) %>%
ggplot(aes(x = mean_ses, y = mean_mathach)) +
  geom_point(aes(colour = school)) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Mean Socioeconomic Status",
       y = "Mean Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
    set_colour_scheme() +
         theme_bg() +
NULL


```

## Option 2: Aggregieren
- Gefahr eines ökologischen Fehlschlusses
- Verlust an Informationen und an Power. 
- Gruppenstrukturen sind meist auch von Interesse. 

## Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren

```{r}
mod1 <- lm(mathach ~ ses_cent + school + ses_cent*school, data = illustration_dat)

coef(mod1)
```


## Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren

```{r}
#| echo: false

ggplot(data = illustration_dat , aes(x = ses_cent, y = mathach)) +
  geom_point(aes(colour = school)) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Mean Socioeconomic Status",
       y = "Mean Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
    set_colour_scheme() +
         theme_bg() +
  facet_grid( . ~ school) +
NULL

```

## Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren
- Wird bei vielen Gruppen schnell unübersichtlich (vor allem auch mit verschiedenen Interkationen). 
- Multilevel-Modelle können die Nestung explizieter berücksichtigen.

## Option 4: Multilevel-Modell
```{r}
library(lme4)
mod2 <- lmer(mathach ~ 1 + ses_cent + (1 + ses_cent|school), data = stud_data) 
summary(mod2)
```


## Option 4: Multilevel-Modell

```{r}
#| echo: false

ggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
         theme_bg() +
  NULL
```



## {background-color="#17161e"}

![](images/equations2.jpg){.absolute top="-12.5%" right="12.5%" height="111%" style="max-height: unset; box-shadow: 0 0 0rem 0 rgba(255, 255, 255, 0);"}

::: {.absolute left="28%" top="2.5%" style="color:#F8F8F8; font-size: 1.5em; text-align: center;"}

Gleichungen

:::


## Level 1 Gleichung

Für jede Person i in Gruppe j:
$$
y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + e_{ij}
$$

## Level 1 Gleichung 
```{r}
#| echo: false

illustration_dat <- illustration_dat %>%
  mutate(regression_point = predict(mod1))
# Filter the data for school 1288
school_1288_data <- illustration_dat %>%
  filter(school == 1288)

# Plot with a dotted line for each point from school 1288
ggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +
  # Add geom_segment for each point in school 1288
  geom_segment(data = school_1288_data, aes(x = ses_cent, xend = ses_cent, y = mathach, yend = regression_point), linetype = "dotted") +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
  theme_bg() +
    set_colour_scheme() +
  ylim(c(-5, 25)) +
  NULL

```

## Level-2 Gleichung

$$
\beta_{0j} = \beta_{0}+\zeta_{0j}
$$

$$
\beta_{1j} = \beta_1 + \zeta_{1j}
$$

## Level 2 Gleichung
```{r}
#| echo: false

ggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +
  geom_smooth(aes(x = ses_cent, y = mathach, group = school, colour = school), method = "lm", se = FALSE) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
         theme_bg() +
  NULL
```

## Das gemischte Modell
Jetzt müssen wir nur noch einsetzen:


$$
y_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + e_{ij}
$$
$$
\beta_{0j} = \beta_{0}+\zeta_{0j}
$$

$$
\beta_{1j} = \beta_1 + \zeta_{1j}
$$

$$
\color{#F4BA02}{y_{ij} = \beta_{0}+\beta_1x_{ij} + \zeta_{0j} + \zeta_{1j}x_{ij} + e_{ij}}
$$


## Das gemischte Modell
```{r}
#| echo: false

ggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  geom_smooth(method = "lm", se = FALSE, colour = "#01364C") +
  labs(title = "Math Score by Socioeconomic Status",
       x = "Socioeconomic Status",
       y = "Math Score") +
       theme_classic() +
       ylim(c(-5, 25)) +
  set_colour_scheme() +
         theme_bg() +
  NULL
```

## Prädiktoren
Wir können jetzt auf beiden Ebenen auch noch Prädiktoren in die Gleichung mit aufnehmen und schauen, ob sich dadurch Varianz in den jeweiligen Leveln ($x_{ij}$ oder $\zeta_{0j}$ aufklären lässt).
Und das tolle: wir können auch eine Cross-Level-Interaktion modellieren (interagiert ein Level-1 Prädiktor mit einem Level 2 Prädiktor?).

:::{.callout-note}
## Beispiel Cross-Level-Interaktion

Zusammenhang zwischen Lernzeit (Level 1 Prädiktor, da individuell) und Lehrqualität könnte an Schulen mit hoher Lehrqualität stärker sein als an Schulen mit niedrigerer Lehrqualität. 

:::


## Random und Fixed effects

:::: {.columns}

::: {.column width="50%"}

**Random Effects**

::: {.fragment .fade-in}

::: small
- Annahme eines zugrundeliegenden Populationsmittelwerts. Von diesem weichen die Gruppen [random]{.highlight} ab. Bei Wiederholung würden wir andere Gruppen ziehen. 
- Partial Pooling: Regularisierung der Extremen Werte in Richtung Gruppenmittelwert. 
:::

:::

![](images/dice.jpg){.absolute bottom="-2.5%" left="0%" height="51.5%" style="max-height: unset; box-shadow: 0 0 0rem 0 rgba(255, 255, 255, 0);padding: 0em 0em;"}

:::

::: {.column width="50%"}

**Fixed Effects**
 ![](images/screws.jpg)

::: {.fragment .fade-in}

::: small
- Hier machen wir diese Annahme einfach nicht. 
- Uns interessieren die tatsächlichen Gruppen, bei Wiederholung würden wir vermutlich die gleichen ziehen.
:::
:::
:::

::::



## Beispiel

:::{.columns}
:::{.column width="50%"}
::: small
Wir untersuchen den Erfolg von Verhaltenstherapie und Psychoanalyse anhand der Rückfallquote nach einem Jahr.  
Patient\*innen müssen hier nach Therapeut\*innen genested werden. Dabei können wir die Therapeut\*innen als random effects betrachten, wir haben sie ja schließlich nur als Mittel zum Zweck aus der Population an Therapeut\*innen gezogen. Die Behandlungsform (Verhaltenstherapie, Psychoanalyse) ist hingegen ein fixed effect, da wir nur diese beiden Behandlungsformen untersuchen wollen.

Anders würde das Ganze aussehen, wenn uns die Erfolgsquote speziell dieser Therapeut*innen interessieren würde. Dann könnten wir sie ebenfalls als fixed effect im Modell mit aufnehmen. 

:::

:::
:::{.column width="50%"}
![](images/therapy.jpg){.image-right}
:::
:::


## {background-image="images/pupils.jpg" background-size="1225px"}

::: {.absolute right="5%" top="5%" style="font-size:1.5em;"}
[Nehmen wir unsere Schulen nun also [random]{.highlight} oder [fixed]{.highlight} effects ins Modell auf?]{.highlight}

:::


## lme4

```{r}
#| echo: true
library(lme4)

mod1 <- lmer(mathach ~ ses_cent + (1 |school), data = illustration_dat) 
summary(mod1)
```


# Raschmodell als LMM
Warum das Ganze? Es geht doch eigentlich um IRT?

## Raschmodell als Spezialfall von LMM

Wir können die Items genestet in Personen betrachten.

Dafür müssen wir zwei Dinge beachten:

- Link Funktion.  
- Entscheidung über Annahme von fixed/random effects von Personen und Items.

::: aside
Siehe @doran2007estimating. 
:::



## {background-image="images/items.jpg" background-size="1225px"}

::: {.absolute right="5%" bottom="5%" style="font-size:1.5em;"}
[Nehmen wir unsere Personen und Items nun als [random]{.highlight} oder [fixed]{.highlight} effects ins Modell auf?]{.highlight}

:::


## Fixed und Random Effects

- Entwicklung Fragebogen um diesen an verschiedenen Stichproben zu nutzen: Person als random, Items als fixed.
- Entwicklung von Items für einen großen Fragenkatalog: Items ebenfalls als random.


::: aside
@burkner2019bayesian stellen die Frage anders (vor allem im Bayesianischen Kontext): Ist parital Pooling gewünscht oder nicht?
:::

## Prädiktoren
Die Formulierung von IRT Modellen als Multilevel Modell erlaubt es uns, auf elegante Art Prädiktoren mit in das Modell aufzunehmen. 


## Literatur
::: {#refs}
:::

## Bildquellen
- Foto von <a href="https://unsplash.com/de/@brenomachado?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Breno Machado</a> auf <a href="https://unsplash.com/de/fotos/fotografie-eines-gewitters-in9-n0JwgZ0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@finnnyc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Mitch</a> auf <a href="https://unsplash.com/de/fotos/brauner-betonbau-tagsuber-nJupV3AOP-U?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@etiennegirardet?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Etienne Girardet</a> auf <a href="https://unsplash.com/de/fotos/menschen-im-gelben-hemd-stehen-auf-grauem-boden-RLT2oxS-Krk?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@museumsvictoria?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Museums Victoria</a> auf <a href="https://unsplash.com/de/fotos/graustufenfoto-von-menschen-die-auf-einem-stuhl-sitzen-n1LIveUPls4?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
  - Foto von <a href="https://unsplash.com/de/@nguyendhn?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Nguyen Dang Hoang Nhu</a> auf <a href="https://unsplash.com/de/fotos/person-die-auf-whitepaper-schreibt-qDgTQOYk6B8?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
  
