---
title: "Linking"
format: letterbox-revealjs
title-slide-attributes:
  data-background-image: ./images/dark_flower.jpg
  data-background-size: cover
bibliography: references.bib
---

```{r}
#| echo: false
library(TAM)
library(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen
library(tidyverse)

source(here::here("R", "plot_functions.R"))
source(here::here("R", "irt_formulas.R"))

```


## Wiederholung: Voraussetzungen für IRT

:::{.columns}

:::{.column width="50%"}

::: {.fragment .fade-in}
::: small
[Eindimmensionalität:]{.highlight}
Die Lösungswahrscheinlichkeit eines Items wird lediglich durch $\theta_p$ beeinflusst (und die Itemparameter), wobei die Dimension von $\theta_p$ gleich eins ist. Das Item [misst also nur ein Konstrukt]{.highlight}.  
:::
:::
:::

:::{.column width="50%"}
::: {.fragment .fade-in}
::: small
[Lokal stochastische Unabhängigkeit:]{.highlight}
Nach Kontrolle für die Personenfähigkeit korrelieren die Items nicht mehr. [Der einzige Grund dafür, dass die Items zusammenhängen, ist also, dass die Antwort von diesem Konstrukt beeinflusst wird.]{.highlight} 
Durch die Kontrolle für die Personenfähigkeit halten wir also den Fähigkeitswert konstant (alle Personen haben die gleiche Fähigkeit).  
Ein Modell mit lokaler Abhängigkeit hat wichtige Kovarianz zwischen den Items nicht entdeckt.
:::
:::
:::

:::

::: {.fragment .fade-in}
:::{.callout-note}

## Übrigens
[Items können mehrdimensional aber trotzdem lokal unabhängig sein]{.highlight}, wenn alle Items die gleichen Dimensionen messen. Andersherum sind Items immer lokal unabängig, wenn sie eindimensional sind.
:::
:::

## {background-image="images/penguins_two.jpg" background-size="1225px"}

::: {.absolute right=1.5% top="0.5%" style="font-size: 1.5em; color: #F8F8F8;"}

Differential Item  
Functioning (DIF) 

:::

## Das Problem
Funktionieren die Items in verschiedenen Gruppen (z.B. Geschlecht, Kultur, Fähigkeit ...) auf dieselbe Art und Weise?
Gibt es also [echte Mittelwertsunterschiede]{.highlight} zwischen beiden Gruppen, oder sind die Unterschiede auf besondere Interaktionen zwischen Items und Gruppen zurückzuführen?

## {background-image="images/rugby_female.jpg" background-size="1225px"}

::: {.absolute left=10% right="10%" top="7.5%" style="font-size:0.5em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255, .7); backdrop-filter: blur(0px); box-shadow: 0 0 1rem 0 rgba(255, 255, 255, .5); border-radius: 10px;"}

Der Legende nach soll Rugby während eines Fußballspiels in der gleichnamigen Stadt entstanden sein. Als der Mannschaft von William Webb Ellis 1823 eine Niederlage bevorstand, packte dieser den Ball mit den Händen und legte ihn ins Tor des Gegners. Obwohl berechtigte Zweifel am Wahrheitsgehalt der Geschichte bestehen – der Ball wurde bereits zuvor in den meisten Spielvarianten mit der Hand getragen –, ist der Pokal der Rugby-Union-Weltmeisterschaft nach William Webb Ellis benannt (der Webb Ellis Cup).

1863 wurde der englische Fußballverband Football Association (FA) mit dem Ziel gegründet, die noch vielfältigen Fußballregeln zu vereinheitlichen. Aufgrund von Streitigkeiten über Regeländerungen zogen sich einige Vereine aus dem Verband zurück und gründeten am 26. Januar 1871 mit der Rugby Football Union (RFU) einen konkurrierenden Verband, der in der Folgezeit nach und nach die Regeln der Rugby School standardisierte. Bereits am 27. März desselben Jahres fand in Edinburgh zwischen Schottland und England das erste Länderspiel statt. 

1895 erfolgte aufgrund eines Streits über den Amateurgedanken eine weitere Trennung, diesmal innerhalb der RFU. 21 Vereine, vor allem aus Arbeitervierteln Nordenglands, spalteten sich als Northern Rugby Union (heute Rugby Football League) ab, legten ihre eigenen Regeln fest und erlaubten die Professionalisierung des Sports. Aus den veränderten Regeln entwickelte sich die Variante Rugby League. Bis heute existieren beide Varianten des Rugbys nebeneinander. Internationale Begegnungen von Nationalmannschaften werden sowohl nach den Regeln der Rugby Union wie auch nach denen der Rugby League abgehalten. Seit 1995 sind im Rugby Union ebenfalls Profisportler zugelassen. 

:::{.aside}
[Wikipedia](https://de.wikipedia.org/wiki/Rugby#Geschichte)
:::
:::


## Beispiel

:::{.columns}
:::{.column width="50%"}
Welche Unterarten von Rugby gibt es laut Text?

\

:::{.columns}
:::{.column width="50%"}
![](images/nz.png) 
:::
:::{.column width="50%"}

![](images/de.png) 
:::
:::

:::
:::{.column width="50%"}

![](images/rugbymale.jpg){.image-right}
:::
:::


## Differential Item Functioning

- DIF: Item Characteristic Curves (also mind. einer der Paramter im IRT Modell) unterscheiden sich in verschiedenen Subgruppen.   
- Grund: [Item ist nicht eindimensional]{.highlight}.  
- DIF-Untersuchung ist damit auch eine Untersuchung der Testvalidität!

:::{.callout-important}
Mögliche Fähigkeitsunterschiede zwischen den Gruppen auf dem gemessenen Konstrukt interessieren uns hier nicht. Die rechnen wir gleich in @sec-linking raus.
:::

## Schwierigkeit

```{r}
#| echo: false

calc_2pl <- function(a, theta, xi){
  p <- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) 
  return(p) 
}


plot_data <- data.frame(
  theta = seq(-4, 4, length.out = 100)
) %>%
  mutate(p_1 = calc_2pl(1, theta, -1)) %>%
  mutate(p_2 = calc_2pl(1, theta, 1)) %>%
  pivot_longer(cols = c(p_1, p_2), names_to = "group", values_to = "p")

ggplot(plot_data, aes(theta, p, colour = group)) +
  geom_line() +
  theme_bg() +
  labs(title = "Item 1") +
  scale_color_manual(name = NULL, labels = unname(TeX( c("Gruppe 1 (\\beta = -1)", "Gruppe 2 (\\beta = 1)"))), values = c("#F4BA02", "#9B1B34"))
```

## Diskriminationsparameter

```{r}
#| echo: false

plot_data <- data.frame(
  theta = seq(-4, 4, length.out = 100)
) %>%
  mutate(p_1 = calc_2pl(0.3, theta, 1)) %>%
  mutate(p_2 = calc_2pl(0.9, theta, 1)) %>%
  pivot_longer(cols = c(p_1, p_2), names_to = "group", values_to = "p")

ggplot(plot_data, aes(theta, p, colour = group)) +
  geom_line() +
  theme_bg() +
  scale_color_manual(name = NULL, labels = unname(TeX( c("Gruppe 1 (\\alpha = 0.3)", "Gruppe 2 (\\alpha = 0.9)"))), values = c("#F4BA02", "#9B1B34"))

```


## Wie ghen wir damit um? 

Wir schauen uns die Itemparameter in der [Reference group]{.highlight} und in der [Focal group]{.highlight} an.  

\

Naive Lösung: Einfach die verschiedenen Subgruppen einzeln kalibrieren und dann die ICRs/Itemparameter anschauen.  

\

[Warum funktioniert das so nicht?]{.highlight}

## Warum funktioniert das nicht?
Werte aus verschiedenen Kalibrierungen können nicht ohne weiteres vergleichen werden, da die [Skalen arbiträr festgelegt]{.highlight} werden.  
\ 

[Wir müssen also vorher linken!]{.highlight}


## {background-image="images/link.jpg" background-size="1225px"}

::: {.absolute right="5%" top="0%" style="font-size:2em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255, 0); backdrop-filter: blur(5px); box-shadow: 0 0 0rem 0 rgba(255, 255, 255, 0); border-radius: 5px;"}

Linking

:::


## Wiederholung: Kalibrierung
Die kalibrierten Itemparameter und Personenfähigkeiten gelten erst einmal nur für **diese bestimmte Kombintation aus Items und Personen**. 

::: r-fit-text
[WARUM?]{.highlight}
:::

## Wiederholung: Kalibrierung
- Skala der Latenten Variable wird arbiträr festgelegt (meist auf einen Mittelwert von 0 und eine SD von 1).
- Modell ist sonst nicht idenfiziert. 
- Itemparameter aus versch. Kalibrierungen dadurch [nicht]{.highlight} auf der selben Skala. 
- [Sie können also nicht direkt miteinander verglichen werden.]{.highlight}

## Problem

:::: {.columns} 
::: {.column width="50%"}

**Das Problem**

Invarianz-Eigenschaft von IRT: [Itemparameter sind gleich über verschiedene Gruppen.]{.highlight}
Die Wahrscheinlichkeit für eine korrekte Antwort auf ein Item hängt also nur von $\theta$ ab. Nicht von anderen Personen in der Stichprobe. 

:::

::: {.column width="50%"}

:::{.fragment .fade-in}
**Die Lösung**

Wir müssen die Werte, die wir aus diesen unterschiedlichen Kalibrierungen bekommen, irgendwie in einen Zusammenhang setzen. 
:::
::: 
::::

## Beispiel 
Wenn wir eine sehr leistungsstarke Stichprobe haben, und eine sehr leistungsschwache, dann wird nach der Kalibrierung trotzdem bei beiden der Mittelwert der Latenten Variable 0 und die SD 1 sein. Mittelschwere Items werden aber in der schwachen Gruppe eher positive Schwierigkeiten haben, in der starken Gruppe eher negative.


## Beispiel
Group 1: $\theta \sim N(0,1)$ \
Group 2: $\theta \sim N(1, 1.4)$ \

\ 

Für die Kalibrierung legen wir jetzt aber fest, dass gilt:
Gruppe 1: $\hat{\theta} \sim N(0,1)$ \
Gruppe 2: $\hat{\theta} \sim N(0,1)$ \

:::{.callout-important}
Die Bedeutung des Skalenursprungs (0) unterscheidet sich, dadurch unterscheiden sich auch die Itemparameter.
:::

## Illustration

Wir nehmen an, dass die gleiche Person in Gruppe 1 und in Gruppe 2 getestet wird. Gruppe 2 ist dabei insgesamt stärker als Gruppe 1.

:::{.columns}

:::{.column width="50%"}
```{r}
#| echo: false

library(tidyverse)

data_lines <- data.frame(
  x = c(-4:4, -4:4),
  y = c(rep(2, 9), rep(1, 9)),
  group = c(rep("Gruppe 1", 9), rep("Gruppe 2", 9)),
  label = c(-4:4, -5:3),
  point = c(rep(0, 9), rep(0, 9))
)

ggplot(data_lines, aes(x, y, group = group, colour = group)) +
  geom_line() +
  geom_point(aes(x = point), show.legend = FALSE) +
  theme_bg() +
  theme(
    axis.title.y = element_blank(),
    axis.text = element_blank(),
    axis.line = element_blank(),
    axis.ticks = element_blank(), 
    legend.title = element_blank()
  ) +
  ylim(0, 3) +
  xlab("Personenfähigkeit") +
  geom_text(aes(label = label), vjust = 1.5, show.legend = FALSE) +
  set_colour_scheme()
  
```
:::
:::{.column width="50%"}
Mit der gleichen Fähigkeit würde sie in Gruppe 2 einen niedrigeren Fähigkeitswert zugewiesen bekommen, da diese Gruppe einfach besser ist als Gruppe 1.
:::
:::

:::{.aside}
Grafik nach [diesem Workshop](https://www.youtube.com/watch?v=AEBcf2zcN9U&t=748s).

:::

## Illustration 2

:::{.columns}
:::{.column width="50%"}
Das gleiche Item wird in Gruppe 2 als leichter geschätzt als in Gruppe 1, einfach weil die Lösungswahrscheinlichkeit in Gruppe 2 insgesamt höher ist. 

:::
:::{.column width="50%"}
```{r}
#| echo: false

library(tidyverse)

data_lines <- data.frame(
  x = c(-4:4, -4:4),
  y = c(rep(2, 9), rep(1, 9)),
  group = c(rep("Gruppe 1", 9), rep("Gruppe 2", 9)),
  label = c(-4:4, -5:3),
  point = c(rep(2, 9), rep(2, 9))
)

ggplot(data_lines, aes(x, y, group = group, colour = group)) +
  geom_line() +
  geom_point(aes(x = point), show.legend = FALSE) +
  theme_bg() +
  theme(
    axis.title.y = element_blank(),
    axis.text = element_blank(),
    axis.line = element_blank(),
    axis.ticks = element_blank(), 
    legend.title = element_blank()
  ) +
  ylim(0, 3) +
  xlab("Itemschwierigkeit") +
  geom_text(aes(label = label), vjust = 1.5, show.legend = FALSE) +
  set_colour_scheme() +
  geom_text(aes(x = point, label = "Item 1"), vjust = -1.5, show.legend = FALSE) 

```
:::
:::



```{r define_itemparameters}
#| echo: false
set.seed(420)

items <- data.frame(
  item_id = 1:13,
  b = sample(seq(-3, 3, by = 0.001), size = 13),
  a = sample(seq(0, 1, by = 0.001), size = 13),
  c = rep(0, 13)
)
```


```{r simulation_nonequivalent}
#| output: false
#| echo: false

set.seed(123)

n_subj <- 50000 ## Als Objekt speichern, da so leichter Änderbar

calc_2pl <- function(a, theta, xi){
  p <- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) 
  return(p) 
}

items <- data.frame(
    item_id = 1:13, 
    b = seq(-3, 3, by = 0.5), 
    a = seq(0.5, 1.5, length.out = 13), 
    c = rep(0, 13)
)

## Diesmal nehmen wir einfach 2 Gruppen
subjects_1 <- data.frame(
  sub_id = 1:n_subj,
  theta = c(rnorm(n_subj, 0, 1)),
  group = rep("1", n_subj)
)

subjects_2 <- data.frame(
  sub_id = n_subj + 1:n_subj * 2, ## Andere Personen, deshalb andere ID
  theta = c(rnorm(n_subj, 1, 1)),
  group = rep("2", n_subj)
)

subjects <- rbind(subjects_1, subjects_2)

sim_dat <- merge(subjects, items) %>%
  mutate(p = calc_2pl(a, theta, b)) %>%
  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))

sim_dat_2 <- sim_dat %>%
  select(item_id, sub_id, answer, group) %>%
  pivot_wider(names_from = item_id, values_from = answer, id_cols = c("group", "sub_id"))

## Jetzt kalibrieren wir sie getrennt, als ob wir zwei verschiedene Sample hätten.

## Zuerst vorbereiten der Daten, d.h. die nicht benötigten Spalten entfernen und einen Datensatz pro Gruppe erzeugen.
group_1_prep <- sim_dat_2 %>%
  filter(group == "1") %>%
  select(-group, -sub_id)

group_2_prep <- sim_dat_2 %>%
  filter(group == "2") %>%
  select(-group, -sub_id)

## Kalibrieren der beiden Gruppen getrennt
group_1_2PL <- tam.mml.2pl(group_1_prep, irtmodel = "2PL", verbose = FALSE)
group_2_2PL <- tam.mml.2pl(group_2_prep, irtmodel = "2PL", verbose = FALSE)

# ## Extrahieren der Itemparameter
itempars_1 <- as.data.frame(apply(group_1_2PL$item_irt[, c("alpha", "beta")], 2, round, 2))
itempars_2 <- as.data.frame(apply(group_2_2PL$item_irt[, c("alpha", "beta")], 2, round, 2))
colnames(itempars_2) <- c("alpha_2", "beta_2")


parameters_b <- cbind(itempars_1, itempars_2)

# ----------------------------- Diskriminationsparameter Simulation

## Diesmal nehmen wir einfach 2 Gruppen
subjects_1 <- data.frame(
  sub_id = 1:n_subj,
  theta = c(rnorm(n_subj, 0, 1)),
  group = rep("1", n_subj)
)

subjects_2 <- data.frame(
  sub_id = n_subj + 1:n_subj * 2, ## Andere Personen, deshalb andere ID
  theta = c(rnorm(n_subj, 0, 1.4)),
  group = rep("2", n_subj)
)

subjects <- rbind(subjects_1, subjects_2)

sim_dat <- merge(subjects, items) %>%
  mutate(p = calc_2pl(a, theta, b)) %>%
  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))

sim_dat_2 <- sim_dat %>%
  select(item_id, sub_id, answer, group) %>%
  pivot_wider(names_from = item_id, values_from = answer, id_cols = c("group", "sub_id"))

## Jetzt kalibrieren wir sie getrennt, als ob wir zwei verschiedene Sample hätten.

## Zuerst vorbereiten der Daten, d.h. die nicht benötigten Spalten entfernen und einen Datensatz pro Gruppe erzeugen.
group_1_prep <- sim_dat_2 %>%
  filter(group == "1") %>%
  select(-group, -sub_id)

group_2_prep <- sim_dat_2 %>%
  filter(group == "2") %>%
  select(-group, -sub_id)

## Kalibrieren der beiden Gruppen getrennt
group_1_2PL <- tam.mml.2pl(group_1_prep, irtmodel = "2PL", verbose = FALSE)
group_2_2PL <- tam.mml.2pl(group_2_prep, irtmodel = "2PL", verbose = FALSE)

# ## Extrahieren der Itemparameter
itempars_1 <- as.data.frame(apply(group_1_2PL$item_irt[, c("alpha", "beta")], 2, round, 2))
itempars_2 <- as.data.frame(apply(group_2_2PL$item_irt[, c("alpha", "beta")], 2, round, 2))
colnames(itempars_2) <- c("alpha_2", "beta_2")

parameters_a <- cbind(itempars_1, itempars_2)

```

## Schwierigkeit
```{r}
#| echo: false

plot_group_pars(parameters_b, beta, beta_2) +
  labs(
    title = "Itemschwierigkeiten für zwei nicht-äquivalente Gruppen",
    caption = TeX("\\theta_1 \\sim N(0,1), \\theta_2 \\sim N(1, 1)")
  )
```


## Diskriminationsparameter
```{r}
#| echo: false

plot_group_pars(parameters_a, alpha, alpha_2) +
  labs(
    title = "Diskriminationsparameter für zwei nicht-äquivalente Gruppen",
    caption = TeX("\\theta_1 \\sim N(0,1), \\theta_2 \\sim N(0, 1.4)")
  ) +
  xlim(0, 1.5) +
  ylim(0, 2.5)
```



## Schlusfolgerung
Wir brauchen also einen Referenzrahmen um unsere Testergebnisse interpretieren zu können. 

Lösung: [Linking]{.highlight}

## Linking: Anwendungsbereiche {#sec-linking}

Immer, wenn wir Werte aus verschiedenen Kalibrierungen miteinander vergleichen wollen:

- DIF
- Tests, die in verschiedenen Jahren bearbeitet wurden
- Adaptives Testen


Ganz egal welcher Anwendungsfall, das Szenario ist das gleiche: Wir haben verschiedene Testformen, und wollen die Scores auf eine gemeinsame Skala bringen. 
- Dafür haben wir zwei Möglichkeiten:
    - Gemeinsame Items
    - Gemeinsame Personen

## Übung
Gehe zur ersten [Übung](https://nickhaf.github.io/IRT_workshop/exercises/linking/data.html) zum Thema Linking/DIF. Es geht hier nochmal um Datenaufbereitung. 


## Gemeinsame Personen
Personen bearbeiten beide Tests. Personenfähigkeit wird basierend auf einem Referenztest geschätzt, und dann fixiert und konstant gehalten, wenn andere Testformen bearbeitet werden. Die Fähigkeitswerte werden dann genutzt, um Itemparameter auf beiden Testformen zu schätzen. 


## Ankeritems

:::: {.columns} 
::: {.column width="50%"}

Ankeritems sind [gemeinsame Items]{.highlight}, die in beiden Testformen vorhanden sind. Hauptproblem bei der Auswahl: Sie sollten in beiden Gruppen nicht unterschiedlich funktionieren, es sollte also kein Differential Item Functioning (DIF) geben.

:::


::: {.column width="50%"}

![](images/anker.jpg){.image-right}

:::
::::

## Linking Verfahren: Grundidee

Die $\theta$ scores der Focal group müssen so transformiert werden, dass sie auf einer gemeinsamen Skala mit den Scores der Reference group liegen:

$$
\theta_R = A \theta_F + B
$$


Ziel: "Linking constants" $A$ und $B$ zu finden, welche die Itemparameter aus den beiden Gruppen auf der selben Skala plazieren. 


## Linking Methoden
- Die häufigsten Methoden:
    - mean-mean ()
    - mean-sigma ()
    - Stocking-Lord ()
    - Haebermann ()


## mean-sigma Transformationen {#sec-transf}

Grundlegend sind einige einfache Transformationen:

- $\theta^* = x\theta+y$
- $\beta^* = x\beta=y$
- $\alpha^*=\frac{\alpha}{x}$
- $c^* = c$

Ziel ist es, die Linkingkonstanten $x$ und $y$ zu finden. 


## Finden der Linkingkonstanten
- $\overline{\beta}_R$ und $\overline{\beta}_F$ als Mittelwert der geschätzten Itemschwierigkeiten in Referenz- und Fokusgruppe
- $\sigma_R$ und $\sigma_F$ als Standardabweichung der geschätzten Itemschwierigkeiten in Referenz- und Fokusgruppe. 

## Finden der Linkingkonstanten
$$
x = \frac{\sigma_R}{\sigma_F}
$$

:::{.callout-note}
## Mean-mean Linking
Die mean-mean Methode nutzt hier statt der Standardabweichung der Itemschwierigkeiten die Mittelwerte (Erwartungswerte) der Diskriminationsparamter. In der Praxis werden beide Methoden eher weniger genutzt. 
:::

$$
y = \overline{\beta}_R - x(\overline{\beta}_F)
$$

Und dann einsetzen in 
$$
\theta* = x\theta+y
$$ 
$$
B_F^* = x\beta_F + y
$$

## mean-sigma


Probleme: linking constants können stark von Outliern beeinflusst werden, und von den differential standards errors of the item difficutly estimates
Es gibt aber auch Robuste Verfahren.  

Alternative: Characteristic curve methods

## Characteristic curve methods
Versuch, die Linking constants so zu berechnen, dass die test charactersitic curves so ähnlich wie möglich sind. Nutzen daher alle Itemparameter um die Linkingkonstanten zu finden. Ist rechnerisch aufwändiger. 

- Haebara-Linking
- Stocking-Lord

## Stocking-Lord

$$
\sum_{\theta}\left[\sum_j P(Y_i = 1|\theta, a_{R_i}, b_{R_i}, c_{R_i})  - \sum_j P(Y_i=1|\theta,\frac{a_{F_i}}{x}, xb_{F_i}+y, c_{F_i})\right]^2
$$

- i: Item

## Stocking-Lord

$$
\sum_{\theta}\left[\color{#9B1B34}{\sum_i P(Y_i = 1|\theta, \alpha_{R_i}, \beta_{R_i}, c_{R_i})}  - \sum_i P(Y_i=1|\theta,\frac{\alpha_{F_i}}{x}, x\beta_{F_i}+y, c_{F_i})\right]^2
$$
- Summe der Test Characteristic Curves über alle Items. 

## Stocking-Lord

$$
\sum_{\theta}\left[\sum_i P(Y_i = 1|\theta, \alpha_{R_i}, \beta_{R_i}, c_{R_i})  - \sum_i P(Y_i=1|\theta,\color{#9B1B34}{\frac{\alpha_{F_i}}{x}, x\beta_{F_i}+y, c_{F_i}})\right]^2
$$

- Das sind unsere Transformationen von @sec-transf.


## Haebara


$$
\sum_{\theta}\color{#9B1B34}{\sum_i}\left[P(Y_i = 1|\theta, \alpha_{R_i}, \beta_{R_i}, c_{R_i}) - P(Y_i=1|\theta,\frac{\alpha_{F_i}}{x}, x\beta_{F_i}+y, c_{F_i})\right]^2
$$
Sehr ähnlich, nur dass wir hier die Item Characteristic Curves verwenden. 


## Haebara und Stocking-Lord

In beiden Fällen wird die Gleichung so optimiert, dass die Linkingkonstanten $x$ und $y$ so bestimmt werden, dass der Unterschied zwischen den Test/Item Characteristic Curves der Referenz- und Fokusgruppe minimiert wird. 

## Übung
Löse die [Übungsaufgaben zum Linking](https://nickhaf.github.io/IRT_workshop/exercises/linking/linking.html). 

## {background-image="images/penguins_group.jpg" background-size="1225px"}

::: {.absolute left="2.5%" bottom="0%" style="font-size:1em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255, .7); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(255, 255, 255, .5); border-radius: 5px;"}

### Zurück zum Anfang: Differential Item Functioning

Wir haben jetzt gesehen, wie man Item- und Personenparamter aus verschiedenen Kalibrierungen auf die selbe Skala bringen kann. Jetzt können wir auf das Eingangsproblem dieser Session zurückkommen: [DIF]{.highlight}. 

:::

## DIF finden

Viele verschiedene Verfahren, meist wird folgende Frage untersucht: Wurden Items in bestimmten Gruppen häufiger beantwortet wurden als in anderen Gruppen, bzw. wurden die Itemparamter in bestimmten Gruppen anders geschätzt (nachdem gelinkt wurde)?  

Es werden also entweder die [beobacheteten Testscores]{.highlight} oder die [latenten Fähigkeitswert]{.highlight} zur Berechnung genutzt.  

:::{.aside}
Siehe @berrio2020developments für eine ausführliche Übersicht zu verschiedenen DIF-Findungs Ansätzen. 
:::

## Ansätze

### Observed Score Ansätze
Z.B. der bekannte [Mantel-Haenszel Test](). Nutzen Kontingenztabellen, um zu schauen, ob sich die Antwortmusster der einzelenen Items in den verschiedenen Gruppen unterscheiden.  

### [Likelihood Ratio Test]()
Vergleich von Modellen mit zwischen Gruppen fixierten Parametern eines Items, und Modellen mit frei geschätzten Parametern.   

## Ansätze
### [Logistische Regression]()
Logistische Regression Interaktionsterm zwischen Gruppenzugehörigkeit und Itemschwierigkeit/Personenfähigkeit gibt.  

### [Lord's Chi Quadrat Test/Wald Test]()
IRT Ansatz, Vergleich von Itemparametern zwischen den Gruppen.

### [Raschtrees]()
Gruppensplitting, kann auch diverse Interaktionen zwischen Variablen einfach untersuchen. 

## [Regularisierung]()


## Iteratives Vorgehen
:::{.callout-note}
Oft werden die Methoden iterativ angewandt, da beim anfänglichen Matchen der Gruppen ja auch eventuell DIF-Items für die Berechnung der Scores verwendet werden. 
:::


## Welche denn jetzt?

Abhängig vom Modell, der Fragestellung und den Daten. 

Für kleine Datensätze eventuell eher Verfahren wählen die auf beobachtete Scores zurückgreifen (nicht auf geschätzte Trait-Variablen).   

Sehr große Datensätze mit vielen Kovariaten (und damit auch vielen verschiedenen Gruppen und Gruppen-Interaktionen) könnten von Machine-Learning profitieren, z.B. Rasch-Trees.  

Ansonste Simulation von Daten und ausprobieren. 

:::{.callout-important}
Generell ist es keine gute Idee, einfach nach p-Werten zu gehen, um Items dann blind auszuschließen. Stattdessen sollten die Itemschwierigkeitsunterschiede zwischen den Gruppen beurteilt, und auch das Item selbst inhaltlich untersucht werden.
:::

https://cran.r-project.org/web/packages/difR/difR.pdf


## Übung
Bitte bearbeite die [DIF-Übung](https://nickhaf.github.io/IRT_workshop/exercises/linking/dif.html).

## {background-image="images/penguins.jpg" background-size="1225px"}
::: {.absolute right="5%" top="0%" style="font-size:2em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255, .7); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(255, 255, 255, .5); border-radius: 5px;"}
Pause
:::

## Literatur
::: {#refs}
:::


## Bildquellen
- Foto von <a href="https://unsplash.com/de/@anniespratt?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Annie Spratt</a> auf <a href="https://unsplash.com/de/fotos/rosa-blattrige-blume-nahaufnahme-fotografie-r9eIL7jtenc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@ncx1701d?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Martin Wettstein</a> auf <a href="https://unsplash.com/de/fotos/weisser-und-schwarzer-pinguin-auf-grauem-felsen-o4snRPEZRRs?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@ncx1701d?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Martin Wettstein</a> auf <a href="https://unsplash.com/de/fotos/menschen-auf-grunem-rasen-tagsuber-GJQUr0SgKi0?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von [Bryson Hammer](https://unsplash.com/de/@trhammerhead?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) auf [Unsplash](https://unsplash.com/de/fotos/selektives-fokusfoto-von-grauen-metallketten-JZ8AHFr2aEg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash).
- Erstellt mit [Bing Bild-Ersteller](ttps://www.bing.com/images/create/a-simulation-that-we-are-all-living-in-a-simulatio/1-66e33509faf2483e82f8b47ed577a221?id=9qHmBvQeaNYbK1HW5T0qLQ%3D%3D&view=detailv2&idpp=genimg&idpclose=1&thid=OIG1.o1KL86Aq8PP9cXCbZnHc&skey=wPdVodkEkkpUXZMJ6uYMCEO41l21b_tAfYC2zWMLPmY&form=SYDBIC).
- Foto von <a href="https://unsplash.com/de/@quinoal?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Quino Al</a> auf <a href="https://unsplash.com/de/fotos/graustufenfoto-einer-frau-die-fussball-spielt-hCfZwxu6auo?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- Foto von <a href="https://unsplash.com/de/@jhc?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">James Coleman</a> auf <a href="https://unsplash.com/de/fotos/graustufenfoto-eines-nfl-spielers-der-den-ball-fangt-CTEvFbFpVC8?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
- https://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/Flag_of_Germany.svg/1920px-Flag_of_Germany.svg.png
- https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Flag_of_New_Zealand.svg/800px-Flag_of_New_Zealand.svg.png
- Foto von <a href="https://unsplash.com/de/@westbeach013?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Casey Allen</a> auf <a href="https://unsplash.com/de/fotos/afrikanische-pinguine-am-meeresufer-neben-felsbrocken-UjpEGHu8uNU?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
  
