{
  "hash": "6964a2c75092e4451eb2cfd924f7001f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"IRT Voraussetzungen\"\nauthor: \"Nicklas Hafiz\"\ndate: \"05 September, 2024\"\nformat: \n  letterbox-revealjs:\n    embed-resources: true\n    logo: \"../../images/iqb.svg\"\n    footer: <https://nickhaf.github.io/IRT_workshop/slides/>\n---\n\n::: {.cell}\n\n:::\n\n\n\n# Überblick \n\n## Voraussetzungen der Item Response Theory\n\n- Eindimmensionalität\n- Lokal Stochastische Unabhänigkeit (https://files.eric.ed.gov/fulltext/EJ1224232.pdf). \n\n## Eindimmensionalität\n- Wenn nicht gegeben:\n    - SEM\n    - Dependency Matrix\n\n## Lokal stochastische Unabhängigkeit\nNach Kontrolle für die Personenfähigkeit korrelieren die Items nicht mehr. Der einzige Grund dafür, dass die Items zusammenhängen, ist also, dass die Antwort von diesem Konstrukt beeinflusst wird. \nDurch die Kontrolle für die Personenfähigkeit halten wir also den Fähigkeitswert konstant (alle Personen haben die gleiche Fähigkeit), \n\n- Abbildung\n- Einordnung: Lokale Unabhängigkeit, weitere Begriffe?\n- Beispiel\n\n# Linking\n\n## Problem\nWir haben die Invarianz-Eigenschaft von IRT bereits kennen gelernt: \n**Itemparameter sind gleich über verschiedene Gruppen.**\nDie Wahrscheinlichkeit für eine korrekte Antwort auf ein Item hängt nur von $\\theta$ ab. Nicht von anderen Personen in der Stichprobe. \n\nWie schaffen wir das aber, wenn wir anhand von verschiedenen Gruppen kalibrieren?\nWir müssen die Werte, die wir aus diesen Kalibrierungen bekommen, irgendwie in einen Zusammenhang setzen. \n\n## Wiederholung: Kalibrierung\n- Kalibrierung: schätzen von Itemparametern und Personenfähigkeiten\n- Erst einmal nur für **diese bestimmte Kombintation aus Items und Personen**\n\nWARUM?\n\n\n## Wiederholung: Kalibrierung\n- Skala der Latenten Variable wird arbiträr festgelegt auf einen Mittelwert von 0 und eine SD von 1  \n- Modell? sonst nicht idenfiziert. \n- Itemparameter dadurch **nicht** auf der selben Skala\n- **Sie können also nicht direkt miteinander verglichen werden.**\n\n## Beispiel \nSie hängen ja von den latenten VAriablen in der Stichprobe ab. Wenn wir eine sehr gute Stichprobe haben, und eine sehr schwache, dann werden trotzdem bei beiden der Mittelwert der Latenten Variable 0 und die SD 1 sein. Mittelschwere Items werden aber in der schwachen Gruppe eher positive Schwierigkeiten haben, in der starken Gruppe eher negative. (Beispiel nochmal genauer ausführen, evtl. mit Grafik, Ich hatte dazu etwas im ersten Buch, dass ich gelesen habe). \n\n\n## Beispiel\nGroup 1: $\\theta \\sim N(0,1)$\nGroup 2: $\\theta \\sim N(1, 1.4)$\n\nFür die Kalibrierung legen wir jetzt aber fest, dass gilt:\nGroup 1: $\\theta \\sim N(0,1)$\nGroup 2: $\\theta \\sim N(0,1)$\n\n## Beispiel \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n\n## Simulate data\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n## Schlusfolgerung\n- Wir brauchen also einen Referenzrahmen um unsere Testergebnisse interpretieren zu können. \n- Das bedeutet auch, dass wir die Werte aus verschiedenen Kalibrierungen nicht direkt miteinander vergleichen können.\n- Lösung: **Linking**\n\n\n## {background-image=\"images/link.jpg\" background-size=\"1150px\"}\n\n::: {.absolute right=\"5%\" top=\"0%\" style=\"font-size:2em; padding: 0.5em 0.5em; background-color: rgba(255, 255, 255, .7); backdrop-filter: blur(5px); box-shadow: 0 0 1rem 0 rgba(255, 255, 255, .5); border-radius: 5px;\"}\n\nLinking/Equating\n\n:::\n\n::: aside\nFoto von [Bryson Hammer](https://unsplash.com/de/@trhammerhead?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) auf [Unsplash](https://unsplash.com/de/fotos/selektives-fokusfoto-von-grauen-metallketten-JZ8AHFr2aEg?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash). \n\n::: \n\n<!-- https://hectornajera83.github.io/book/scale-equating-and-linking.html -->\n\n\n## Identifizirbarkeit\n\n\n## Beispiel\n\n\n## Linking/Equating\n- Szenario: Wir haben verschiedene Testformen, und wollen die Scores auf eine gemeinsame Skala bringen. \n- Dafür haben wir zwei Möglichkeiten:\n    - Gemeinsame Items\n    - Gemeinsame Personen\n\nAbbildung z.B. mit Verteilung von theta scores, die nochmal zeigt was das Problem ist. \nDann kann man bestimmte Items markieren, und die Verteilungen entsprechend dieser markierten Items verschieben. \n\nEmbretson 2000, S. 253\n\n- Item Parameter werden in beiden Tests geschätzt, und dann anhand der Ankeritems durch eine geeignete Transformation auf eine gemeinsame Skala gebracht.\n\n## Beispiel\n- Schulvergleichsstudien über die Jahre:\n- Itempools von Unternehmen, die Einstellungstests anbieten. \n\n## Ankeritems\n\n:::: {.columns} \n::: {.column width=\"50%\"}\n\n- Gemeinsame Items, die in beiden Testformen vorhanden sind. \n- Sollten keinen DIF haben.Genauer recherchieren: How to choose anchor items. \n\n:::\n\n\n::: {.column width=\"50%\"}\n\n![](images/anker.jpg){.image-right}\n\n:::\n\n::::\n\n## Ankeritems\n- Kallibrierungen der Parameterschätzer aus zwei verschiedenen Testformen werden auf eine gemeinsame Skala gebracht.\n- Wir müssen also die theta ($\\theta$) scores des einen Tests so transformieren, dass sie auf einer gemeinsamen Skala mit den Scores des anderen Tests liegen:\n\n$$\n\\theta_Y = A \\theta_X + B\n$$\n\n## Ankerpersonen\nPersonen bearbeiten beide Tests. Personenfähigkeit wird basierend auf einem Referenztest geschätzt, und dann fixiert und konstant gehalten, wenn andere Testformen bearbeitet werden. Die Fähigkeitswerte werden dann genutzt, um Itemparameter auf beiden Testformen zu schätzen. \n\n\n## Linking \n\n$$\n\\theta* = x\\theta+y\n$$\n\n...\n\n## Linking\nZiel: \"Linking constants\" $x$ und $y$ findend, welche die Item parameter aus den beiden Gruppen auf der selben Skala plazieren. \nDeutlich machen, für welche Art Modell nutzbar!\nNochmal mit dem neueren Buch rübergehen, das geht noch mehr in die Tiefe. \n\n- Zwei häufige Methoden:\n    - mean-sigma:\n        - Annahme: Gemeinsame Ankeritems, oder Zwei Gruppen haben den genau gleichen Test bearbeitet. \n$$\nB_B^* = x\\beta_b=y\n$$\n\n$$\nx = \\frac{\\sigma_A}{\\sigma_B}\n$$\n\n$$\ny = \\overline{\\beta}_A - x(\\overline{\\beta}_B)\n$$\n\nUnd dann einsetzen in \n$$\n\\theta* = x\\theta+y\n$$ \n\netc. \n\nmal ausprobieren!\n\n## mean-sigma\n\n\nProbleme: linking constants können stark von Outliern beeinflusst werden, und von den differential standards errors of the item difficutly estimates\n- Robust procedures exist. \n\nNur die  item difficulty parameters werden zur berechnung der Linking constants genutzt. \n\nAlternative: Characteristic curve methods\n\n## Characteristic curve methods\nVersuch, die Linking constants so zu berechnen, dass die test charctersitic curves so ähnlich wie möglich sind. Nutzen daher alle item parameter um die Linking constants zu finden.  computationally more expensive. \nEmpirical research zeigt keine großen Unterschide zwischen beiden Methoden? Nochmal selber recherchiereen. \n\n## Gibt es neuere methoden? Z.B. Multi-group IRT, CFA framework ...?\n\n## Beispiel\nIm Embretson machen sie eine kleine Simulation. Könnten wir auch machen, entweder als aufgabe oder demonstrieren. \n-  Man könnte die Linking constants setzen, gukcen was das mit den schwierikeiten macht, und die Simulierten Werte wieder rekapitulieren. \n\n\n\n# Messinvarianz/DIF\n\n## Das Problem\n- Funktionieren die Items in verschiedenen Gruppen (z.B. Geschlecht, Kultur, Fähigkeit ...) auf dieselbe Art und Weise?\n- Gibt es also echte Mittelwertsunterschiede zwischen beiden Gruppen, oder sind die Unterschiede auf Besondere Interaktionen zwischen Items und Gruppen zurückzuführen?\n\n\n## DIF\n- Wenn wir das auf bestimmte Items anwenden, sprechen wir von Differential Item Functioning. \n\nRaschtrees vorstellen?\nAnsonsten Embretson ab Linking auch gut. \n\n\n## Was wird Überprüft? \n\n\n\n\n## Beispiel was bei nichtbeachtung passiert\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}