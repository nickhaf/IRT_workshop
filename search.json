[
  {
    "objectID": "exercises/index_glm.html",
    "href": "exercises/index_glm.html",
    "title": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Sortieren nach\n       Voreinstellung\n         \n          Titel\n        \n         \n          Autor:in\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitel\n\n\nAutor:in\n\n\n\n\n\n\nDas Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells\n\n\nNicklas Hafiz\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells"
    ]
  },
  {
    "objectID": "exercises/glm/glm.html",
    "href": "exercises/glm/glm.html",
    "title": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Ziel dieser übung ist es, Daten für ein einfachs Raschmodell zu simulieren. Warum? Weil wir so die Datengenerierenden Prozesse besser verstehen können. Also, let’s get started.\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse",
    "crumbs": [
      "Übungen",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells"
    ]
  },
  {
    "objectID": "exercises/glm/glm.html#simulation",
    "href": "exercises/glm/glm.html#simulation",
    "title": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Ziel dieser übung ist es, Daten für ein einfachs Raschmodell zu simulieren. Warum? Weil wir so die Datengenerierenden Prozesse besser verstehen können. Also, let’s get started.\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse",
    "crumbs": [
      "Übungen",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells"
    ]
  },
  {
    "objectID": "exercises/index.html",
    "href": "exercises/index.html",
    "title": "Übungen",
    "section": "",
    "text": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEinführung in R\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinking\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHöher parametrisierte Modelle\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen"
    ]
  },
  {
    "objectID": "exercises/xPl/xPL.html",
    "href": "exercises/xPl/xPL.html",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Wir schauen uns eine ganz simple Version an. Wer interessiert ist, und z.B. Daten für eine Poweranalyse simulieren möchte, findet hier Unterstützung. Installieren und/oder lade folgende Pakete für diese Übung:\n\n## Wenn noch nicht installiert:\n# install.packages(\"tidyverse\")\n# install.packages(\"TAM\")\n\nlibrary(tidyverse)\nlibrary(TAM)\n\n\nZuerst müssen wir festlegen, was wir eigentlich simulieren wollen. Wir starten mit einem 2PL Modell. Wie sah die Gleichung dafür noch einmal aus?\n\\[\nP(X_{is} = 1|\\theta_s,\\beta_i,\\alpha_i) = \\frac{\\exp(\\alpha_i(\\theta_s-\\beta_i))}{1 + \\exp(a_i (\\theta_s - \\beta_i))}\n\\tag{1}\\]\n\nVersuche noch einmal, alle Elemente von Gleichung 1 für dich selbst zu erklären.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir versuchen zu schätzen wie hoch die Wahrscheinlichkeit ist, dass eine Person \\(s\\) ein Item \\(i\\) richtig (\\(X_{is} = 1\\)) beantwortet. Dazu nutzen wir den Diskriminationsparameter \\(\\alpha_i\\) und den Schwierigkeitsparameter \\(\\beta_i\\) von Item \\(i\\) und die Personenfähigkeit \\(\\theta_s\\) von Person \\(s\\).\n\n\n\n\n\nJetzt beginnt der fun part: Schreibe eine Funktion genannt calc_2pl die Gleichung 1 in R Code umsetzt.\n\n\n\n\n\n\n\nDer Aufbau der Funktion könnte so aussehen:\n\ncalc_2pl &lt;- function(alpha, theta, beta){\n}\n\nBefülle sie nun mit Gleichung 1. alpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Diese Werte können dann im Funktionskörper (zwischen {}) genutzt werden, um Gleichung 1 in R Code zu übersetzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nalpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Im Funktionskörper (zwischen {}) werden sie genutzt, um \\(p\\) anhand von Gleichung 1 zu berechnen.\n\n\n\n\nJetzt geht’s los! Wir wollen nun eigene Daten simulieren. Das tolle ist: wir können so alle Aspekte selber festlegen, und daran untersuchen, wie sich das Variieren von bestimmten Parametern auf das Ergebnis auswirkt.\n\n\nZuerst die Items. Baue einen data.frame mit dem Namen items. Er soll 13 Zeilen und 4 Spalten haben und folgendes enthalten:\n\n\n\nitem_id: Die ID des Items, von 1 bis 13.\n\nalpha: Die Diskriminationsparameter, liegen zwischen 0.5 und 1.5 in 13 gleich langen Schritten.\n\nbeta: Die Schwierigkeitsparameter, liegen zwischen -3 und 3 jeweils im Abstand von 0.5.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDie Funktion seq() ist dein Freund. Mehr brauchst du nicht, um die Zahlenreihen zu erzeugen. Schaue dir die Dokumentation an.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 1.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nDas sind also die Itemparameter, die wir in unsere Simulation packen.\n\n\n\n\nJetzt können wir die Personen simulieren. Unser Ziel ist also ein data.frame, der \\(\\theta\\) Werte für die untersuchten Personen enthält. Wir simulieren 100000 Personen, der data.frame sollte also 100000 Zeilen haben. Außerdem benötigen wir zwei Spalten:\n\n\n\nID: Die ID der Person, von 1 bis 100000.\n\ntheta: Die Fähigkeit der Person, die wir simulieren. Wir nehmen an, dass die Fähigkeit normalverteilt ist, mit einem Mittelwert von 0 und einer Standardabweichung von 1.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWir können zufällige Daten aus einer Normalverteilung mit Hilfe der Funktion rnorm() ziehen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(666) \n## Ich setzte hier einen Seed, damit meine zufällig erzeugten Werte replizierbar bleiben.\n## Wenn du den Seed in deinem Skript auf die gleiche Zahl setzt, bekommst du genau die gleichen Zufallswerte und kannst besser vergleichen. \n\n\nsubjects &lt;- data.frame(\n    sub_id = 1:100000,\n    theta = c(rnorm(100000, 0, 1))\n)\n\n\n\n\nPerfekt! Jetzt können wir die Itemantworten simulieren. Dazu sind noch ein paar kleine Schritte nötig:\n\nMerge die beiden data.frames subjects und items zu einem neuen data.frame sim_dat zusammen. Und zwar so, dass wir \\(1000 * 13\\) Zeilen bekommen, also jede Person jedes der 13 Items zugeordnet wird (bisher noch ohne Antwort der Person, nur mit den Itemkennwerten. Das erleichtert uns im nächsten Schritt, die Antworten der Personen zu simulieren).\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNutze die Funktion merge() ohne irgendwelche weiteren Argumente.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- merge(subjects, items)\n\n## Wir schauen mal, ob das hinkommt:\n\nstr(sim_dat)\n\n'data.frame':   1300000 obs. of  6 variables:\n $ sub_id : int  1 2 3 4 5 6 7 8 9 10 ...\n $ theta  : num  0.753 2.014 -0.355 2.028 -2.217 ...\n $ item_id: int  1 1 1 1 1 1 1 1 1 1 ...\n $ b      : num  -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 ...\n $ a      : num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n $ c      : num  0 0 0 0 0 0 0 0 0 0 ...\n\n\nUnser finaler data.frame hat 1300000 Zeilen, wie verlangt. Lasst uns auch noch einmal schauen, ob eine zufällige Person alle Items beantwortet hat:\n\nsim_dat %&gt;%\n  filter(sub_id == 420) %&gt;%\n  pull(item_id)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n\nDas sieht gut aus!\n\n\n\n\nJetzt simulieren wir aus diesem Vorbereiteten data.frame die Antworten der Personen, abhängig von ihren Fähigkeiten \\(\\theta\\) (jede Person hat hier einen zufälligen Wert aus einer Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 1\\) bekommen) und den Itemparametern \\(\\alpha\\) und \\(\\beta\\) (die hatten wir einfach als Sequenz festgelegt). Lege eine neue Spalte p in sim_dat an, die für jede Person die Wahrscheinlichkeit enthält, dass sie das jeweilige Item richtig beantwortet. Dafür brauchen wir jetzt unsere Funktion calc_2pl, die wir am Anfang definiert haben! Diese nimmt aus jeder Zeile den theta, alpha und beta Wert als input, und berechnet daraus die Wahrscheinlichkeit, dass die Person das Item richtig beantwortet.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSupereinfach geht das ganze mit der mutate() Funktion aus dem tidyverse.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(p = calc_2pl(a, theta, b))\n\n## Mal nachschauen:\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p\n1      1  0.7533110       1 -3 0.5 0 0.8672265\n2      2  2.0143547       1 -3 0.5 0 0.9246434\n3      3 -0.3551345       1 -3 0.5 0 0.7895862\n4      4  2.0281678       1 -3 0.5 0 0.9251233\n5      5 -2.2168745       1 -3 0.5 0 0.5966588\n6      6  0.7583962       1 -3 0.5 0 0.8675190\n\n\nAuf den ersten Blick sieht das schonmal gut aus. Personen mit niedrigerem \\(\\theta\\) Wert haben auch eine geringere Wahrscheinlichkeit, das Item richtig zu beantworten (vgl. z.B. Zeile 2 und 3).\n\n\n\n\nJetzt sind wir auch schon fast am Ende. Wir müssen lediglich aus den Wahrscheinlichkeiten die tatsächlichen Antworten der Personen simulieren. Nutze die Berechneten Antwortwahrscheinlichkeiten p, um für jede Person und jedes Item einen Wert aus einer Bernoulliverteilung zu ziehen.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEine Bernoulliverteilung ist eine Binomialverteilung mit nur einem Versuch. Wir können daher die Funktion rbinom() nutzen, und das size-Argument auf 1 setzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p answer\n1      1  0.7533110       1 -3 0.5 0 0.8672265      1\n2      2  2.0143547       1 -3 0.5 0 0.9246434      1\n3      3 -0.3551345       1 -3 0.5 0 0.7895862      0\n4      4  2.0281678       1 -3 0.5 0 0.9251233      1\n5      5 -2.2168745       1 -3 0.5 0 0.5966588      1\n6      6  0.7583962       1 -3 0.5 0 0.8675190      1\n\n\nAuch das sieht erst einmal plausibel aus! Toll!\n\n\n\n\nJetzt wollen wir natürlich noch schauen, ob das Ganze so funktioniert hat, wie wir uns das vorgestellt haben. Wir wollen das TAM Paket, um ein 2PL Modell auf die Itemantworten zu fitten. Wenn alles geklappt hat, sollten wir in etwa unsere Itemparameter wiedererkennen.\n\nZuerst müssen wir unsere Daten dafür noch ein bisschen aufbereiten, sprich ins Wide-Format bringen. Probiere das also mal aus!\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIch nutze dafür immer deutlich lieber die tidyverse Funktion pivot_wider() als die base-R Funtkion reshape().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = sub_id)\n\nhead(sim_dat_wide)\n\n# A tibble: 6 × 14\n  sub_id   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`  `10`  `11`  `12`\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1      1     1     1     1     1     1     0     1     0     1     1     0     0\n2      2     1     1     1     1     1     1     1     1     1     1     1     0\n3      3     0     1     1     1     0     0     0     0     0     1     0     0\n4      4     1     1     1     1     1     1     1     1     0     0     0     0\n5      5     1     1     0     1     0     0     0     0     0     0     0     0\n6      6     1     1     0     1     1     1     0     0     0     0     0     0\n# ℹ 1 more variable: `13` &lt;int&gt;\n\n\nDie Spaltennamen sind jetzt unsere Item-Nummern. Pro Zeile finden sich die Antworten der Personen, entweder hat sie das entsprechende Item richtig (1) oder falsch (0) beantwortet.\n\n\n\n\nJetzt können wir das Modell fitten. Nutze dafür wie angekündigt das TAM Paket, und entferne noch die Spalte sub_id, wir geben nur die Itemantworten in die Funktion. Speichere den Funktionsoutput in dem Object sim_dat_2PL.\n\n\n\n\n\n\n\nWir brauchen die Funktion tam.mml.2pl().\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsim_dat_2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"2PL\")\n\n....................................................\nProcessing Data      2024-10-07 10:05:31.649142 \n    * Response Data: 100000 Persons and  13 Items \n    * Numerical integration with 21 nodes\n    * Created Design Matrices   ( 2024-10-07 10:05:31.838423 )\n    * Calculated Sufficient Statistics   ( 2024-10-07 10:05:32.106954 )\n....................................................\nIteration 1     2024-10-07 10:05:32.147749\nE Step\nM Step Intercepts   |----\nM Step Slopes       |---\n  Deviance = 1267150.8426\n  Maximum item intercept parameter change: 0.419556\n  Maximum item slope parameter change: 0.209449\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 2     2024-10-07 10:05:32.380107\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1256572.3453 | Absolute change: 10578.5 | Relative change: 0.00841853\n  Maximum item intercept parameter change: 0.142116\n  Maximum item slope parameter change: 0.13129\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 3     2024-10-07 10:05:32.619823\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1255075.8194 | Absolute change: 1496.526 | Relative change: 0.00119238\n  Maximum item intercept parameter change: 0.085173\n  Maximum item slope parameter change: 0.070548\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 4     2024-10-07 10:05:32.864377\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254560.5132 | Absolute change: 515.3062 | Relative change: 0.00041075\n  Maximum item intercept parameter change: 0.064561\n  Maximum item slope parameter change: 0.041601\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 5     2024-10-07 10:05:32.987871\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254359.2843 | Absolute change: 201.2289 | Relative change: 0.00016042\n  Maximum item intercept parameter change: 0.050987\n  Maximum item slope parameter change: 0.030886\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 6     2024-10-07 10:05:33.103148\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254269.9949 | Absolute change: 89.2894 | Relative change: 7.119e-05\n  Maximum item intercept parameter change: 0.04019\n  Maximum item slope parameter change: 0.023359\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 7     2024-10-07 10:05:33.240256\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254226.1047 | Absolute change: 43.8902 | Relative change: 3.499e-05\n  Maximum item intercept parameter change: 0.031482\n  Maximum item slope parameter change: 0.017898\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 8     2024-10-07 10:05:33.467036\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254203.2462 | Absolute change: 22.8585 | Relative change: 1.823e-05\n  Maximum item intercept parameter change: 0.02456\n  Maximum item slope parameter change: 0.013847\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 9     2024-10-07 10:05:33.580888\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254191.0072 | Absolute change: 12.239 | Relative change: 9.76e-06\n  Maximum item intercept parameter change: 0.019126\n  Maximum item slope parameter change: 0.01079\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 10     2024-10-07 10:05:33.694889\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254184.3636 | Absolute change: 6.6436 | Relative change: 5.3e-06\n  Maximum item intercept parameter change: 0.014893\n  Maximum item slope parameter change: 0.008455\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 11     2024-10-07 10:05:33.826551\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254180.7248 | Absolute change: 3.6388 | Relative change: 2.9e-06\n  Maximum item intercept parameter change: 0.011608\n  Maximum item slope parameter change: 0.006653\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 12     2024-10-07 10:05:34.0218\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254178.7154 | Absolute change: 2.0093 | Relative change: 1.6e-06\n  Maximum item intercept parameter change: 0.009062\n  Maximum item slope parameter change: 0.005253\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 13     2024-10-07 10:05:34.142448\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254177.5963 | Absolute change: 1.1192 | Relative change: 8.9e-07\n  Maximum item intercept parameter change: 0.007088\n  Maximum item slope parameter change: 0.004157\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 14     2024-10-07 10:05:34.266304\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.967 | Absolute change: 0.6293 | Relative change: 5e-07\n  Maximum item intercept parameter change: 0.005555\n  Maximum item slope parameter change: 0.003297\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 15     2024-10-07 10:05:34.380882\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.6097 | Absolute change: 0.3573 | Relative change: 2.8e-07\n  Maximum item intercept parameter change: 0.004363\n  Maximum item slope parameter change: 0.002619\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 16     2024-10-07 10:05:34.510906\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.4047 | Absolute change: 0.205 | Relative change: 1.6e-07\n  Maximum item intercept parameter change: 0.003433\n  Maximum item slope parameter change: 0.002083\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 17     2024-10-07 10:05:34.718183\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.286 | Absolute change: 0.1188 | Relative change: 9e-08\n  Maximum item intercept parameter change: 0.002706\n  Maximum item slope parameter change: 0.001658\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 18     2024-10-07 10:05:34.83199\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.2165 | Absolute change: 0.0695 | Relative change: 6e-08\n  Maximum item intercept parameter change: 0.002137\n  Maximum item slope parameter change: 0.001321\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 19     2024-10-07 10:05:34.94643\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1755 | Absolute change: 0.041 | Relative change: 3e-08\n  Maximum item intercept parameter change: 0.00169\n  Maximum item slope parameter change: 0.001053\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 20     2024-10-07 10:05:35.059214\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1511 | Absolute change: 0.0244 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.001338\n  Maximum item slope parameter change: 0.00084\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 21     2024-10-07 10:05:35.173408\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1364 | Absolute change: 0.0146 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.001061\n  Maximum item slope parameter change: 0.00067\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 22     2024-10-07 10:05:35.308891\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1276 | Absolute change: 0.0088 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000842\n  Maximum item slope parameter change: 0.000535\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 23     2024-10-07 10:05:35.50356\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1222 | Absolute change: 0.0054 | Relative change: 0\n  Maximum item intercept parameter change: 0.000669\n  Maximum item slope parameter change: 0.000427\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 24     2024-10-07 10:05:35.62626\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1189 | Absolute change: 0.0033 | Relative change: 0\n  Maximum item intercept parameter change: 0.000532\n  Maximum item slope parameter change: 0.000341\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 25     2024-10-07 10:05:35.742111\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1169 | Absolute change: 0.002 | Relative change: 0\n  Maximum item intercept parameter change: 0.000423\n  Maximum item slope parameter change: 0.000272\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 26     2024-10-07 10:05:35.951754\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1156 | Absolute change: 0.0012 | Relative change: 0\n  Maximum item intercept parameter change: 0.000337\n  Maximum item slope parameter change: 0.000218\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 27     2024-10-07 10:05:36.068103\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1149 | Absolute change: 8e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000268\n  Maximum item slope parameter change: 0.000174\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 28     2024-10-07 10:05:36.184109\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1144 | Absolute change: 5e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000214\n  Maximum item slope parameter change: 0.000139\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 29     2024-10-07 10:05:36.304893\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1141 | Absolute change: 3e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.00017\n  Maximum item slope parameter change: 0.000111\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 30     2024-10-07 10:05:36.43922\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1139 | Absolute change: 2e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000136\n  Maximum item slope parameter change: 8.9e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 31     2024-10-07 10:05:36.654303\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1138 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000108\n  Maximum item slope parameter change: 7.1e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 32     2024-10-07 10:05:36.777484\nE Step\nM Step Intercepts   |-\nM Step Slopes       |-\n  Deviance = 1254176.1137 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 8.6e-05\n  Maximum item slope parameter change: 5.7e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nItem Parameters\n   xsi.index xsi.label     est\n1          1         1 -1.5085\n2          2         2 -1.4816\n3          3         3 -1.3370\n4          4         4 -1.1347\n5          5         5 -0.8444\n6          6         6 -0.4600\n7          7         7 -0.0038\n8          8         8  0.5308\n9          9         9  1.1642\n10        10        10  1.8783\n11        11        11  2.6740\n12        12        12  3.4901\n13        13        13  4.4630\n...................................\nRegression Coefficients\n     [,1]\n[1,]    0\n\nVariance:\n     [,1]\n[1,]    1\n\n\nEAP Reliability:\n[1] 0.626\n\n-----------------------------\nStart:  2024-10-07 10:05:31.6458\nEnd:  2024-10-07 10:05:37.142358 \nTime difference of 5.496558 secs\n\n\n\n\n\n\nSchau dir die Itemparameter an, die das Modell geschätzt hat. Sie finden sich unter sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")]. Vergleiche mit den ursprünglichen Itemparametern, die wir in items festgelegt haben. Was fällt dir auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems_2pl &lt;- apply(sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\nitem_comparison &lt;- cbind(items_2pl, items[, c(\"a\", \"b\")])\n\nitem_comparison\n\n   alpha  beta         a    b\n1   0.52 -2.92 0.5000000 -3.0\n2   0.59 -2.53 0.5833333 -2.5\n3   0.66 -2.04 0.6666667 -2.0\n4   0.75 -1.52 0.7500000 -1.5\n5   0.84 -1.01 0.8333333 -1.0\n6   0.92 -0.50 0.9166667 -0.5\n7   1.00  0.00 1.0000000  0.0\n8   1.09  0.49 1.0833333  0.5\n9   1.17  1.00 1.1666667  1.0\n10  1.24  1.52 1.2500000  1.5\n11  1.35  1.97 1.3333333  2.0\n12  1.38  2.52 1.4166667  2.5\n13  1.47  3.03 1.5000000  3.0\n\n\n\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nggplot(data=item_comparison, \n       aes(x = b, y = beta)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() + ## Ein anderes Theme festlegen\n  xlab(TeX(\"\\\\beta\")) + ## Latex Syntax für die Achsenbeschriftung nutzen\n  ylab(TeX(\"\\\\hat{\\\\beta}\"))\n\n\n\n\n\n\n\n\nggplot(data=item_comparison, \n       aes(x = a, y = alpha)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() +\n  xlab(TeX(\"\\\\alpha\")) +\n  ylab(TeX(\"\\\\hat{\\\\alpha}\"))\n\n\n\n\n\n\n\nDas sieht super aus, die Werte stimmen gut überein. Dadurch, dass wir so viele Personen simuliert haben, sehen wir also, dass unsere Simulation gut funktioniert. Wir können das Gerüst dieses Simplen Modells jetzt nutzen, um uns noch spannendere Fragestellungen anzuschauen. Zum Beispiel könnten wir untersuchen, ab welcher Stichprobengröße unser Modell genau genug schätzt, oder wir könnten verschiedene Modelle miteinander vergleichen (Rasch vs. 2PL z.B.). Beides kann uns bei der Studienplanung helfen."
  },
  {
    "objectID": "exercises/xPl/xPL.html#gleichung",
    "href": "exercises/xPl/xPL.html#gleichung",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Zuerst müssen wir festlegen, was wir eigentlich simulieren wollen. Wir starten mit einem 2PL Modell. Wie sah die Gleichung dafür noch einmal aus?\n\\[\nP(X_{is} = 1|\\theta_s,\\beta_i,\\alpha_i) = \\frac{\\exp(\\alpha_i(\\theta_s-\\beta_i))}{1 + \\exp(a_i (\\theta_s - \\beta_i))}\n\\tag{1}\\]\n\nVersuche noch einmal, alle Elemente von Gleichung 1 für dich selbst zu erklären.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir versuchen zu schätzen wie hoch die Wahrscheinlichkeit ist, dass eine Person \\(s\\) ein Item \\(i\\) richtig (\\(X_{is} = 1\\)) beantwortet. Dazu nutzen wir den Diskriminationsparameter \\(\\alpha_i\\) und den Schwierigkeitsparameter \\(\\beta_i\\) von Item \\(i\\) und die Personenfähigkeit \\(\\theta_s\\) von Person \\(s\\)."
  },
  {
    "objectID": "exercises/xPl/xPL.html#pl-funktion",
    "href": "exercises/xPl/xPL.html#pl-funktion",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Jetzt beginnt der fun part: Schreibe eine Funktion genannt calc_2pl die Gleichung 1 in R Code umsetzt.\n\n\n\n\n\n\n\nDer Aufbau der Funktion könnte so aussehen:\n\ncalc_2pl &lt;- function(alpha, theta, beta){\n}\n\nBefülle sie nun mit Gleichung 1. alpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Diese Werte können dann im Funktionskörper (zwischen {}) genutzt werden, um Gleichung 1 in R Code zu übersetzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nalpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Im Funktionskörper (zwischen {}) werden sie genutzt, um \\(p\\) anhand von Gleichung 1 zu berechnen."
  },
  {
    "objectID": "exercises/xPl/xPL.html#simulieren-von-daten",
    "href": "exercises/xPl/xPL.html#simulieren-von-daten",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Jetzt geht’s los! Wir wollen nun eigene Daten simulieren. Das tolle ist: wir können so alle Aspekte selber festlegen, und daran untersuchen, wie sich das Variieren von bestimmten Parametern auf das Ergebnis auswirkt.\n\n\nZuerst die Items. Baue einen data.frame mit dem Namen items. Er soll 13 Zeilen und 4 Spalten haben und folgendes enthalten:\n\n\n\nitem_id: Die ID des Items, von 1 bis 13.\n\nalpha: Die Diskriminationsparameter, liegen zwischen 0.5 und 1.5 in 13 gleich langen Schritten.\n\nbeta: Die Schwierigkeitsparameter, liegen zwischen -3 und 3 jeweils im Abstand von 0.5.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDie Funktion seq() ist dein Freund. Mehr brauchst du nicht, um die Zahlenreihen zu erzeugen. Schaue dir die Dokumentation an.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 1.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nDas sind also die Itemparameter, die wir in unsere Simulation packen.\n\n\n\n\nJetzt können wir die Personen simulieren. Unser Ziel ist also ein data.frame, der \\(\\theta\\) Werte für die untersuchten Personen enthält. Wir simulieren 100000 Personen, der data.frame sollte also 100000 Zeilen haben. Außerdem benötigen wir zwei Spalten:\n\n\n\nID: Die ID der Person, von 1 bis 100000.\n\ntheta: Die Fähigkeit der Person, die wir simulieren. Wir nehmen an, dass die Fähigkeit normalverteilt ist, mit einem Mittelwert von 0 und einer Standardabweichung von 1.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWir können zufällige Daten aus einer Normalverteilung mit Hilfe der Funktion rnorm() ziehen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(666) \n## Ich setzte hier einen Seed, damit meine zufällig erzeugten Werte replizierbar bleiben.\n## Wenn du den Seed in deinem Skript auf die gleiche Zahl setzt, bekommst du genau die gleichen Zufallswerte und kannst besser vergleichen. \n\n\nsubjects &lt;- data.frame(\n    sub_id = 1:100000,\n    theta = c(rnorm(100000, 0, 1))\n)\n\n\n\n\nPerfekt! Jetzt können wir die Itemantworten simulieren. Dazu sind noch ein paar kleine Schritte nötig:\n\nMerge die beiden data.frames subjects und items zu einem neuen data.frame sim_dat zusammen. Und zwar so, dass wir \\(1000 * 13\\) Zeilen bekommen, also jede Person jedes der 13 Items zugeordnet wird (bisher noch ohne Antwort der Person, nur mit den Itemkennwerten. Das erleichtert uns im nächsten Schritt, die Antworten der Personen zu simulieren).\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNutze die Funktion merge() ohne irgendwelche weiteren Argumente.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- merge(subjects, items)\n\n## Wir schauen mal, ob das hinkommt:\n\nstr(sim_dat)\n\n'data.frame':   1300000 obs. of  6 variables:\n $ sub_id : int  1 2 3 4 5 6 7 8 9 10 ...\n $ theta  : num  0.753 2.014 -0.355 2.028 -2.217 ...\n $ item_id: int  1 1 1 1 1 1 1 1 1 1 ...\n $ b      : num  -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 ...\n $ a      : num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n $ c      : num  0 0 0 0 0 0 0 0 0 0 ...\n\n\nUnser finaler data.frame hat 1300000 Zeilen, wie verlangt. Lasst uns auch noch einmal schauen, ob eine zufällige Person alle Items beantwortet hat:\n\nsim_dat %&gt;%\n  filter(sub_id == 420) %&gt;%\n  pull(item_id)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n\nDas sieht gut aus!\n\n\n\n\nJetzt simulieren wir aus diesem Vorbereiteten data.frame die Antworten der Personen, abhängig von ihren Fähigkeiten \\(\\theta\\) (jede Person hat hier einen zufälligen Wert aus einer Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 1\\) bekommen) und den Itemparametern \\(\\alpha\\) und \\(\\beta\\) (die hatten wir einfach als Sequenz festgelegt). Lege eine neue Spalte p in sim_dat an, die für jede Person die Wahrscheinlichkeit enthält, dass sie das jeweilige Item richtig beantwortet. Dafür brauchen wir jetzt unsere Funktion calc_2pl, die wir am Anfang definiert haben! Diese nimmt aus jeder Zeile den theta, alpha und beta Wert als input, und berechnet daraus die Wahrscheinlichkeit, dass die Person das Item richtig beantwortet.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSupereinfach geht das ganze mit der mutate() Funktion aus dem tidyverse.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(p = calc_2pl(a, theta, b))\n\n## Mal nachschauen:\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p\n1      1  0.7533110       1 -3 0.5 0 0.8672265\n2      2  2.0143547       1 -3 0.5 0 0.9246434\n3      3 -0.3551345       1 -3 0.5 0 0.7895862\n4      4  2.0281678       1 -3 0.5 0 0.9251233\n5      5 -2.2168745       1 -3 0.5 0 0.5966588\n6      6  0.7583962       1 -3 0.5 0 0.8675190\n\n\nAuf den ersten Blick sieht das schonmal gut aus. Personen mit niedrigerem \\(\\theta\\) Wert haben auch eine geringere Wahrscheinlichkeit, das Item richtig zu beantworten (vgl. z.B. Zeile 2 und 3).\n\n\n\n\nJetzt sind wir auch schon fast am Ende. Wir müssen lediglich aus den Wahrscheinlichkeiten die tatsächlichen Antworten der Personen simulieren. Nutze die Berechneten Antwortwahrscheinlichkeiten p, um für jede Person und jedes Item einen Wert aus einer Bernoulliverteilung zu ziehen.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEine Bernoulliverteilung ist eine Binomialverteilung mit nur einem Versuch. Wir können daher die Funktion rbinom() nutzen, und das size-Argument auf 1 setzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p answer\n1      1  0.7533110       1 -3 0.5 0 0.8672265      1\n2      2  2.0143547       1 -3 0.5 0 0.9246434      1\n3      3 -0.3551345       1 -3 0.5 0 0.7895862      0\n4      4  2.0281678       1 -3 0.5 0 0.9251233      1\n5      5 -2.2168745       1 -3 0.5 0 0.5966588      1\n6      6  0.7583962       1 -3 0.5 0 0.8675190      1\n\n\nAuch das sieht erst einmal plausibel aus! Toll!\n\n\n\n\nJetzt wollen wir natürlich noch schauen, ob das Ganze so funktioniert hat, wie wir uns das vorgestellt haben. Wir wollen das TAM Paket, um ein 2PL Modell auf die Itemantworten zu fitten. Wenn alles geklappt hat, sollten wir in etwa unsere Itemparameter wiedererkennen.\n\nZuerst müssen wir unsere Daten dafür noch ein bisschen aufbereiten, sprich ins Wide-Format bringen. Probiere das also mal aus!\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIch nutze dafür immer deutlich lieber die tidyverse Funktion pivot_wider() als die base-R Funtkion reshape().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = sub_id)\n\nhead(sim_dat_wide)\n\n# A tibble: 6 × 14\n  sub_id   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`  `10`  `11`  `12`\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1      1     1     1     1     1     1     0     1     0     1     1     0     0\n2      2     1     1     1     1     1     1     1     1     1     1     1     0\n3      3     0     1     1     1     0     0     0     0     0     1     0     0\n4      4     1     1     1     1     1     1     1     1     0     0     0     0\n5      5     1     1     0     1     0     0     0     0     0     0     0     0\n6      6     1     1     0     1     1     1     0     0     0     0     0     0\n# ℹ 1 more variable: `13` &lt;int&gt;\n\n\nDie Spaltennamen sind jetzt unsere Item-Nummern. Pro Zeile finden sich die Antworten der Personen, entweder hat sie das entsprechende Item richtig (1) oder falsch (0) beantwortet.\n\n\n\n\nJetzt können wir das Modell fitten. Nutze dafür wie angekündigt das TAM Paket, und entferne noch die Spalte sub_id, wir geben nur die Itemantworten in die Funktion. Speichere den Funktionsoutput in dem Object sim_dat_2PL.\n\n\n\n\n\n\n\nWir brauchen die Funktion tam.mml.2pl().\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsim_dat_2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"2PL\")\n\n....................................................\nProcessing Data      2024-10-07 10:05:31.649142 \n    * Response Data: 100000 Persons and  13 Items \n    * Numerical integration with 21 nodes\n    * Created Design Matrices   ( 2024-10-07 10:05:31.838423 )\n    * Calculated Sufficient Statistics   ( 2024-10-07 10:05:32.106954 )\n....................................................\nIteration 1     2024-10-07 10:05:32.147749\nE Step\nM Step Intercepts   |----\nM Step Slopes       |---\n  Deviance = 1267150.8426\n  Maximum item intercept parameter change: 0.419556\n  Maximum item slope parameter change: 0.209449\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 2     2024-10-07 10:05:32.380107\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1256572.3453 | Absolute change: 10578.5 | Relative change: 0.00841853\n  Maximum item intercept parameter change: 0.142116\n  Maximum item slope parameter change: 0.13129\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 3     2024-10-07 10:05:32.619823\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1255075.8194 | Absolute change: 1496.526 | Relative change: 0.00119238\n  Maximum item intercept parameter change: 0.085173\n  Maximum item slope parameter change: 0.070548\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 4     2024-10-07 10:05:32.864377\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254560.5132 | Absolute change: 515.3062 | Relative change: 0.00041075\n  Maximum item intercept parameter change: 0.064561\n  Maximum item slope parameter change: 0.041601\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 5     2024-10-07 10:05:32.987871\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254359.2843 | Absolute change: 201.2289 | Relative change: 0.00016042\n  Maximum item intercept parameter change: 0.050987\n  Maximum item slope parameter change: 0.030886\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 6     2024-10-07 10:05:33.103148\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254269.9949 | Absolute change: 89.2894 | Relative change: 7.119e-05\n  Maximum item intercept parameter change: 0.04019\n  Maximum item slope parameter change: 0.023359\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 7     2024-10-07 10:05:33.240256\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254226.1047 | Absolute change: 43.8902 | Relative change: 3.499e-05\n  Maximum item intercept parameter change: 0.031482\n  Maximum item slope parameter change: 0.017898\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 8     2024-10-07 10:05:33.467036\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254203.2462 | Absolute change: 22.8585 | Relative change: 1.823e-05\n  Maximum item intercept parameter change: 0.02456\n  Maximum item slope parameter change: 0.013847\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 9     2024-10-07 10:05:33.580888\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254191.0072 | Absolute change: 12.239 | Relative change: 9.76e-06\n  Maximum item intercept parameter change: 0.019126\n  Maximum item slope parameter change: 0.01079\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 10     2024-10-07 10:05:33.694889\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254184.3636 | Absolute change: 6.6436 | Relative change: 5.3e-06\n  Maximum item intercept parameter change: 0.014893\n  Maximum item slope parameter change: 0.008455\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 11     2024-10-07 10:05:33.826551\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254180.7248 | Absolute change: 3.6388 | Relative change: 2.9e-06\n  Maximum item intercept parameter change: 0.011608\n  Maximum item slope parameter change: 0.006653\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 12     2024-10-07 10:05:34.0218\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254178.7154 | Absolute change: 2.0093 | Relative change: 1.6e-06\n  Maximum item intercept parameter change: 0.009062\n  Maximum item slope parameter change: 0.005253\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 13     2024-10-07 10:05:34.142448\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254177.5963 | Absolute change: 1.1192 | Relative change: 8.9e-07\n  Maximum item intercept parameter change: 0.007088\n  Maximum item slope parameter change: 0.004157\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 14     2024-10-07 10:05:34.266304\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.967 | Absolute change: 0.6293 | Relative change: 5e-07\n  Maximum item intercept parameter change: 0.005555\n  Maximum item slope parameter change: 0.003297\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 15     2024-10-07 10:05:34.380882\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.6097 | Absolute change: 0.3573 | Relative change: 2.8e-07\n  Maximum item intercept parameter change: 0.004363\n  Maximum item slope parameter change: 0.002619\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 16     2024-10-07 10:05:34.510906\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.4047 | Absolute change: 0.205 | Relative change: 1.6e-07\n  Maximum item intercept parameter change: 0.003433\n  Maximum item slope parameter change: 0.002083\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 17     2024-10-07 10:05:34.718183\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.286 | Absolute change: 0.1188 | Relative change: 9e-08\n  Maximum item intercept parameter change: 0.002706\n  Maximum item slope parameter change: 0.001658\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 18     2024-10-07 10:05:34.83199\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.2165 | Absolute change: 0.0695 | Relative change: 6e-08\n  Maximum item intercept parameter change: 0.002137\n  Maximum item slope parameter change: 0.001321\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 19     2024-10-07 10:05:34.94643\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1755 | Absolute change: 0.041 | Relative change: 3e-08\n  Maximum item intercept parameter change: 0.00169\n  Maximum item slope parameter change: 0.001053\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 20     2024-10-07 10:05:35.059214\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1511 | Absolute change: 0.0244 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.001338\n  Maximum item slope parameter change: 0.00084\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 21     2024-10-07 10:05:35.173408\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1364 | Absolute change: 0.0146 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.001061\n  Maximum item slope parameter change: 0.00067\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 22     2024-10-07 10:05:35.308891\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1276 | Absolute change: 0.0088 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000842\n  Maximum item slope parameter change: 0.000535\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 23     2024-10-07 10:05:35.50356\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1222 | Absolute change: 0.0054 | Relative change: 0\n  Maximum item intercept parameter change: 0.000669\n  Maximum item slope parameter change: 0.000427\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 24     2024-10-07 10:05:35.62626\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1189 | Absolute change: 0.0033 | Relative change: 0\n  Maximum item intercept parameter change: 0.000532\n  Maximum item slope parameter change: 0.000341\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 25     2024-10-07 10:05:35.742111\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1169 | Absolute change: 0.002 | Relative change: 0\n  Maximum item intercept parameter change: 0.000423\n  Maximum item slope parameter change: 0.000272\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 26     2024-10-07 10:05:35.951754\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1156 | Absolute change: 0.0012 | Relative change: 0\n  Maximum item intercept parameter change: 0.000337\n  Maximum item slope parameter change: 0.000218\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 27     2024-10-07 10:05:36.068103\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1149 | Absolute change: 8e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000268\n  Maximum item slope parameter change: 0.000174\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 28     2024-10-07 10:05:36.184109\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1144 | Absolute change: 5e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000214\n  Maximum item slope parameter change: 0.000139\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 29     2024-10-07 10:05:36.304893\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1141 | Absolute change: 3e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.00017\n  Maximum item slope parameter change: 0.000111\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 30     2024-10-07 10:05:36.43922\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1139 | Absolute change: 2e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000136\n  Maximum item slope parameter change: 8.9e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 31     2024-10-07 10:05:36.654303\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1138 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000108\n  Maximum item slope parameter change: 7.1e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 32     2024-10-07 10:05:36.777484\nE Step\nM Step Intercepts   |-\nM Step Slopes       |-\n  Deviance = 1254176.1137 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 8.6e-05\n  Maximum item slope parameter change: 5.7e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nItem Parameters\n   xsi.index xsi.label     est\n1          1         1 -1.5085\n2          2         2 -1.4816\n3          3         3 -1.3370\n4          4         4 -1.1347\n5          5         5 -0.8444\n6          6         6 -0.4600\n7          7         7 -0.0038\n8          8         8  0.5308\n9          9         9  1.1642\n10        10        10  1.8783\n11        11        11  2.6740\n12        12        12  3.4901\n13        13        13  4.4630\n...................................\nRegression Coefficients\n     [,1]\n[1,]    0\n\nVariance:\n     [,1]\n[1,]    1\n\n\nEAP Reliability:\n[1] 0.626\n\n-----------------------------\nStart:  2024-10-07 10:05:31.6458\nEnd:  2024-10-07 10:05:37.142358 \nTime difference of 5.496558 secs\n\n\n\n\n\n\nSchau dir die Itemparameter an, die das Modell geschätzt hat. Sie finden sich unter sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")]. Vergleiche mit den ursprünglichen Itemparametern, die wir in items festgelegt haben. Was fällt dir auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems_2pl &lt;- apply(sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\nitem_comparison &lt;- cbind(items_2pl, items[, c(\"a\", \"b\")])\n\nitem_comparison\n\n   alpha  beta         a    b\n1   0.52 -2.92 0.5000000 -3.0\n2   0.59 -2.53 0.5833333 -2.5\n3   0.66 -2.04 0.6666667 -2.0\n4   0.75 -1.52 0.7500000 -1.5\n5   0.84 -1.01 0.8333333 -1.0\n6   0.92 -0.50 0.9166667 -0.5\n7   1.00  0.00 1.0000000  0.0\n8   1.09  0.49 1.0833333  0.5\n9   1.17  1.00 1.1666667  1.0\n10  1.24  1.52 1.2500000  1.5\n11  1.35  1.97 1.3333333  2.0\n12  1.38  2.52 1.4166667  2.5\n13  1.47  3.03 1.5000000  3.0\n\n\n\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nggplot(data=item_comparison, \n       aes(x = b, y = beta)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() + ## Ein anderes Theme festlegen\n  xlab(TeX(\"\\\\beta\")) + ## Latex Syntax für die Achsenbeschriftung nutzen\n  ylab(TeX(\"\\\\hat{\\\\beta}\"))\n\n\n\n\n\n\n\n\nggplot(data=item_comparison, \n       aes(x = a, y = alpha)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() +\n  xlab(TeX(\"\\\\alpha\")) +\n  ylab(TeX(\"\\\\hat{\\\\alpha}\"))\n\n\n\n\n\n\n\nDas sieht super aus, die Werte stimmen gut überein. Dadurch, dass wir so viele Personen simuliert haben, sehen wir also, dass unsere Simulation gut funktioniert. Wir können das Gerüst dieses Simplen Modells jetzt nutzen, um uns noch spannendere Fragestellungen anzuschauen. Zum Beispiel könnten wir untersuchen, ab welcher Stichprobengröße unser Modell genau genug schätzt, oder wir könnten verschiedene Modelle miteinander vergleichen (Rasch vs. 2PL z.B.). Beides kann uns bei der Studienplanung helfen."
  },
  {
    "objectID": "exercises/intro_r/load_data_ex.html",
    "href": "exercises/intro_r/load_data_ex.html",
    "title": "Einlesen von Daten",
    "section": "",
    "text": "Erstelle einen neuen Ordner data in deinem Arbeitsverzeichnis. Gehe dann auf GitHub, downloade die beiden Datensätze psych_stats.csv und characters.rds, und speichere sie in deinem neu erstellen data Ordner ab.\n\nZum Downloaden von GitHub, klicke auf die Datei. Es öffnet sich eine neue Seite, auf der du oben rechts den Button “Download” findest.\n\n\nLies beide Datensätze in deinem R-Skript ein. Schaue dir vor allem den psych_stats Datensatz danach genauer an. Hat alles geklappt? Wenn nicht, woran könnte es liegen?\n\n\n\n\n\n\nTipp 1\n\n\n\n\n\nEs handelt sich um eine .rds-Datei und eine .csv-Datei.\n\n\n\n\n\n\n\n\n\nTipp 2\n\n\n\n\n\nÖffne die .csv-Datei und schaue nach, durch welches Zeichen die Werte getrennt sind. Nutze das sep Argument in read.csv!\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Einlesen von Daten"
    ]
  },
  {
    "objectID": "exercises/intro_r/load_data_ex.html#download",
    "href": "exercises/intro_r/load_data_ex.html#download",
    "title": "Einlesen von Daten",
    "section": "",
    "text": "Erstelle einen neuen Ordner data in deinem Arbeitsverzeichnis. Gehe dann auf GitHub, downloade die beiden Datensätze psych_stats.csv und characters.rds, und speichere sie in deinem neu erstellen data Ordner ab.\n\nZum Downloaden von GitHub, klicke auf die Datei. Es öffnet sich eine neue Seite, auf der du oben rechts den Button “Download” findest.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Einlesen von Daten"
    ]
  },
  {
    "objectID": "exercises/intro_r/load_data_ex.html#einlesen",
    "href": "exercises/intro_r/load_data_ex.html#einlesen",
    "title": "Einlesen von Daten",
    "section": "",
    "text": "Lies beide Datensätze in deinem R-Skript ein. Schaue dir vor allem den psych_stats Datensatz danach genauer an. Hat alles geklappt? Wenn nicht, woran könnte es liegen?\n\n\n\n\n\n\nTipp 1\n\n\n\n\n\nEs handelt sich um eine .rds-Datei und eine .csv-Datei.\n\n\n\n\n\n\n\n\n\nTipp 2\n\n\n\n\n\nÖffne die .csv-Datei und schaue nach, durch welches Zeichen die Werte getrennt sind. Nutze das sep Argument in read.csv!\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Einlesen von Daten"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html",
    "href": "exercises/intro_r/reshaping_ex.html",
    "title": "Reshaping",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html#exercise-1",
    "href": "exercises/intro_r/reshaping_ex.html#exercise-1",
    "title": "Reshaping",
    "section": "Exercise 1",
    "text": "Exercise 1\nTake a look at the data frame psych_stats. Which format does it have?\n\nWide format\nLong format\nNone of the above\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nWide format\nLong format\nNone of the above\n\nEach unit of observation, in this case each character, only has one row.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html#exercise-2",
    "href": "exercises/intro_r/reshaping_ex.html#exercise-2",
    "title": "Reshaping",
    "section": "Exercise 2",
    "text": "Exercise 2\nReshape it, so there are only three columns in the data set: char_id, question and rating.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can select multiple columns like this: column_1:column_10.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\npsych_stats &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\nhead(psych_stats)\n\n# A tibble: 6 × 3\n  char_id question                      rating\n  &lt;chr&gt;   &lt;chr&gt;                          &lt;dbl&gt;\n1 F2      messy_neat                     95.7 \n2 F2      disorganized_self.disciplined  95.2 \n3 F2      diligent_lazy                   6.10\n4 F2      on.time_tardy                   6.2 \n5 F2      competitive_cooperative         6.40\n6 F2      scheduled_spontaneous           6.60\n\n\nNow we have multiple rows for every character, but all question ratings are nicely aligned in one column.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html#exercise-3",
    "href": "exercises/intro_r/reshaping_ex.html#exercise-3",
    "title": "Reshaping",
    "section": "Exercise 3",
    "text": "Exercise 3\nTry to reshape the data into long format again.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\npsych_stats %&gt;%\n  pivot_wider(id_cols = char_id, \n               names_from = \"question\", \n               values_from = \"rating\")\n\n# A tibble: 889 × 365\n   char_id messy_neat disorganized_self.disciplined diligent_lazy on.time_tardy\n   &lt;chr&gt;        &lt;dbl&gt;                         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 F2           95.7                           95.2          6.10           6.2\n 2 F1           30.2                           25.9         51.8           77.9\n 3 F5           45.3                           42.4         52.2           57.1\n 4 F4           13                             11           78.1           84.1\n 5 F3           20.9                           20.9         45.2           74  \n 6 F6           81                             75.6         20             20.6\n 7 EU1           9.60                          10.4         62.3           85.7\n 8 EU2          27.7                           31.9         23.7           68.3\n 9 EU6          40                             39.6         54.1           73.6\n10 EU3          43.9                           31.1         32.2           58.2\n# ℹ 879 more rows\n# ℹ 360 more variables: competitive_cooperative &lt;dbl&gt;,\n#   scheduled_spontaneous &lt;dbl&gt;, ADHD_OCD &lt;dbl&gt;, chaotic_orderly &lt;dbl&gt;,\n#   motivated_unmotivated &lt;dbl&gt;, bossy_meek &lt;dbl&gt;, persistent_quitter &lt;dbl&gt;,\n#   overachiever_underachiever &lt;dbl&gt;, muddy_washed &lt;dbl&gt;, beautiful_ugly &lt;dbl&gt;,\n#   slacker_workaholic &lt;dbl&gt;, driven_unambitious &lt;dbl&gt;, outlaw_sheriff &lt;dbl&gt;,\n#   precise_vague &lt;dbl&gt;, bad.cook_good.cook &lt;dbl&gt;, manicured_scruffy &lt;dbl&gt;, …\n\n\nThis is how we got it! But scratch that, it was just for the sake of the exercise. We want to use psych_stats in the long format from now on.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/missings_ex.html",
    "href": "exercises/intro_r/missings_ex.html",
    "title": "Missings",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n\n\n\n\n\nDoes the characters data set contain any NAs?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse any() to see if a logical vector contains any TRUE values.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nany(is.na(characters))\n\n[1] FALSE\n\n\nNo, there don’t seem to be any NAs in this data set, which would be great in real life. For this exercise it’s not great, so let’s introduce some NAs manually.\n\n\n\n\nBe careful not to overwrite the characters data frame, so copy it into the new object characters_na before doing anything. Then set the name to NA in the rows 34, 103, 300 and the uni_name to NA in the rows 404, 670.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo overwrite values, you can select them on the left side of the assignment operator &lt;- and assign them a new value on the right side.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters\n\ncharacters_na[c(34, 103, 300), \"name\"] &lt;- NA\ncharacters_na[c(404, 670), \"uni_name\"] &lt;- NA\n\n\n\n\n\nRemove all rows containing missing values in the column name from the characters_na data frame.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters_na[!is.na(characters_na$name), ]\n\nOr:\n\n\nlibrary(tidyverse)\n\ncharacters_na &lt;- characters_na %&gt;%\n  drop_na(name)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Missings"
    ]
  },
  {
    "objectID": "exercises/intro_r/missings_ex.html#exercise-1",
    "href": "exercises/intro_r/missings_ex.html#exercise-1",
    "title": "Missings",
    "section": "",
    "text": "Does the characters data set contain any NAs?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse any() to see if a logical vector contains any TRUE values.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nany(is.na(characters))\n\n[1] FALSE\n\n\nNo, there don’t seem to be any NAs in this data set, which would be great in real life. For this exercise it’s not great, so let’s introduce some NAs manually.\n\n\n\n\nBe careful not to overwrite the characters data frame, so copy it into the new object characters_na before doing anything. Then set the name to NA in the rows 34, 103, 300 and the uni_name to NA in the rows 404, 670.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo overwrite values, you can select them on the left side of the assignment operator &lt;- and assign them a new value on the right side.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters\n\ncharacters_na[c(34, 103, 300), \"name\"] &lt;- NA\ncharacters_na[c(404, 670), \"uni_name\"] &lt;- NA\n\n\n\n\n\nRemove all rows containing missing values in the column name from the characters_na data frame.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters_na[!is.na(characters_na$name), ]\n\nOr:\n\n\nlibrary(tidyverse)\n\ncharacters_na &lt;- characters_na %&gt;%\n  drop_na(name)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Missings"
    ]
  },
  {
    "objectID": "slides/IntroR/introR.html#überblick",
    "href": "slides/IntroR/introR.html#überblick",
    "title": "Einführung in R",
    "section": "Überblick",
    "text": "Überblick\n\nArbeiten mit R und RStudio\nGrundlegende Operationen in R: Daten laden, Pakete installieren …\nDatenmanipulation und Transformation in R\n\n\n\n\n\n\n\nZiel\n\n\nAm Ende der Session solltet ihr mit den Grundlagen in R vertraut sein, sodass ihr den Rest des Workshops in R bestreiten könnt."
  },
  {
    "objectID": "slides/IntroR/introR.html#section",
    "href": "slides/IntroR/introR.html#section",
    "title": "Einführung in R",
    "section": "",
    "text": "RStudio Interface"
  },
  {
    "objectID": "slides/IntroR/introR.html#section-1",
    "href": "slides/IntroR/introR.html#section-1",
    "title": "Einführung in R",
    "section": "",
    "text": "Beim ersten Öffnen wird RStudio in etwa so aussehen:"
  },
  {
    "objectID": "slides/IntroR/introR.html#section-2",
    "href": "slides/IntroR/introR.html#section-2",
    "title": "Einführung in R",
    "section": "",
    "text": "Das Fenster hat 4 Bereiche:"
  },
  {
    "objectID": "slides/IntroR/introR.html#script-pane",
    "href": "slides/IntroR/introR.html#script-pane",
    "title": "Einführung in R",
    "section": "1) Script Pane",
    "text": "1) Script Pane\nEditieren von Skripten (Datein, in denen Code gespeichert wird) und ausführen von Code (crtl + enter (Windows) oder command + return (macOS).\n\n# Our first line of code:\nprint(\"Hello World!\")\n\n[1] \"Hello World!\"\n\n\n\n\n\n\n\n\nÜbrigens: Codezeilen, die mit einem # beginnen, sind auskommentiert und werden nicht ausgewertet."
  },
  {
    "objectID": "slides/IntroR/introR.html#console",
    "href": "slides/IntroR/introR.html#console",
    "title": "Einführung in R",
    "section": "2) Console",
    "text": "2) Console\nHier erscheint der Output aus unseren Skripten. Wir können auch direkt in der Konsole arbeiten und Befehle mit enter ausführen:\n\n10 + 5\n\n[1] 15\n\n\n\n\n\n\n\n\nHier geschriebener Code wird nicht gespeichert. Nutze die Konsole also, um Dinge auszuprobieren, schreibe aber alles Wichtige in Skripte."
  },
  {
    "objectID": "slides/IntroR/introR.html#workspace",
    "href": "slides/IntroR/introR.html#workspace",
    "title": "Einführung in R",
    "section": "3) Workspace",
    "text": "3) Workspace\nIm Environment-Tab erhalten wir einen Überblick über die Objekte, die derzeit in unserer R-Sitzung geladen sind.\nWir können auch den Befehlsverlauf einsehen und einige weitere Dinge, die wir jetzt nicht benötigen."
  },
  {
    "objectID": "slides/IntroR/introR.html#plots-datein-hilfe",
    "href": "slides/IntroR/introR.html#plots-datein-hilfe",
    "title": "Einführung in R",
    "section": "4) Plots, Datein, Hilfe …",
    "text": "4) Plots, Datein, Hilfe …\nPlots, die wir in einer R-Sitzung erstellen, werden im Plot-Tab ausgegeben.\nBeim Aufrufen der Hilfefunktion öffnet sich die Dokumentation im Hilfe-Tab.\n\n\n\n\n\n\nHilfe in R\n\n\nDie Dokumentation kann mit ?funktionsname aufgerufen werden. Das ist eines der wichtigsten Werkzeuge bei der Arbeit in R.\n\n\n\nDer Dateien-Tab ermöglicht es uns, die Dateien in unserem Arbeitsverzeichnis zu verwalten."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-3",
    "href": "slides/IntroR/introR.html#section-3",
    "title": "Einführung in R",
    "section": "",
    "text": "Los Geht’s!"
  },
  {
    "objectID": "slides/IntroR/introR.html#grundlegende-operationen",
    "href": "slides/IntroR/introR.html#grundlegende-operationen",
    "title": "Einführung in R",
    "section": "Grundlegende Operationen",
    "text": "Grundlegende Operationen\n\n\nc(): Vektor erstellen\n\nseq() oder :: Sequenzen erstellen\n\n&, |, !: Logische Operatoren (und, oder, nicht)"
  },
  {
    "objectID": "slides/IntroR/introR.html#datenstrukturen",
    "href": "slides/IntroR/introR.html#datenstrukturen",
    "title": "Einführung in R",
    "section": "Datenstrukturen:",
    "text": "Datenstrukturen:\n\n\n\nHomogeneous\nHeterogeneous\n\n\n\n1d\natomic vector\nlist\n\n\n2d\nmatrix\ndata.frame\n\n\nnd\narray\n\n\n\n\n\n\nTabelle aus Advanced R."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-4",
    "href": "slides/IntroR/introR.html#section-4",
    "title": "Einführung in R",
    "section": "",
    "text": "Basic Setup"
  },
  {
    "objectID": "slides/IntroR/introR.html#rstudio-projekte",
    "href": "slides/IntroR/introR.html#rstudio-projekte",
    "title": "Einführung in R",
    "section": "RStudio Projekte",
    "text": "RStudio Projekte\nHilft ungemein beim Organisieren von Dateien und Code!\n\n\n\n\n\n\nÜbung\n\n\nErstelle einen neuen Ordner (falls noch nicht getan) für diesen Workshop, und lege darin ein RStudio Projekt an (File - New Project)."
  },
  {
    "objectID": "slides/IntroR/introR.html#skripte",
    "href": "slides/IntroR/introR.html#skripte",
    "title": "Einführung in R",
    "section": "Skripte",
    "text": "Skripte\nHier kommt der Code rein!\n\n\n\n\n\n\nÜbung\n\n\nErstelle einen neuen Unterordner und lege darin ein R-Skript and (File - New File - R Script). In diesen kommen dann die Übungsaufgaben und Notizen aus dem Workshop. Leg am besten für jedes Thema ein eigenes Skript an, damit sie übersichtlich bleiben."
  },
  {
    "objectID": "slides/IntroR/introR.html#pakete",
    "href": "slides/IntroR/introR.html#pakete",
    "title": "Einführung in R",
    "section": "Pakete",
    "text": "Pakete\n\n\nPakete sind Erweiterungen zum base R und funktionieren ein bisschen wie Apps im Playstore:\n\n\n Einmalig installieren:\n\n\ninstall.packages(\"packagename\")\n\n\n\n Bei jeder Nutzung in die R-Session laden:\n\n\nlibrary(packagename)"
  },
  {
    "objectID": "slides/IntroR/introR.html#tidyverse",
    "href": "slides/IntroR/introR.html#tidyverse",
    "title": "Einführung in R",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\n\nVerbreitete Paketsammlung in R für so ziemlich jede Stufe der Datenauswertung. Der meiste Code den wird schreiben wird wahrscheinlich aus einer Mischung aus base R und tidyverse bestehen."
  },
  {
    "objectID": "slides/IntroR/introR.html#tidyverse-pipe-operator",
    "href": "slides/IntroR/introR.html#tidyverse-pipe-operator",
    "title": "Einführung in R",
    "section": "\ntidyverse: Pipe Operator",
    "text": "tidyverse: Pipe Operator\n%&gt;%\n\nsum(seq(from = 1, to = mean(c(45:100), na.rm = TRUE), by = 0.1))\n\n[1] 26313\n\n\nwird zu:\n\nlibrary(tidyverse)\n\nc(45:100) %&gt;%\n  mean(na.rm = TRUE) %&gt;%\n  seq(from = 1, to = ., by = 0.1) %&gt;%\n  sum\n\n[1] 26313"
  },
  {
    "objectID": "slides/IntroR/introR.html#section-5",
    "href": "slides/IntroR/introR.html#section-5",
    "title": "Einführung in R",
    "section": "",
    "text": "Daten und Pfade"
  },
  {
    "objectID": "slides/IntroR/introR.html#einlesen-von-daten",
    "href": "slides/IntroR/introR.html#einlesen-von-daten",
    "title": "Einführung in R",
    "section": "Einlesen von Daten",
    "text": "Einlesen von Daten\n\n\n\n\n\n\n\n\n\n\nData type\nImport\nExport\n\n\n\nR objects (.Rdata, .rda)\nload()\nsave()\n\n\nsingle R object (.rds)\nreadRDS()\nsaveRDS()\n\n\ntext-files (.txt)\nread.table()\nwrite.table()\n\n\n.csv-files (.csv)\nread.csv()\nwrite.csv()\n\n\nExcel-files (.xlsx)\nreadxl::read_excel()\nwritexl::write_xlsx()\n\n\nSPSS-files (.sav)\nhaven::read_sav()\nhaven::write_sav()\n\n\nSAS-files (.sas)\nhaven::read_sas()\nhaven::write_sas()\n\n\nStata-files (.stata)\nhaven::read_dta()\nhaven::write_dta()"
  },
  {
    "objectID": "slides/IntroR/introR.html#exkurs-here-paket",
    "href": "slides/IntroR/introR.html#exkurs-here-paket",
    "title": "Einführung in R",
    "section": "Exkurs: here-Paket",
    "text": "Exkurs: here-Paket\nhere ist ein Paket zum Erstellen von Dateipfaden. Dadurch können Probleme mit relativen und absoluten Pfaden vermieden werden.\nC:\\Users\\hafiznij\\Documents\\GitHub\\IRT_workshop\\raw_data\\athletes.rds wird zu:here::here(\"raw_data\", \"athletes.rds\").\nAlso:\n\n# install.packages(\"here\")\nathletes &lt;- readRDS(here::here(\"raw_data\", \"athletes.rds\"))"
  },
  {
    "objectID": "slides/IntroR/introR.html#einlesen-von-daten-1",
    "href": "slides/IntroR/introR.html#einlesen-von-daten-1",
    "title": "Einführung in R",
    "section": "Einlesen von Daten",
    "text": "Einlesen von Daten\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übung zum Einlesen von Daten."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-7",
    "href": "slides/IntroR/introR.html#section-7",
    "title": "Einführung in R",
    "section": "",
    "text": "Datenmanipulation und Transformation"
  },
  {
    "objectID": "slides/IntroR/introR.html#section-8",
    "href": "slides/IntroR/introR.html#section-8",
    "title": "Einführung in R",
    "section": "",
    "text": "Einen Überblick bekommen"
  },
  {
    "objectID": "slides/IntroR/introR.html#view",
    "href": "slides/IntroR/introR.html#view",
    "title": "Einführung in R",
    "section": "View()",
    "text": "View()\n\n\nÖffnet den Datensatz in einem neuem Fenster:\n\nView(athletes)"
  },
  {
    "objectID": "slides/IntroR/introR.html#str",
    "href": "slides/IntroR/introR.html#str",
    "title": "Einführung in R",
    "section": "str()",
    "text": "str()\n\nStruktur der Daten:\n\n\nstr(athletes)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: int  NA NA 163 NA NA 168 NA NA NA NA ...\n $ Weight: num  NA NA 57 NA 74 73 NA NA 57 NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ..."
  },
  {
    "objectID": "slides/IntroR/introR.html#head",
    "href": "slides/IntroR/introR.html#head",
    "title": "Einführung in R",
    "section": "head()",
    "text": "head()\n\nErste Zeilen:\n\n\nhead(athletes)\n\n  NOC     ID                  Name Sex Age Height Weight        Team\n1 AFG 132181           Najam Yahya   M  NA     NA     NA Afghanistan\n2 AFG  87371 Ahmad Jahan Nuristani   M  NA     NA     NA Afghanistan\n3 AFG  44977     Mohammad Halilula   M  28    163     57 Afghanistan\n4 AFG    502     Ahmad Shah Abouwi   M  NA     NA     NA Afghanistan\n5 AFG 109153    Shakar Khan Shakar   M  24     NA     74 Afghanistan\n6 AFG  29626  Sultan Mohammad Dost   M  28    168     73 Afghanistan\n        Games Year Season      City     Sport\n1 1956 Summer 1956 Summer Melbourne    Hockey\n2 1948 Summer 1948 Summer    London    Hockey\n3 1980 Summer 1980 Summer    Moskva Wrestling\n4 1956 Summer 1956 Summer Melbourne    Hockey\n5 1964 Summer 1964 Summer     Tokyo Wrestling\n6 1960 Summer 1960 Summer      Roma Wrestling\n                                    Event Medal      Region\n1                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n2                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n3 Wrestling Men's Bantamweight, Freestyle  &lt;NA&gt; Afghanistan\n4                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n5 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n6 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan"
  },
  {
    "objectID": "slides/IntroR/introR.html#einen-überblick-bekommen-übung",
    "href": "slides/IntroR/introR.html#einen-überblick-bekommen-übung",
    "title": "Einführung in R",
    "section": "Einen Überblick bekommen: Übung",
    "text": "Einen Überblick bekommen: Übung\n\n\n\n\n\n\nÜbung 1\n\n\nWie viele Zeilen und Spalten hat der in der letzten Übung eingelesene Datensatz characters?\n\n\n\n\n\n\n\n\n\nÜbung 2\n\n\nAus welcher Show stammen die ersten Charactere im Datensatz?"
  },
  {
    "objectID": "slides/IntroR/introR.html#einfaches-subsetting",
    "href": "slides/IntroR/introR.html#einfaches-subsetting",
    "title": "Einführung in R",
    "section": "Einfaches Subsetting",
    "text": "Einfaches Subsetting\n\n\n# Auswahl der Spalten\nathletes[c(1,4), c(\"Year\", \"Sport\")]\n\n  Year  Sport\n1 1956 Hockey\n4 1956 Hockey"
  },
  {
    "objectID": "slides/IntroR/introR.html#konditionales-subsetting",
    "href": "slides/IntroR/introR.html#konditionales-subsetting",
    "title": "Einführung in R",
    "section": "Konditionales Subsetting",
    "text": "Konditionales Subsetting\n\nathletes_de &lt;- athletes[athletes$Team == \"Germany\", ]\nhead(athletes_de)\n\n       NOC     ID                   Name Sex Age Height Weight    Team\n107246 GER   7385     Dirk Peter Balster   M  26    195     90 Germany\n107247 GER 114424 Kathleen Stark (-Kern)   F  16    166     51 Germany\n...\n\n\nAlle Zeilen, in denen Team gleich Germany ist.\n\n\n\n\n\n\nWas passiert hier genau?\n\n\nWir erzeugen einen Boolean Vektor (besteht aus TRUE und FALSE), der anzeigt, welche Zeilen ausgewählt werden sollen:\n\nathletes$Team == \"Germany\"\n\n    [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n...\n\n\nDieser indiziert dann die Zeilen, die ausgewählt werden sollen."
  },
  {
    "objectID": "slides/IntroR/introR.html#komplexes-konditionales-subsetting",
    "href": "slides/IntroR/introR.html#komplexes-konditionales-subsetting",
    "title": "Einführung in R",
    "section": "Komplexes konditionales Subsetting",
    "text": "Komplexes konditionales Subsetting\nDiese Prinzip können wir uns zu Nutze machen, um mehrere Bedingungen zu verknüpfen:\n\nathletes_3 &lt;- athletes[(athletes$Sport == \"Judo\") & (athletes$Weight &gt; 100 | athletes$Weight &lt; 50), ]\nhead(athletes_3)\n\n      NOC    ID                Name  Sex Age Height Weight    Team       Games\nNA   &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.1 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.2 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.3 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\n471   ALG 13895 Mohamed Bouaichaoui    M  25    178    120 Algeria 2004 Summer\n...\n\n\n\n\n\n\n\n\nNA\n\n\nViele der Zeilen enthalten nur NA Werte. Das schauen wir uns gleich im Kapitel Kapitel 1.7 genauer an."
  },
  {
    "objectID": "slides/IntroR/introR.html#subsetting-zeilen-tidyverse",
    "href": "slides/IntroR/introR.html#subsetting-zeilen-tidyverse",
    "title": "Einführung in R",
    "section": "Subsetting Zeilen: Tidyverse\n",
    "text": "Subsetting Zeilen: Tidyverse\n\n\nlibrary(tidyverse)\n\nathletes %&gt;%\n  filter(Sport == \"Judo\", (Weight &gt; 100 | Weight &lt; 50)) %&gt;%\n  head\n\n  NOC    ID                   Name Sex Age Height Weight      Team       Games\n1 ALG 13895    Mohamed Bouaichaoui   M  25    178    120   Algeria 2004 Summer\n2 ALG 82643          Meriem Moussa   F  20    150     48   Algeria 2008 Summer\n3 ALG 80035        Boualem Miloudi   M  23    192    106   Algeria 1988 Summer\n...\n\n\n\n\n\n\n\n\nNA\n\n\nHier werden NA Werte automatisch ignoriert."
  },
  {
    "objectID": "slides/IntroR/introR.html#subsetting-spalten-tidyverse",
    "href": "slides/IntroR/introR.html#subsetting-spalten-tidyverse",
    "title": "Einführung in R",
    "section": "Subsetting Spalten: Tidyverse\n",
    "text": "Subsetting Spalten: Tidyverse\n\n\nathletes %&gt;%\n  select(Year, Sport) %&gt;%\n  head\n\n  Year     Sport\n1 1956    Hockey\n2 1948    Hockey\n3 1980 Wrestling\n4 1956    Hockey\n5 1964 Wrestling\n6 1960 Wrestling"
  },
  {
    "objectID": "slides/IntroR/introR.html#übung-3",
    "href": "slides/IntroR/introR.html#übung-3",
    "title": "Einführung in R",
    "section": "Übung",
    "text": "Übung\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übungen zum Subsetting."
  },
  {
    "objectID": "slides/IntroR/introR.html#sec-missings",
    "href": "slides/IntroR/introR.html#sec-missings",
    "title": "Einführung in R",
    "section": "Fehlende Werte",
    "text": "Fehlende Werte\n\nNA"
  },
  {
    "objectID": "slides/IntroR/introR.html#arbeit-mit-fehlenden-werten",
    "href": "slides/IntroR/introR.html#arbeit-mit-fehlenden-werten",
    "title": "Einführung in R",
    "section": "Arbeit mit fehlenden Werten",
    "text": "Arbeit mit fehlenden Werten\n\n\nNAs in der Spalte Weight auswählen:\n\n\nis.na(athletes$Weight)\n\n    [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n...\n\n\n\n\nNAs in der Spalte Weight beim Subsetting nicht beachten:\n\n\nathletes[(athletes$Sport == \"Judo\") & (athletes$Weight &gt; 100 | athletes$Weight &lt; 50) & !is.na(athletes$Weight), ]\n\n       NOC     ID                                 Name Sex Age Height Weight\n471    ALG  13895                  Mohamed Bouaichaoui   M  25    178  120.0\n673    ALG  82643                        Meriem Moussa   F  20    150   48.0\n..."
  },
  {
    "objectID": "slides/IntroR/introR.html#fehlende-werte-entfernen",
    "href": "slides/IntroR/introR.html#fehlende-werte-entfernen",
    "title": "Einführung in R",
    "section": "Fehlende Werte entfernen",
    "text": "Fehlende Werte entfernen\n\nathletes_na &lt;- athletes[!is.na(athletes$Weight), ]\nhead(athletes_na)\n\n   NOC     ID                 Name Sex Age Height Weight        Team\n3  AFG  44977    Mohammad Halilula   M  28    163     57 Afghanistan\n5  AFG 109153   Shakar Khan Shakar   M  24     NA     74 Afghanistan\n...\n\n\n\n## tidyverse:\nathletes_na &lt;- athletes %&gt;%\n  drop_na(Weight)\nhead(athletes_na)\n\n  NOC     ID                 Name Sex Age Height Weight        Team       Games\n1 AFG  44977    Mohammad Halilula   M  28    163     57 Afghanistan 1980 Summer\n2 AFG 109153   Shakar Khan Shakar   M  24     NA     74 Afghanistan 1964 Summer\n...\n\n\nBeides entfernt alle Zeilen, die in der Spalte Weight ein NA haben."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-9",
    "href": "slides/IntroR/introR.html#section-9",
    "title": "Einführung in R",
    "section": "",
    "text": "Reshaping"
  },
  {
    "objectID": "slides/IntroR/introR.html#wide-format",
    "href": "slides/IntroR/introR.html#wide-format",
    "title": "Einführung in R",
    "section": "Wide-Format",
    "text": "Wide-Format\n\ninhabitants_wide &lt;- data.frame(\n  country = c(\"China\", \"India\", \"USA\"),\n  inhabitants_2021 = c(1425893465 , 1407563842, NA),\n  inhabitants_2022 = c(1425857720, 1420939232, 338903174)\n)\n\nhead(inhabitants_wide)\n\n  country inhabitants_2021 inhabitants_2022\n1   China       1425893465       1425857720\n2   India       1407563842       1420939232\n3     USA               NA        338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#long-format",
    "href": "slides/IntroR/introR.html#long-format",
    "title": "Einführung in R",
    "section": "Long-Format",
    "text": "Long-Format\n\n\n  country         variable      value\n1   China             area    9597000\n2   China inhabitants_2022 1425857720\n3   India             area    3287000\n4   India inhabitants_2022 1420939232\n5     USA             area    9834000\n6     USA inhabitants_2022  338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#von-wide-zu-long",
    "href": "slides/IntroR/introR.html#von-wide-zu-long",
    "title": "Einführung in R",
    "section": "Von Wide zu Long",
    "text": "Von Wide zu Long\n\ninhabitants_long_2 &lt;- inhabitants_wide %&gt;%\n  pivot_longer(\n    ## Spalten die gereshaped werden sollen\n    cols = c(\"inhabitants_2022\", \"inhabitants_2021\"),\n    ## Neue Spalte, in der die bisherigen Spaltennamen gespeichert werden\n    names_to = \"year\",\n    ## Neue Spalte, in der die bisherigen Werte gespeichert werden\n    values_to = \"inhabitants\"\n  )\n\nhead(inhabitants_long)\n\n  country         variable      value\n1   China             area    9597000\n2   China inhabitants_2022 1425857720\n3   India             area    3287000\n4   India inhabitants_2022 1420939232\n5     USA             area    9834000\n6     USA inhabitants_2022  338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#von-long-zu-wide",
    "href": "slides/IntroR/introR.html#von-long-zu-wide",
    "title": "Einführung in R",
    "section": "Von Long zu Wide",
    "text": "Von Long zu Wide\n\ninhabitants_wide_2 &lt;- inhabitants_long %&gt;%\n  pivot_wider(\n    id_cols = \"country\",\n    names_from = \"variable\",\n    values_from = \"value\"\n  )\n\nhead(inhabitants_wide_2)\n\n# A tibble: 3 × 3\n  country    area inhabitants_2022\n  &lt;chr&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n1 China   9597000       1425857720\n2 India   3287000       1420939232\n3 USA     9834000        338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#übung-5",
    "href": "slides/IntroR/introR.html#übung-5",
    "title": "Einführung in R",
    "section": "Übung",
    "text": "Übung\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übung zum Reshaping."
  },
  {
    "objectID": "slides/IntroR/introR.html#merging",
    "href": "slides/IntroR/introR.html#merging",
    "title": "Einführung in R",
    "section": "Merging",
    "text": "Merging\n\n\nVorbereitung\nZuerst müssen wir die Daten laden und für das Beispiel vorbereiten.\n\nworld_coordinates &lt;- readRDS(file = here::here(\"raw_data\", \"world_coordinates.rds\"))\n\n## Count the number of gold medal winners in each country\nmedal_counts &lt;- athletes %&gt;%\n  filter(Medal == \"Gold\") %&gt;%\n  group_by(Region) %&gt;%\n  count(Medal) \n\nmedal_counts\n\n# A tibble: 99 × 3\n# Groups:   Region [99]\n   Region     Medal     n\n..."
  },
  {
    "objectID": "slides/IntroR/introR.html#merging-1",
    "href": "slides/IntroR/introR.html#merging-1",
    "title": "Einführung in R",
    "section": "Merging",
    "text": "Merging\nSchaue dir die Dokumentation von merge an für Infos zu den Argumenten.\n\nmedal_countries &lt;- merge(\n  x = medal_counts,\n  y = world_coordinates,\n  by.x = \"Region\",\n  by.y = \"region\",\n  all.x = FALSE,\n  all.y = TRUE\n)\n\nhead(medal_countries)\n\n       Region Medal  n     long      lat group order subregion\n1 Afghanistan  &lt;NA&gt; NA 74.89131 37.23164     2    12      &lt;NA&gt;\n2 Afghanistan  &lt;NA&gt; NA 74.84023 37.22505     2    13      &lt;NA&gt;\n3 Afghanistan  &lt;NA&gt; NA 74.76738 37.24917     2    14      &lt;NA&gt;\n4 Afghanistan  &lt;NA&gt; NA 74.73896 37.28564     2    15      &lt;NA&gt;\n5 Afghanistan  &lt;NA&gt; NA 74.72666 37.29072     2    16      &lt;NA&gt;\n6 Afghanistan  &lt;NA&gt; NA 74.66895 37.26670     2    17      &lt;NA&gt;"
  },
  {
    "objectID": "slides/IntroR/introR.html#merging-im-tidyverse",
    "href": "slides/IntroR/introR.html#merging-im-tidyverse",
    "title": "Einführung in R",
    "section": "Merging im tidyverse\n",
    "text": "Merging im tidyverse\n\n\nmedal_countries &lt;- world_coordinates %&gt;%\n  left_join(medal_counts, join_by(region == Region))\nhead(medal_countries)\n\n       long      lat group order region subregion Medal  n\n1 -69.89912 12.45200     1     1  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n2 -69.89571 12.42300     1     2  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n3 -69.94219 12.43853     1     3  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n4 -70.00415 12.50049     1     4  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n5 -70.06612 12.54697     1     5  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n6 -70.05088 12.59707     1     6  Aruba      &lt;NA&gt;  &lt;NA&gt; NA"
  },
  {
    "objectID": "slides/IntroR/introR.html#übung-7",
    "href": "slides/IntroR/introR.html#übung-7",
    "title": "Einführung in R",
    "section": "Übung",
    "text": "Übung\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übung zum Merging."
  },
  {
    "objectID": "slides/IntroR/introR.html#funktionen",
    "href": "slides/IntroR/introR.html#funktionen",
    "title": "Einführung in R",
    "section": "Funktionen",
    "text": "Funktionen"
  },
  {
    "objectID": "slides/IntroR/introR.html#basics",
    "href": "slides/IntroR/introR.html#basics",
    "title": "Einführung in R",
    "section": "Basics",
    "text": "Basics\n\nfunction_name &lt;- function(argument_1, argument_2, ...){\n  result &lt;- argument_1 + argument_2\n  return(result)\n}\n\nMotivation\n\nAlles was etwas in R tut ist eine Funktion.\nSuperhilfreich, sich eigene Funktionen zu schreiben, weil das eine Menge Code-Duplikationen vermeidet (und die sind schlecht)."
  },
  {
    "objectID": "slides/IntroR/introR.html#beispiel",
    "href": "slides/IntroR/introR.html#beispiel",
    "title": "Einführung in R",
    "section": "Beispiel",
    "text": "Beispiel\n\nsum_num &lt;- function(x, y, z = 0){\n  result &lt;- x + y + z\n  return(result)\n}\n\nsum_num(x = 1, y = 1, z = 2)\n\n[1] 4\n\nsum_num(x = 1, y = 1)\n\n[1] 2"
  },
  {
    "objectID": "slides/IntroR/introR.html#bildquellen",
    "href": "slides/IntroR/introR.html#bildquellen",
    "title": "Einführung in R",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Mohammad Rahmani auf Unsplash\n\nFoto von Adi Goldstein auf Unsplash\n\nIcons from icons8.de."
  },
  {
    "objectID": "slides/IntroR/introR.html#bildquellen-1",
    "href": "slides/IntroR/introR.html#bildquellen-1",
    "title": "Einführung in R",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von elnaz asadi auf Unsplash\n\nFoto von Mika Baumeister auf Unsplash\n\nhttps://upload.wikimedia.org/wikipedia/commons/f/ff/Tidyverse_hex_logo.png\nhttps://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/rstats-artwork/here.png\nFoto von Suzanne D. Williams auf Unsplash"
  },
  {
    "objectID": "slides/IntroR/introR.html#bildquellen-2",
    "href": "slides/IntroR/introR.html#bildquellen-2",
    "title": "Einführung in R",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Zoe Holling auf Unsplash\n\nFoto von Steinar Engeland auf Unsplash\n\nFoto von Muhil Mohan auf Unsplash"
  },
  {
    "objectID": "slides/Linking/linking.html#wiederholung-voraussetzungen-für-irt",
    "href": "slides/Linking/linking.html#wiederholung-voraussetzungen-für-irt",
    "title": "Linking",
    "section": "Wiederholung: Voraussetzungen für IRT",
    "text": "Wiederholung: Voraussetzungen für IRT\n\nEindimmensionalität\nLokal Stochastische Unabhänigkeit"
  },
  {
    "objectID": "slides/Linking/linking.html#eindimmensionalität",
    "href": "slides/Linking/linking.html#eindimmensionalität",
    "title": "Linking",
    "section": "Eindimmensionalität",
    "text": "Eindimmensionalität\nDie Lösungswahrscheinlichkeit eines Items wird lediglich durch \\(\\theta_p\\) beeinflusst (und die Itemparameter), wobei die Dimension von \\(\\theta_p\\) gleich eins ist. Das Item misst also nur ein Konstrukt."
  },
  {
    "objectID": "slides/Linking/linking.html#lokal-stochastische-unabhängigkeit",
    "href": "slides/Linking/linking.html#lokal-stochastische-unabhängigkeit",
    "title": "Linking",
    "section": "Lokal stochastische Unabhängigkeit",
    "text": "Lokal stochastische Unabhängigkeit\nNach Kontrolle für die Personenfähigkeit korrelieren die Items nicht mehr. Der einzige Grund dafür, dass die Items zusammenhängen, ist also, dass die Antwort von diesem Konstrukt beeinflusst wird. Durch die Kontrolle für die Personenfähigkeit halten wir also den Fähigkeitswert konstant (alle Personen haben die gleiche Fähigkeit).\n\n\n\n\n\n\nItems können übrigens mehrdimensional aber trotzdem lokal unabhängig sein, wenn alle Items die gleichen Dimensionen messen. Andersherum sind Items immer lokal unabängig, wenn sie unidimensional sind.\n\n\n\nEin Modell mit lokal dependence hat wichtige Kovarianz zwischen den Items nicht entdeckt."
  },
  {
    "objectID": "slides/Linking/linking.html#abbildung",
    "href": "slides/Linking/linking.html#abbildung",
    "title": "Linking",
    "section": "Abbildung",
    "text": "Abbildung"
  },
  {
    "objectID": "slides/Linking/linking.html#section",
    "href": "slides/Linking/linking.html#section",
    "title": "Linking",
    "section": "",
    "text": "Linking"
  },
  {
    "objectID": "slides/Linking/linking.html#problem",
    "href": "slides/Linking/linking.html#problem",
    "title": "Linking",
    "section": "Problem",
    "text": "Problem\n\n\nDas Problem\nInvarianz-Eigenschaft von IRT: Itemparameter sind gleich über verschiedene Gruppen. Die Wahrscheinlichkeit für eine korrekte Antwort auf ein Item hängt also nur von \\(\\theta\\) ab. Nicht von anderen Personen in der Stichprobe. Wie schaffen wir das aber, wenn wir anhand von verschiedenen Gruppen kalibrieren?\n\nDie Lösung\nWir müssen die Werte, die wir aus diesen Kalibrierungen bekommen, irgendwie in einen Zusammenhang setzen."
  },
  {
    "objectID": "slides/Linking/linking.html#wiederholung-kalibrierung",
    "href": "slides/Linking/linking.html#wiederholung-kalibrierung",
    "title": "Linking",
    "section": "Wiederholung: Kalibrierung",
    "text": "Wiederholung: Kalibrierung\nDie kalibrierten Itemparameter und Personenfähigkeiten gelten erst einmal nur für diese bestimmte Kombintation aus Items und Personen.\nWARUM?"
  },
  {
    "objectID": "slides/Linking/linking.html#wiederholung-kalibrierung-1",
    "href": "slides/Linking/linking.html#wiederholung-kalibrierung-1",
    "title": "Linking",
    "section": "Wiederholung: Kalibrierung",
    "text": "Wiederholung: Kalibrierung\n\nSkala der Latenten Variable wird arbiträr festgelegt (meist auf einen Mittelwert von 0 und eine SD von 1)\nModell? sonst nicht idenfiziert.\nItemparameter dadurch nicht auf der selben Skala.\nSie können also nicht direkt miteinander verglichen werden."
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel",
    "href": "slides/Linking/linking.html#beispiel",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nSie hängen ja von den latenten Variablen in der Stichprobe ab. Wenn wir eine sehr gute Stichprobe haben, und eine sehr schwache, dann werden trotzdem bei beiden der Mittelwert der Latenten Variable 0 und die SD 1 sein. Mittelschwere Items werden aber in der schwachen Gruppe eher positive Schwierigkeiten haben, in der starken Gruppe eher negative. (Beispiel nochmal genauer ausführen, evtl. mit Grafik, Ich hatte dazu etwas im ersten Buch, dass ich gelesen habe)."
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel-1",
    "href": "slides/Linking/linking.html#beispiel-1",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nGroup 1: \\(\\theta \\sim N(0,1)\\) Group 2: \\(\\theta \\sim N(1, 1.4)\\)\nFür die Kalibrierung legen wir jetzt aber fest, dass gilt: Group 1: \\(\\theta \\sim N(0,1)\\) Group 2: \\(\\theta \\sim N(0,1)\\)"
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel-2",
    "href": "slides/Linking/linking.html#beispiel-2",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel"
  },
  {
    "objectID": "slides/Linking/linking.html#warum-das-ganze",
    "href": "slides/Linking/linking.html#warum-das-ganze",
    "title": "Linking",
    "section": "Warum das Ganze?",
    "text": "Warum das Ganze?\nAn diesem Grundgerüst können wir jetzt verschiedene Anpassungen vornehmen, um ein paar Eigenschaften von Linking zu untersuchen.\nWir erinnern uns zurück: die Fähigkeitsverteilung wird bei der Kalibrierung auf eine Standardnormalverteilung gesetzt (\\(\\theta \\sim N(0, 1)\\)).\nSo hatten wir das auch in der Übung bereits simuliert. Wir können eine zweite Gruppe mit der selben Fähigkeitsverteilung simulieren, und uns anschauen, wie die Itemparameter \\(\\alpha\\) und \\(\\beta\\) geschätzt werden."
  },
  {
    "objectID": "slides/Linking/linking.html#zwei-gruppen",
    "href": "slides/Linking/linking.html#zwei-gruppen",
    "title": "Linking",
    "section": "Zwei Gruppen",
    "text": "Zwei Gruppen\nDas Vorgehen bleibt genauso wie in der Übung. Der einzige Unterschied ist: Wir simulieren noch eine neue Gruppe hinzu, und setzten dort die \\(\\theta\\) Verteilung auf $N(1, 1).\n\nCode zeigenlibrary(TAM)\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nset.seed(123)\n\n## 2PL Funktion\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 1.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nn_subj &lt;- 100000 ## Als Objekt speichern, da so leichter Änderbar\n\n## Diesmal nehmen wir einfach 2 Gruppen\nsubjects_1 &lt;- data.frame(\n    sub_id = 1:n_subj,\n    theta = c(rnorm(n_subj, 0, 1)), \n    group = rep(\"1\", n_subj)\n)\n\nsubjects_2 &lt;- data.frame(\n    sub_id = n_subj+1:n_subj*2, ## Andere Personen, deshalb andere ID\n    theta = c(rnorm(n_subj, 1, 1)), \n    group = rep(\"2\", n_subj)\n)\n\nsubjects &lt;- rbind(subjects_1, subjects_2)\n\nsim_dat &lt;- merge(subjects, items) %&gt;%\n    mutate(p = calc_2pl(a, theta, b)) %&gt;%\n    mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nsim_dat_2 &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer, group) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = c(\"group\", \"sub_id\"))\n\n## Jetzt kalibrieren wir sie getrennt, als ob wir zwei verschiedene Sample hätten. \n\n## Zuerst vorbereiten der Daten, d.h. die nicht benötigten Spalten entfernen und einen Datensatz pro Gruppe erzeugen. \ngroup_1_prep &lt;- sim_dat_2 %&gt;% \n  filter(group == \"1\") %&gt;% \n  select(-group, -sub_id)\n\ngroup_2_prep &lt;- sim_dat_2 %&gt;%\n  filter(group == \"2\") %&gt;% \n  select(-group, -sub_id)\n\n## Kalibrieren der beiden Gruppen getrennt\ngroup_1_2PL &lt;- tam.mml.2pl(group_1_prep, irtmodel = \"2PL\")\ngroup_2_2PL &lt;- tam.mml.2pl(group_2_prep, irtmodel = \"2PL\")\n\n# ## Extrahieren der Itemparameter\nitempars_1 &lt;- as.data.frame(apply(group_1_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\nitempars_2 &lt;- as.data.frame(apply(group_2_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(itempars_2) &lt;- c(\"alpha_2\", \"beta_2\")"
  },
  {
    "objectID": "slides/Linking/linking.html#plotten",
    "href": "slides/Linking/linking.html#plotten",
    "title": "Linking",
    "section": "Plotten",
    "text": "Plotten\n\nCode zeigen## Plotten\nparameters &lt;- cbind(itempars_1, itempars_2)\n\n## Und weil ich das gleich noch ein paar mal brauche bastel ich mir mal eine Funktion draus:\nplot_group_pars &lt;- function(dat, x, y){\n  ylab_char &lt;- gsub(\"_2\", \"\", deparse(substitute(y))) ## Automatically produce ylabel\n  \n  ggplot(data = dat, aes(x = {{x}}, y = {{y}})) +\n    geom_point() +\n    geom_abline(intercept = 0, slope = 1) +\n    xlim(-4, 4) +\n    ylim(-4, 4) +\n    theme_bw() +\n    xlab(TeX(paste0(\"\\\\hat{\\\\\", deparse(substitute(x)), \"}_1\"))) + \n    ylab(TeX(paste0(\"\\\\hat{\\\\\", ylab_char, \"}_2\")))\n}\n\nplot_group_pars(parameters, beta, beta_2) +\n  labs(title = \"Itemschwierigkeiten für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(1, 1)\"))"
  },
  {
    "objectID": "slides/Linking/linking.html#warum",
    "href": "slides/Linking/linking.html#warum",
    "title": "Linking",
    "section": "Warum??",
    "text": "Warum??"
  },
  {
    "objectID": "slides/Linking/linking.html#diskriminationsparameter",
    "href": "slides/Linking/linking.html#diskriminationsparameter",
    "title": "Linking",
    "section": "Diskriminationsparameter",
    "text": "Diskriminationsparameter\n\nCode zeigenplot_group_pars(parameters, alpha, alpha_2) +\n  labs(title = \"Diskriminationsparameter für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(1, 1)\"))"
  },
  {
    "objectID": "slides/Linking/linking.html#simirt",
    "href": "slides/Linking/linking.html#simirt",
    "title": "Linking",
    "section": "SimIRT",
    "text": "SimIRT\nÜbringes: es gibt natürlich auch schon R Pakete, die die Simulationsarbeit für uns übernehmen. Aus didaktischen Gründen haben wir das bisher selber gemacht, aber können uns jetzt ein bisschen Arbeit ersparen, und das ganze von dem Paket catIrt übernehmen lassen. Hier nochmal die gleiche Simulation, aber mit\n\nlibrary(catIrt)\n\ngroup_1 &lt;- simIrt(theta =rnorm(100000, 0, 1), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\ngroup_2 &lt;- simIrt(theta =rnorm(100000, 0, 1.5), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\n\n## Kalibrieren der beiden Gruppen getrennt\ngroup_1_2PL &lt;- tam.mml.2pl(group_1$resp, irtmodel = \"2PL\")\ngroup_2_2PL &lt;- tam.mml.2pl(group_2$resp, irtmodel = \"2PL\")\n\n## Extrahieren der Itemparameter\nitempars_1 &lt;- as.data.frame(apply(group_1_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\nitempars_2 &lt;- as.data.frame(apply(group_2_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(itempars_2) &lt;- c(\"alpha_2\", \"beta_2\")"
  },
  {
    "objectID": "slides/Linking/linking.html#plots-zeigen",
    "href": "slides/Linking/linking.html#plots-zeigen",
    "title": "Linking",
    "section": "Plots zeigen",
    "text": "Plots zeigen\n\nCode zeigenparameters &lt;- cbind(itempars_1, itempars_2)\n\nplot_group_pars(parameters, alpha, alpha_2) +\n  labs(title = \"Diskriminationsparameter für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(0, 1.5)\"))"
  },
  {
    "objectID": "slides/Linking/linking.html#schwierigkeit",
    "href": "slides/Linking/linking.html#schwierigkeit",
    "title": "Linking",
    "section": "Schwierigkeit",
    "text": "Schwierigkeit\n\nCode zeigenplot_group_pars(parameters, beta, beta_2) +\n  labs(title = \"Itemschwierigkeiten für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(0, 1.5)\"))"
  },
  {
    "objectID": "slides/Linking/linking.html#schlusfolgerung",
    "href": "slides/Linking/linking.html#schlusfolgerung",
    "title": "Linking",
    "section": "Schlusfolgerung",
    "text": "Schlusfolgerung\n\nWir brauchen also einen Referenzrahmen um unsere Testergebnisse interpretieren zu können.\nDas bedeutet auch, dass wir die Werte aus verschiedenen Kalibrierungen nicht direkt miteinander vergleichen können.\nLösung: Linking"
  },
  {
    "objectID": "slides/Linking/linking.html#identifizierbarkeit",
    "href": "slides/Linking/linking.html#identifizierbarkeit",
    "title": "Linking",
    "section": "Identifizierbarkeit",
    "text": "Identifizierbarkeit"
  },
  {
    "objectID": "slides/Linking/linking.html#sec-linking",
    "href": "slides/Linking/linking.html#sec-linking",
    "title": "Linking",
    "section": "Linking/Equating",
    "text": "Linking/Equating\n\nSzenario: Wir haben verschiedene Testformen, und wollen die Scores auf eine gemeinsame Skala bringen.\nDafür haben wir zwei Möglichkeiten:\n\nGemeinsame Items\nGemeinsame Personen\n\n\n\nAbbildung z.B. mit Verteilung von theta scores, die nochmal zeigt was das Problem ist. Dann kann man bestimmte Items markieren, und die Verteilungen entsprechend dieser markierten Items verschieben.\nEmbretson 2000, S. 253\n\nItem Parameter werden in beiden Tests geschätzt, und dann anhand der Ankeritems durch eine geeignete Transformation auf eine gemeinsame Skala gebracht."
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel-3",
    "href": "slides/Linking/linking.html#beispiel-3",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\n\nSchulvergleichsstudien über die Jahre:\nItempools von Unternehmen, die Einstellungstests anbieten."
  },
  {
    "objectID": "slides/Linking/linking.html#ankeritems",
    "href": "slides/Linking/linking.html#ankeritems",
    "title": "Linking",
    "section": "Ankeritems",
    "text": "Ankeritems\n\n\nAnkeritems sind gemeinsame Items, die in beiden Testformen vorhanden sind. Hauptproblem bei der Auswahl: Sie sollten in beiden Gruppen nicht unterschiedlich funktionieren, es sollte also kein Differential Item Functioning (DIF) geben, siehe Kapitel 1."
  },
  {
    "objectID": "slides/Linking/linking.html#ankeritems-1",
    "href": "slides/Linking/linking.html#ankeritems-1",
    "title": "Linking",
    "section": "Ankeritems",
    "text": "Ankeritems\n\nKallibrierungen der Parameterschätzer aus zwei verschiedenen Testformen werden auf eine gemeinsame Skala gebracht.\nWir müssen also die theta (\\(\\theta\\)) scores des einen Tests so transformieren, dass sie auf einer gemeinsamen Skala mit den Scores des anderen Tests liegen:\n\n\\[\n\\theta_Y = A \\theta_X + B\n\\]"
  },
  {
    "objectID": "slides/Linking/linking.html#ankerpersonen",
    "href": "slides/Linking/linking.html#ankerpersonen",
    "title": "Linking",
    "section": "Ankerpersonen",
    "text": "Ankerpersonen\nPersonen bearbeiten beide Tests. Personenfähigkeit wird basierend auf einem Referenztest geschätzt, und dann fixiert und konstant gehalten, wenn andere Testformen bearbeitet werden. Die Fähigkeitswerte werden dann genutzt, um Itemparameter auf beiden Testformen zu schätzen."
  },
  {
    "objectID": "slides/Linking/linking.html#linking",
    "href": "slides/Linking/linking.html#linking",
    "title": "Linking",
    "section": "Linking",
    "text": "Linking\n\\[\n\\theta* = x\\theta+y\n\\]\n…"
  },
  {
    "objectID": "slides/Linking/linking.html#linking-1",
    "href": "slides/Linking/linking.html#linking-1",
    "title": "Linking",
    "section": "Linking",
    "text": "Linking\nZiel: “Linking constants” \\(x\\) und \\(y\\) findend, welche die Item parameter aus den beiden Gruppen auf der selben Skala plazieren. Deutlich machen, für welche Art Modell nutzbar! Nochmal mit dem neueren Buch rübergehen, das geht noch mehr in die Tiefe.\n\nZwei häufige Methoden:\n\nmean-sigma:\n\nAnnahme: Gemeinsame Ankeritems, oder Zwei Gruppen haben den genau gleichen Test bearbeitet. \\[\nB_B^* = x\\beta_b=y\n\\]\n\n\n\n\n\n\n\\[\nx = \\frac{\\sigma_A}{\\sigma_B}\n\\]\n\\[\ny = \\overline{\\beta}_A - x(\\overline{\\beta}_B)\n\\]\nUnd dann einsetzen in \\[\n\\theta* = x\\theta+y\n\\]\netc.\nmal ausprobieren!"
  },
  {
    "objectID": "slides/Linking/linking.html#mean-sigma",
    "href": "slides/Linking/linking.html#mean-sigma",
    "title": "Linking",
    "section": "mean-sigma",
    "text": "mean-sigma\nProbleme: linking constants können stark von Outliern beeinflusst werden, und von den differential standards errors of the item difficutly estimates - Robust procedures exist.\nNur die item difficulty parameters werden zur berechnung der Linking constants genutzt.\nAlternative: Characteristic curve methods"
  },
  {
    "objectID": "slides/Linking/linking.html#characteristic-curve-methods",
    "href": "slides/Linking/linking.html#characteristic-curve-methods",
    "title": "Linking",
    "section": "Characteristic curve methods",
    "text": "Characteristic curve methods\nVersuch, die Linking constants so zu berechnen, dass die test charctersitic curves so ähnlich wie möglich sind. Nutzen daher alle item parameter um die Linking constants zu finden. computationally more expensive. Empirical research zeigt keine großen Unterschide zwischen beiden Methoden? Nochmal selber recherchiereen."
  },
  {
    "objectID": "slides/Linking/linking.html#gibt-es-neuere-methoden-z.b.-multi-group-irt-cfa-framework",
    "href": "slides/Linking/linking.html#gibt-es-neuere-methoden-z.b.-multi-group-irt-cfa-framework",
    "title": "Linking",
    "section": "Gibt es neuere methoden? Z.B. Multi-group IRT, CFA framework …?",
    "text": "Gibt es neuere methoden? Z.B. Multi-group IRT, CFA framework …?"
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel-4",
    "href": "slides/Linking/linking.html#beispiel-4",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nIm Embretson machen sie eine kleine Simulation. Könnten wir auch machen, entweder als aufgabe oder demonstrieren. - Man könnte die Linking constants setzen, gukcen was das mit den schwierikeiten macht, und die Simulierten Werte wieder rekapitulieren."
  },
  {
    "objectID": "slides/Linking/linking.html#das-problem",
    "href": "slides/Linking/linking.html#das-problem",
    "title": "Linking",
    "section": "Das Problem",
    "text": "Das Problem\n\nFunktionieren die Items in verschiedenen Gruppen (z.B. Geschlecht, Kultur, Fähigkeit …) auf dieselbe Art und Weise?\nGibt es also echte Mittelwertsunterschiede zwischen beiden Gruppen, oder sind die Unterschiede auf Besondere Interaktionen zwischen Items und Gruppen zurückzuführen?"
  },
  {
    "objectID": "slides/Linking/linking.html#section-1",
    "href": "slides/Linking/linking.html#section-1",
    "title": "Linking",
    "section": "",
    "text": "Der Legende nach soll Rugby während eines Fußballspiels in der gleichnamigen Stadt entstanden sein. Als der Mannschaft von William Webb Ellis 1823 eine Niederlage bevorstand, packte dieser den Ball mit den Händen und legte ihn ins Tor des Gegners. Obwohl berechtigte Zweifel am Wahrheitsgehalt der Geschichte bestehen – der Ball wurde bereits zuvor in den meisten Spielvarianten mit der Hand getragen –, ist der Pokal der Rugby-Union-Weltmeisterschaft nach William Webb Ellis benannt (der Webb Ellis Cup).\n1863 wurde der englische Fußballverband Football Association (FA) mit dem Ziel gegründet, die noch vielfältigen Fußballregeln zu vereinheitlichen. Aufgrund von Streitigkeiten über Regeländerungen zogen sich einige Vereine aus dem Verband zurück und gründeten am 26. Januar 1871 mit der Rugby Football Union (RFU) einen konkurrierenden Verband, der in der Folgezeit nach und nach die Regeln der Rugby School standardisierte. Bereits am 27. März desselben Jahres fand in Edinburgh zwischen Schottland und England das erste Länderspiel statt.\n1895 erfolgte aufgrund eines Streits über den Amateurgedanken eine weitere Trennung, diesmal innerhalb der RFU. 21 Vereine, vor allem aus Arbeitervierteln Nordenglands, spalteten sich als Northern Rugby Union (heute Rugby Football League) ab, legten ihre eigenen Regeln fest und erlaubten die Professionalisierung des Sports. Aus den veränderten Regeln entwickelte sich die Variante Rugby League. Bis heute existieren beide Varianten des Rugbys nebeneinander. Internationale Begegnungen von Nationalmannschaften werden sowohl nach den Regeln der Rugby Union wie auch nach denen der Rugby League abgehalten. Seit 1995 sind im Rugby Union ebenfalls Profisportler zugelassen.\n\n\n\nWikipedia"
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel-5",
    "href": "slides/Linking/linking.html#beispiel-5",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\n\n\nWelche Unterarten von Rugby gibt es laut Text?"
  },
  {
    "objectID": "slides/Linking/linking.html#beispielbild",
    "href": "slides/Linking/linking.html#beispielbild",
    "title": "Linking",
    "section": "Beispielbild",
    "text": "Beispielbild"
  },
  {
    "objectID": "slides/Linking/linking.html#dif",
    "href": "slides/Linking/linking.html#dif",
    "title": "Linking",
    "section": "DIF",
    "text": "DIF\nDIF: Item Characteristic Curves unterscheiden sich in verschiedenen Subgruppen.\nMindestens einer der Paramter im IRT Modell unterscheidet sich also zwischen den Gruppen.\n\nGrund: Item ist nicht eindimensional.\n\nDIF-Untersuchung ist damit auch eine Untersuchung der Testvalidität!"
  },
  {
    "objectID": "slides/Linking/linking.html#wie",
    "href": "slides/Linking/linking.html#wie",
    "title": "Linking",
    "section": "Wie?",
    "text": "Wie?\nReference vs. focal group\nNaive Lösung: Einfach die verschiedenen Subgruppen einzeln kalibrieren und dann die ICRs anschauen.\nWarum funktioniert das nicht?"
  },
  {
    "objectID": "slides/Linking/linking.html#warum-funktioniert-das-nicht",
    "href": "slides/Linking/linking.html#warum-funktioniert-das-nicht",
    "title": "Linking",
    "section": "Warum funktioniert das nicht?",
    "text": "Warum funktioniert das nicht?\nWir haben am Anfang dieser Präsi gesehen, dass man die Werte aus versch. Kalibrierungen nich ohne weiteres vergleichen kann, da die Skalen arbiträr festgelegt werden. Wir müssen also vorher linken, siehe Kapitel 0.22 !"
  },
  {
    "objectID": "slides/Linking/linking.html#dif-finden",
    "href": "slides/Linking/linking.html#dif-finden",
    "title": "Linking",
    "section": "DIF finden",
    "text": "DIF finden\nEs gibt viele verschiedene Verfahren, mit denen man Items auf DIF tests kann:\n\nWald-Test etc.\nLogistische Regression\nArea Measuures\nCFA-Ansätze\n(fixieren von Parametern in beiden Subgruppen und Vergleich mit Modell, wo diese Parameter frei geschätzt werden).\nMultigruppen-IRT\nMIMIC model\nRaschtrees\nRegularisierung\n\n\n\nSee Berrio 2020 for a review."
  },
  {
    "objectID": "slides/Linking/linking.html#iteratives-vorgehen",
    "href": "slides/Linking/linking.html#iteratives-vorgehen",
    "title": "Linking",
    "section": "Iteratives Vorgehen",
    "text": "Iteratives Vorgehen\n\n\n\n\n\n\nOft werden die Methoden iterativ angewandt, da beim anfänglichen Matchen der Gruppen ja auch eventuell DIF-Items für die Berechnung der Scores verwendet werden."
  },
  {
    "objectID": "slides/Linking/linking.html#einszwei-methoden-kurz-genauer-vorstellen-und-in-der-übung-bearbeiten.",
    "href": "slides/Linking/linking.html#einszwei-methoden-kurz-genauer-vorstellen-und-in-der-übung-bearbeiten.",
    "title": "Linking",
    "section": "Eins/Zwei Methoden kurz genauer vorstellen und in der Übung bearbeiten.",
    "text": "Eins/Zwei Methoden kurz genauer vorstellen und in der Übung bearbeiten."
  },
  {
    "objectID": "slides/Linking/linking.html#bildquellen",
    "href": "slides/Linking/linking.html#bildquellen",
    "title": "Linking",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Annie Spratt auf Unsplash\n\nFoto von Bryson Hammer auf Unsplash.\nErstellt mit Bing Bild-Ersteller.\nFoto von Quino Al auf Unsplash\n\nFoto von James Coleman auf Unsplash\n\nhttps://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/Flag_of_Germany.svg/1920px-Flag_of_Germany.svg.png\nhttps://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Flag_of_New_Zealand.svg/800px-Flag_of_New_Zealand.svg.png"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IRT Workshop",
    "section": "",
    "text": "Tag 1\n\nProgramm 1\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n10:00 – 13:00\nEinführung in Modellierung latenter Variablen\nTheoretische Einführung in die Modellierung latenter Variablen in Klassischer Testtheorie und Item Response Theory (IRT) (90 min.; SW)\n\n\n11:30 – 13:00\nEinführung in R\nEinführung in die R-Programmierumgebung. Datenaufbereitung für IRT-Analysen. (90 min.; NH)\n\n\n14:00 – 17:00\nIRT-Modelle in TAM\nÜbung: einfacher IRT-Modelle in TAM. Theoretische Unterscheidung zwischen JML, CML und MML (SW).\n\n\n14:00 – 17:00\nRaschmodell und GLMM\nTheoretische Einführung und praktische Illustration: Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells (GLMM) (NH + SW).\n\n\n14:00 – 17:00\nReliabilität und Validität\nReliabilität, Validität, lokale stochastische Unabhängigkeit\n\n\nTag 2\n\nProgramm 1\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n09:00 – 12:00\nLinking und Differential Item Functioning\nVerlinkte Items, lokale stochastische Unabhängigkeit, Messinvarianz (90 min.; NH)\n\n\n09:00 – 12:00\nBedeutung von Testdesigns\nDie Bedeutung von Testdesigns. Was kann schiefgehen, wenn Testdesigns ungeeignet sind? (SW)\n\n\n13:00 – 16:00\nHöher parametrisierte Modelle\nHöher parametrisierte Modelle: 2pl, 3pl, partial credit (NH)\n\n\n13:00 – 16:00\nLängsschnittliche Designs\nLängsschnittliche Designs: Wiederholte Messungen für Individuen, Kohorten oder Populationen (SW)\n\n\n\n\n\n\n\nTag 3\n\nProgramm 3\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n09:00 – 12:00\nPraktische Überlegungen\nPraktische Überlegungen: Welches Modell für welche Forschungsfrage? Wieviele Personen sind notwendig für welches Forschungsdesign? Theoretische Überlegungen und praktische Empfehlungen (180 min., SW + NH)\n\n\n13:00 – 16:00\nDas ganze Bild\nVollständige “Schritt für Schritt”-Analyse von Forschungsdaten: Datenaufbereitung, Kalibrierung, Plausibilitätsprüfungen, Messinvarianz, Beantworten von Forschungsfragen (180 Min., SW/NH)"
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Folien",
    "section": "",
    "text": "Einführung Item Response Theorie\n  Download PDF File\n   \n    Unable to display PDF file. Download instead.\n  \n  \n\n\nEinführung in R\n    View slides in full screen\n       \n      \n    \n  \n\n\nGLM\n    View slides in full screen\n       \n      \n    \n  \n\n\nLinking\n    View slides in full screen\n       \n      \n    \n  \n\n\nHöher Parametrisierte Modelle\n    View slides in full screen"
  },
  {
    "objectID": "slides/GLM/glm.html#überblick",
    "href": "slides/GLM/glm.html#überblick",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Überblick",
    "text": "Überblick\n\nGeneralized Linear Modell (GLM)\nLinear Mixed Model (LMM)\nÜbertragung auf IRT Kontext"
  },
  {
    "objectID": "slides/GLM/glm.html#generalized-linear-model",
    "href": "slides/GLM/glm.html#generalized-linear-model",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Generalized Linear Model",
    "text": "Generalized Linear Model\n\\[\ny = Xb+e\n\\]\n\\[\nE(y) = \\mu = g^{-1}(Xb)\n\\]\n\nmit \\(g\\) als Link Funktion\n\nVarianzfunktion auch zeigen?"
  },
  {
    "objectID": "slides/GLM/glm.html#irt-modell-als-glm",
    "href": "slides/GLM/glm.html#irt-modell-als-glm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "IRT Modell als GLM",
    "text": "IRT Modell als GLM\n\\[\ng(\\mu) = ln(\\frac{\\mu}{1-\\mu}) = Xb\n\\]"
  },
  {
    "objectID": "slides/GLM/glm.html#irt-modell-als-glm-1",
    "href": "slides/GLM/glm.html#irt-modell-als-glm-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "IRT Modell als GLM",
    "text": "IRT Modell als GLM\n\nLogistische Regression: Modellierung der Wahrscheinlichkeit einer korrekten Antwort.\nZusammenhang der Variablen linear. Muss dann noch auf die logit-scale gebracht werden (Link Funktion)."
  },
  {
    "objectID": "slides/GLM/glm.html#section",
    "href": "slides/GLM/glm.html#section",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "",
    "text": "Linear Mixed Models\n\n\n\nFoto von Mauro Lima auf Unsplash."
  },
  {
    "objectID": "slides/GLM/glm.html#llm",
    "href": "slides/GLM/glm.html#llm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "LLM",
    "text": "LLM\n\nlibrary(tidyverse)\n\n## Daten laden\nload(here::here(\"raw_data\", \"multilevel_data.rda\"))\n\n## Überblick\nstr(stud_data)\n\ntibble [7,185 × 5] (S3: tbl_df/tbl/data.frame)\n $ school  : chr [1:7185] \"1224\" \"1224\" \"1224\" \"1224\" ...\n $ minority: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ sex     : Factor w/ 2 levels \"Male\",\"Female\": 2 2 1 1 1 1 2 1 2 1 ...\n $ ses     : num [1:7185] -1.528 -0.588 -0.528 -0.668 -0.158 ...\n $ mathach : num [1:7185] 5.88 19.71 20.35 8.78 17.9 ...\n\n\n\nillustration_dat &lt;- stud_data %&gt;% \nfilter(school %in% c(\"1224\", \"1288\", \"1296\", \"1308\", \"1317\", \"1358\", \"1374\", \"1433\", \"1436\"))\n\n## Zentrieren\nillustration_dat &lt;- illustration_dat %&gt;% \n  mutate(ses_cent = ses - mean(ses))\n\n\n\nDaten aus diesem Tutorial"
  },
  {
    "objectID": "slides/GLM/glm.html#option-1-ignorieren",
    "href": "slides/GLM/glm.html#option-1-ignorieren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 1: Ignorieren",
    "text": "Option 1: Ignorieren\n\nggplot(data = illustration_dat , aes(x = ses_cent, y = mathach)) +\n  geom_point(aes(colour = school)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Math Score by Socioeconomic Status\",\n       x = \"Socioeconomic Status\",\n       y = \"Math Score\") +\n       theme_classic() +\n       ylim(c(-5, 25))"
  },
  {
    "objectID": "slides/GLM/glm.html#option-1-ignorieren-1",
    "href": "slides/GLM/glm.html#option-1-ignorieren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 1: Ignorieren",
    "text": "Option 1: Ignorieren\nGenerell eher keine gute Idee:\n\nDie genestete Struktur kann von Interesse sein!\nWir tun so, als ob wir mehr Informationen hätten, als wir letztendlich haben. Das liegt daran, dass Abhängigkeiten zwischen den Daten bestehen. Konsequenz:\n\nStandardfehler werden unterschätzt, unsere Inferenzstatistischen Tests werden eher signifikant."
  },
  {
    "objectID": "slides/GLM/glm.html#option-2-aggregieren",
    "href": "slides/GLM/glm.html#option-2-aggregieren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 2: Aggregieren",
    "text": "Option 2: Aggregieren\n\nillustration_dat %&gt;%\n  group_by(school) %&gt;%\n  summarise(mean_mathach = mean(mathach),\n            mean_ses = mean(ses_cent)) %&gt;%\nggplot(aes(x = mean_ses, y = mean_mathach)) +\n  geom_point(aes(colour = school)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Math Score by Socioeconomic Status\",\n       x = \"Mean Socioeconomic Status\",\n       y = \"Mean Math Score\") +\n       theme_classic() +\n       ylim(c(-5, 25))"
  },
  {
    "objectID": "slides/GLM/glm.html#option-2-aggregieren-1",
    "href": "slides/GLM/glm.html#option-2-aggregieren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 2: Aggregieren",
    "text": "Option 2: Aggregieren"
  },
  {
    "objectID": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren",
    "href": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren",
    "text": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren\nVerstehe noch nicht so ganz, wie das grafisch aussehen würde. https://www.cambridge.org/core/journals/political-science-research-and-methods/article/abs/should-i-use-fixed-or-random-effects/12DFCB222123587A37163F2226E85C67\nrandom effect models reduce bias, but can reduce the variance of estimates of coefficients of interest. some sort of regularization\n\nlm(mathach ~ ses_cent + school, data = illustration_dat) %&gt;% \n    summary()\n\nmod2 &lt;- lmer(mathach ~ ses_cent + (1|school), data = illustration_dat) \nranef(mod2)\n\nWird schnell unübersichtlich, lm z.B. gibt uns viele Infos raus, die uns eigentlich gar nicht interssieren. An sich müsste die Grafik ähnlich aussehen wie im nächsten Beispiel? Die Berechnungen sind aber ein bisscehn anders, v.a. wegen Partial pooling."
  },
  {
    "objectID": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren-1",
    "href": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren",
    "text": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren"
  },
  {
    "objectID": "slides/GLM/glm.html#option-4-multilevel-modell",
    "href": "slides/GLM/glm.html#option-4-multilevel-modell",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 4: Multilevel-Modell",
    "text": "Option 4: Multilevel-Modell\n\nggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Math Score by Socioeconomic Status\",\n       x = \"Socioeconomic Status\",\n       y = \"Math Score\") +\n       theme_classic() +\n       ylim(c(-5, 25))"
  },
  {
    "objectID": "slides/GLM/glm.html#notizen",
    "href": "slides/GLM/glm.html#notizen",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Notizen",
    "text": "Notizen\nRein Optisch betrachtet scheint es recht wichtig zu sein, auf welche Schule man geht. Die Abweichung von Mittelwert des GesamtSES hat auch einen Einfluss."
  },
  {
    "objectID": "slides/GLM/glm.html#level-1-gleichung",
    "href": "slides/GLM/glm.html#level-1-gleichung",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Level 1 Gleichung",
    "text": "Level 1 Gleichung\nFür jede Gruppe j: \\[\ny_{ij} = \\beta_{0j} + \\beta_{1j}x_{ij} + e_{ij}\n\\]\nAbbildung"
  },
  {
    "objectID": "slides/GLM/glm.html#level-2-gleichung",
    "href": "slides/GLM/glm.html#level-2-gleichung",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Level-2 Gleichung",
    "text": "Level-2 Gleichung\n\\[\n\\beta_{0j} = \\beta_{0}+\\zeta_{0j}\n\\]\n\\[\n\\beta_{1j} = \\beta_1 + \\zeta_{1j}\n\\]\nAbbildung"
  },
  {
    "objectID": "slides/GLM/glm.html#das-gemischte-modell",
    "href": "slides/GLM/glm.html#das-gemischte-modell",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Das gemischte Modell",
    "text": "Das gemischte Modell\nJetzt müssen wir nur noch einsetzen:\n\\[\ny_{ij} = \\beta_{0j} + \\beta_{1j}x_{ij} + e_{ij}\n\\] \\[\n\\beta_{0j} = \\beta_{0}+\\zeta_{0j}\n\\]\n\\[\n\\beta_{1j} = \\beta_1 + \\zeta_{1j}\n\\]\n\\[\ny_{ij} = \\beta_{0}+\\beta_1x_{ij} + \\zeta_{0j} + \\zeta_{1j}x_{ij} + e_{ij}\n\\]"
  },
  {
    "objectID": "slides/GLM/glm.html#section-1",
    "href": "slides/GLM/glm.html#section-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "",
    "text": "Random effects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixed effects"
  },
  {
    "objectID": "slides/GLM/glm.html#random-und-fixed-effects",
    "href": "slides/GLM/glm.html#random-und-fixed-effects",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Random und Fixed effects",
    "text": "Random und Fixed effects\n\n\nRandom Effects\n\nAnnahme eines zugrundeliegenden Gesamtmittelwerts. Von diesem weichen die Gruppen random ab.\nBei Wiederholung würden wir andere Gruppen ziehen.\nPartial Pooling: Regularisierung der Extremen Werte in Richtung Gruppenmittelwert. \n\n\n\nFixed Effects\n\nHier machen wir diese Annahme einfach nicht.\nUns interessieren die tatsächlichen Gruppen, bei Wiederholung würden wird die gleichen ziehen."
  },
  {
    "objectID": "slides/GLM/glm.html#beispiel",
    "href": "slides/GLM/glm.html#beispiel",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Beispiel",
    "text": "Beispiel\nWir untersuchen den Erfolg von Verhaltenstherapie und Psychoanalyse anhand der Rückfallquote nach einem Jahr.\nPatientinnen müssen hier nach Therapeutinnen genested werden. Dabei können wir die Therapeutinnen als random effects betrachten, wir haben sie ja schließlich nur als Mittel zum Zweck aus der Population an Therapeutinnen gezogen. Die Behandlungsform (Verhaltenstherapie, Psychoanalyse) ist hingegen ein fixed effect, da wir nur diese beiden Behandlungsformen untersuchen wollen.\nAnders würde das Ganze aussehen, wenn uns die Erfolgsquote speziell dieser Therapeut*innen interessieren würde. Dann könnten wir sie ebenfalls als fixed effect im Modell mit aufnehmen."
  },
  {
    "objectID": "slides/GLM/glm.html#lme4",
    "href": "slides/GLM/glm.html#lme4",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "lme4",
    "text": "lme4\n\nlibrary(lme4)\n\nmod1 &lt;- lmer(mathach ~ ses_cent + (1|school), data = illustration_dat) \nsummary(mod1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: mathach ~ ses_cent + (1 | school)\n   Data: illustration_dat\n\nREML criterion at convergence: 2091\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.52568 -0.67053 -0.06796  0.74859  2.79564 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept)  8.778   2.963   \n Residual             34.699   5.891   \nNumber of obs: 325, groups:  school, 9\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  13.1169     1.0447  12.555\nses_cent      2.6255     0.5285   4.968\n\nCorrelation of Fixed Effects:\n         (Intr)\nses_cent -0.016"
  },
  {
    "objectID": "slides/GLM/glm.html#raschmodell-als-spezialfall-von-lmm",
    "href": "slides/GLM/glm.html#raschmodell-als-spezialfall-von-lmm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Raschmodell als Spezialfall von LMM",
    "text": "Raschmodell als Spezialfall von LMM\nDafür müssen wir zwei Dinge beachten: - Link Funktion.\n- Entscheidung über Annahme von fixed/random effects von Personen und Items.\n\n\n\nDe Boeck and Wilson (2004)\nDoran et al. (2007)"
  },
  {
    "objectID": "slides/GLM/glm.html#link-funktion",
    "href": "slides/GLM/glm.html#link-funktion",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Link Funktion",
    "text": "Link Funktion"
  },
  {
    "objectID": "slides/GLM/glm.html#fixed-und-random-effects",
    "href": "slides/GLM/glm.html#fixed-und-random-effects",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Fixed und Random Effects",
    "text": "Fixed und Random Effects\n\nEntwicklung Fragebogen um diesen an verschiedenen Stichproben zu nutzen: Person als random, Items als fixed\nEntwicklung von Items für einen großen Fragenkatalog: Items ebenfalls als random"
  },
  {
    "objectID": "slides/GLM/glm.html#exercise",
    "href": "slides/GLM/glm.html#exercise",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Exercise",
    "text": "Exercise\n\nDirekt übertragen auf den IRT-KOntext? Also sagen: Nehmt die Daten aus dem letzten Beispiel und fittet ein LLM Modell.\nDann Vergleich mit TAM."
  },
  {
    "objectID": "slides/GLM/glm.html#prädiktoren",
    "href": "slides/GLM/glm.html#prädiktoren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Prädiktoren",
    "text": "Prädiktoren\n\nBeispiel aufgreifen, zeigen, wass man mit diesen Modell noch machen kann."
  },
  {
    "objectID": "slides/GLM/glm.html#bildquellen",
    "href": "slides/GLM/glm.html#bildquellen",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Breno Machado auf Unsplash"
  },
  {
    "objectID": "slides/xPL/xPL.html#wiederholung",
    "href": "slides/xPL/xPL.html#wiederholung",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Wiederholung",
    "text": "Wiederholung\n1PL Modell\n\\[\nlogit(P(X_{pi}=1)) = \\theta_p - \\beta_i\n\\] - Logit: Transformation unseres linearen Terms, damit die Werte zwischen 0 und 1 liegen. - Inverse der logit ist die Logistic function.\n\\[\nP(X_{pi}=1) = logistic(\\theta_p - \\beta_i)\n\\]"
  },
  {
    "objectID": "slides/xPL/xPL.html#pl-exponentielle-form-des-logistischen-modells",
    "href": "slides/xPL/xPL.html#pl-exponentielle-form-des-logistischen-modells",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL exponentielle Form des logistischen Modells",
    "text": "1PL exponentielle Form des logistischen Modells\nhttps://www.geo.fu-berlin.de/en/v/soga-r/Basics-of-statistics/Logistic-Regression/The-Logit-Function/index.html \\[\nP(X_{pi}=1) = \\frac{exp(\\theta_p - \\beta_i)}{1 + exp(\\theta_p - \\beta_i)}\n\\]"
  },
  {
    "objectID": "slides/xPL/xPL.html#umschreiben-zu",
    "href": "slides/xPL/xPL.html#umschreiben-zu",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Umschreiben zu",
    "text": "Umschreiben zu\n\\[\nP(X_{pi}=1) = \\frac{e^{\\theta_p - \\beta_i}}{1 + e^{\\theta_p - \\beta_i}}\n\\]"
  },
  {
    "objectID": "slides/xPL/xPL.html#vereinfachen",
    "href": "slides/xPL/xPL.html#vereinfachen",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Vereinfachen",
    "text": "Vereinfachen\n\\[\nP(X_{pi}=1) = \\frac{1}{1 + e^{\\color{red}{-}\\theta_p \\color{red}{+} \\beta_i}}\n\\] ## Beispiel\n\\[\n\\frac{exp(1 - 0.8)}{1 + exp(1 - 0.8)} = 0.55\n\\] - \\(\\theta_p = 1\\) - \\(\\beta_i = 0.8\\)"
  },
  {
    "objectID": "slides/xPL/xPL.html#beispiel",
    "href": "slides/xPL/xPL.html#beispiel",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beispiel",
    "text": "Beispiel\n\\[\n\\frac{exp(0.8 - 1)}{1 + exp(0.8 - 1)} = 0.45\n\\]\n\n\\(\\theta_p = 0.8\\)\n\\(\\beta_i = 1\\)"
  },
  {
    "objectID": "slides/xPL/xPL.html#pl",
    "href": "slides/xPL/xPL.html#pl",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "3PL",
    "text": "3PL\n\\[\nP(X_{pi}=1) = \\gamma_i + (1-\\gamma_i)\\frac{exp(\\alpha_i(\\theta_p - \\beta_i)))}{1 + exp(\\alpha_i(\\theta_p - \\beta_i))}\n\\] - \\(\\beta_i\\): Schwierigkeit - \\(\\alpha_i\\): discrimination/factor loading/slope - \\(\\gamma_i\\) : guessing probability - Kann entweder geschätzt oder gesetzt werden (z.B. bei 4 Antwortmöglichkeiten: \\(\\gamma_i = 1/4 = 0.25\\)) - Wenn die Lösungswahrscheinlichkeit auf der rehcten Seite sehr gering ist, ist sie immer noch mind. \\(\\gamma_i\\)"
  },
  {
    "objectID": "slides/xPL/xPL.html#pl-1",
    "href": "slides/xPL/xPL.html#pl-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "2PL",
    "text": "2PL\n\\(\\gamma_i = 0\\)\n\\[\nP(X_{pi}=1) = \\color{red}{0} + (1-\\color{red}{0})\\frac{exp(\\alpha_i(\\theta_p - \\beta_i)))}{1 + exp(\\alpha_i(\\theta_p - \\beta_i))}\n\\]"
  },
  {
    "objectID": "slides/xPL/xPL.html#darstellung",
    "href": "slides/xPL/xPL.html#darstellung",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Darstellung",
    "text": "Darstellung\n\n\n\nviewof alpha1 = Inputs.range(\n  [-1, 1], \n  {value: 1, step: .1, label: tex`\\alpha_1`}\n)\nviewof beta1 = Inputs.range(\n  [-3, 3], \n  {value: 0, step: .1, label: tex`\\beta_1`}\n)\nviewof alpha2 = Inputs.range(\n  [-1, 1], \n  {value: 1, step: .1, label: tex`\\alpha_2`}\n)\nviewof beta2 = Inputs.range(\n  [-3, 3], \n  {value: 0, step: .1, label: tex`\\beta_2`}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nline_function = function(alpha, beta, theta) {\n    return Math.exp(alpha * (theta - beta)) / (1 + Math.exp(alpha * (theta - beta)));\n}\n\n// X-Variable\ndata = d3.range(-3, 3, 0.1).map((theta) =&gt; ({\n  x: theta,\n  y1: line_function(alpha1, beta1, theta),\n  y2: line_function(alpha2, beta2, theta)\n}));\n\nPlot.plot(\n  {\n    x: {grid: false, domain: [-3, 3]}, \n    y: {grid: false, domain: [0, 1]},\n    marks: [\n      Plot.line(data, {x: \"x\", y: \"y1\", stroke: \"#9B1B34\"}),\n      Plot.line(data, {x: \"x\", y: \"y2\", stroke: \"#99D9DD\"}),\n    ]\n  }\n)"
  },
  {
    "objectID": "slides/xPL/xPL.html#pl-2",
    "href": "slides/xPL/xPL.html#pl-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL",
    "text": "1PL\n\\(\\alpha_i = 1\\)\n\\[\nP(X_{pi}=1) = 0 + (1-0)\\frac{exp(\\color{red}{1}(\\theta_p - \\beta_i)))}{1 + exp(\\color{red}{1}(\\theta_p - \\beta_i))}\n\\]"
  },
  {
    "objectID": "slides/xPL/xPL.html#simulieren-von-irt-daten",
    "href": "slides/xPL/xPL.html#simulieren-von-irt-daten",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Simulieren von IRT Daten",
    "text": "Simulieren von IRT Daten\n\n\nJetzt ist ein guter Zeitpunkt, und uns ein sehr mächtiges Werkzeug anzuschauen: Datensimulation.\n\nEinerseits hilft es hoffentlich, die Konzepte hinter IRT und Linking noch besser zu verstehen.\nHilfreich, z.B. für Poweranalysen"
  },
  {
    "objectID": "slides/xPL/xPL.html#lets-take-a-step-back",
    "href": "slides/xPL/xPL.html#lets-take-a-step-back",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Let’s take a step back!",
    "text": "Let’s take a step back!\nGeht zur Übung und probiert euch aus!"
  },
  {
    "objectID": "slides/xPL/xPL.html#mögliche-punkte",
    "href": "slides/xPL/xPL.html#mögliche-punkte",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Mögliche Punkte",
    "text": "Mögliche Punkte\n\n\nGewichtung der Items\nAntwortskala\n\n\nSimulation/Modellfit\n\nZiel"
  },
  {
    "objectID": "slides/xPL/xPL.html#section",
    "href": "slides/xPL/xPL.html#section",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Exkurs:   Tradeoff zwischen\nUnderfit und\nOverfit"
  },
  {
    "objectID": "slides/xPL/xPL.html#tradeoff-zwischen-underfit-und-overfit",
    "href": "slides/xPL/xPL.html#tradeoff-zwischen-underfit-und-overfit",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Tradeoff zwischen Underfit und Overfit",
    "text": "Tradeoff zwischen Underfit und Overfit\n\n\n\n\n\n\n\n\n\n\nNach @mcelreath2018statistical, Kapitel 7"
  },
  {
    "objectID": "slides/xPL/xPL.html#tradeoff-zwischen-underfit-und-overfit-1",
    "href": "slides/xPL/xPL.html#tradeoff-zwischen-underfit-und-overfit-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Tradeoff zwischen Underfit und Overfit",
    "text": "Tradeoff zwischen Underfit und Overfit"
  },
  {
    "objectID": "slides/xPL/xPL.html#tradeoff-zwischen-underfit-und-overfit-2",
    "href": "slides/xPL/xPL.html#tradeoff-zwischen-underfit-und-overfit-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Tradeoff zwischen Underfit und Overfit",
    "text": "Tradeoff zwischen Underfit und Overfit"
  },
  {
    "objectID": "slides/xPL/xPL.html#beurteilung-von-fit",
    "href": "slides/xPL/xPL.html#beurteilung-von-fit",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beurteilung von Fit",
    "text": "Beurteilung von Fit\nz.B.: - lokLikelihood/\\(\\chi^2\\) - AIC, BIC"
  },
  {
    "objectID": "slides/xPL/xPL.html#beispielaufgabe",
    "href": "slides/xPL/xPL.html#beispielaufgabe",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beispielaufgabe",
    "text": "Beispielaufgabe\nnie – manchmal – häufig"
  },
  {
    "objectID": "slides/xPL/xPL.html#section-2",
    "href": "slides/xPL/xPL.html#section-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Grundidee: Den einzelnen Antwortkategorien wird eine eigene Schwierigkeit zugeordnet. Dadurch können wir die Antwortwahrscheinlichkeit in einer bestimmten Kategorie berechnen."
  },
  {
    "objectID": "slides/xPL/xPL.html#anwendungsbereich",
    "href": "slides/xPL/xPL.html#anwendungsbereich",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Anwendungsbereich",
    "text": "Anwendungsbereich\nOrdinale Daten (geordnete Antwortkategorien), z.B.: - Likert-Skalen - Items, die auch mit Teilpunkten bewertet werden können (z.B. Mathe)"
  },
  {
    "objectID": "slides/xPL/xPL.html#darstellung-1",
    "href": "slides/xPL/xPL.html#darstellung-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Darstellung",
    "text": "Darstellung"
  },
  {
    "objectID": "slides/xPL/xPL.html#formel",
    "href": "slides/xPL/xPL.html#formel",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Formel",
    "text": "Formel\n\\[\n\\pi_{pix}= P(X_{pi}=x|\\theta_p, \\beta_{ik})= \\frac{exp[\\sum^x_{j=0}(\\theta_p-\\beta_{ij})]}{1+exp[\\sum^k_{j=0}(\\theta_p-\\beta_{ij})]}\n\\] ::: aside - Person \\(p\\) - Item \\(i\\) - Personenscore \\(x\\) :::"
  },
  {
    "objectID": "slides/xPL/xPL.html#partial-credit-model",
    "href": "slides/xPL/xPL.html#partial-credit-model",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Partial Credit Model",
    "text": "Partial Credit Model\n\\[\n\\pi_{pix}= \\color{red}{P(X_{pi}=x|\\theta_p, \\beta_{ik})}= \\frac{exp[\\sum^x_{j=0}(\\theta_p-\\beta_{ij})]}{1+exp[\\sum^k_{j=0}(\\theta_p-\\beta_{ij})]}\n\\]"
  },
  {
    "objectID": "slides/xPL/xPL.html#partial-credit-model-1",
    "href": "slides/xPL/xPL.html#partial-credit-model-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Partial Credit Model",
    "text": "Partial Credit Model\n\\[\n\\pi_{pix}= P(X_{pi}=x|\\theta_p, \\beta_{ik})= \\frac{exp[\\sum^x_{j=0}\\color{red}{(\\theta_p-\\beta_{ij})}]}{1+exp[\\sum^k_{j=0}(\\theta_p-\\beta_{ij})]}\n\\]\nWichtig:\\(/beta_{i\\color{red}{j}}\\) ist jetzt der Schwellenparameter der Kategorie \\(j\\) des Items \\(i\\)."
  },
  {
    "objectID": "slides/xPL/xPL.html#raw-score-curve",
    "href": "slides/xPL/xPL.html#raw-score-curve",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Raw score curve",
    "text": "Raw score curve"
  },
  {
    "objectID": "slides/xPL/xPL.html#übung",
    "href": "slides/xPL/xPL.html#übung",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Übung",
    "text": "Übung\nPartial Credit Modell fitten.\n\nGrit scale\nOder Psychometrics data und so tun, als ob die das selber ausgefüllt hätten. Und dann auf 5 Stufen kondensieren oder so. Aber was ist hier mit Eindimensionalität? -&gt; Könnte aber einfach ein subset nehmen, die vermutlich eindimensional sind? Achso, und sollte eigentlich ok sein. Die sollten ja nur aufgrund des Konstruktes korrelieren. Aber: Was ist mit missings, haben alle alles bearbeitet?\n\nThis is actuallyu quite a comprehensive tutorial.\nHier auch nochmal schauen: https://www.edmeasurementsurveys.com/TAM/Tutorials/5PartialCredit.htm\n\n\n                              messy_neat disorganized_self.disciplined\nmessy_neat                     1.0000000                     0.8106662\ndisorganized_self.disciplined  0.8106662                     1.0000000\nADHD_OCD                       0.7900800                     0.7793043\nchaotic_orderly                0.8205825                     0.7954963\nlazy_diligent                  0.6354662                     0.7927139\ntardy_on.time                  0.8293504                     0.8466559\nspontaneous_scheduled          0.7805277                     0.7413686\nunderachiever_overachiever     0.5842898                     0.6923879\n                               ADHD_OCD chaotic_orderly lazy_diligent\nmessy_neat                    0.7900800       0.8205825     0.6354662\ndisorganized_self.disciplined 0.7793043       0.7954963     0.7927139\nADHD_OCD                      1.0000000       0.7636661     0.6417821\nchaotic_orderly               0.7636661       1.0000000     0.6121194\nlazy_diligent                 0.6417821       0.6121194     1.0000000\ntardy_on.time                 0.7893593       0.8186320     0.7435570\nspontaneous_scheduled         0.8300721       0.8261965     0.5471122\nunderachiever_overachiever    0.5630071       0.4739749     0.7609475\n                              tardy_on.time spontaneous_scheduled\nmessy_neat                        0.8293504             0.7805277\ndisorganized_self.disciplined     0.8466559             0.7413686\nADHD_OCD                          0.7893593             0.8300721\nchaotic_orderly                   0.8186320             0.8261965\nlazy_diligent                     0.7435570             0.5471122\ntardy_on.time                     1.0000000             0.8027984\nspontaneous_scheduled             0.8027984             1.0000000\nunderachiever_overachiever        0.6119956             0.4334656\n                              underachiever_overachiever\nmessy_neat                                     0.5842898\ndisorganized_self.disciplined                  0.6923879\nADHD_OCD                                       0.5630071\nchaotic_orderly                                0.4739749\nlazy_diligent                                  0.7609475\ntardy_on.time                                  0.6119956\nspontaneous_scheduled                          0.4334656\nunderachiever_overachiever                     1.0000000\n\n\n[1] FALSE\n\n\n                                       0          1         2         3\nmessy_neat                    0.09223847 0.19460067 0.2080990 0.3183352\ndisorganized_self.disciplined 0.07761530 0.14848144 0.1799775 0.2913386\nADHD_OCD                      0.07536558 0.19572553 0.2305962 0.4004499\nchaotic_orderly               0.14960630 0.23284589 0.2069741 0.2890889\nlazy_diligent                 0.01912261 0.07536558 0.1282340 0.2992126\ntardy_on.time                 0.07424072 0.16872891 0.2035996 0.3059618\nspontaneous_scheduled         0.13948256 0.19460067 0.1766029 0.3138358\nunderachiever_overachiever    0.02699663 0.10461192 0.2002250 0.3948256\n                                       4 miss\nmessy_neat                    0.18672666    0\ndisorganized_self.disciplined 0.30258718    0\nADHD_OCD                      0.09786277    0\nchaotic_orderly               0.12148481    0\nlazy_diligent                 0.47806524    0\ntardy_on.time                 0.24746907    0\nspontaneous_scheduled         0.17547807    0\nunderachiever_overachiever    0.27334083    0\n\n\n....................................................\nProcessing Data      2024-10-07 10:04:15.066415 \n    * Response Data: 889 Persons and  7 Items \n    * Numerical integration with 21 nodes\n    * Created Design Matrices   ( 2024-10-07 10:04:15.069092 )\n    * Calculated Sufficient Statistics   ( 2024-10-07 10:04:15.080265 )\n....................................................\nIteration 1     2024-10-07 10:04:15.083148\nE Step\nM Step Intercepts   |----\n  Deviance = 14117.3527\n  Maximum item intercept parameter change: 0.349757\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.968234\n....................................................\nIteration 2     2024-10-07 10:04:15.086743\nE Step\nM Step Intercepts   |----\n  Deviance = 13676.5477 | Absolute change: 440.8049 | Relative change: 0.03223072\n  Maximum item intercept parameter change: 0.41339\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.62565\n....................................................\nIteration 3     2024-10-07 10:04:15.088477\nE Step\nM Step Intercepts   |----\n  Deviance = 13529.42 | Absolute change: 147.1277 | Relative change: 0.01087465\n  Maximum item intercept parameter change: 0.34842\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.558409\n....................................................\nIteration 4     2024-10-07 10:04:15.269478\nE Step\nM Step Intercepts   |----\n  Deviance = 13437.3794 | Absolute change: 92.0407 | Relative change: 0.0068496\n  Maximum item intercept parameter change: 0.27763\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.491573\n....................................................\nIteration 5     2024-10-07 10:04:15.271383\nE Step\nM Step Intercepts   |----\n  Deviance = 13379.4197 | Absolute change: 57.9596 | Relative change: 0.004332\n  Maximum item intercept parameter change: 0.221208\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.41836\n....................................................\nIteration 6     2024-10-07 10:04:15.273436\nE Step\nM Step Intercepts   |----\n  Deviance = 13343.2773 | Absolute change: 36.1425 | Relative change: 0.00270866\n  Maximum item intercept parameter change: 0.174156\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.345819\n....................................................\nIteration 7     2024-10-07 10:04:15.27522\nE Step\nM Step Intercepts   |----\n  Deviance = 13321.0359 | Absolute change: 22.2413 | Relative change: 0.00166964\n  Maximum item intercept parameter change: 0.134009\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.279501\n....................................................\nIteration 8     2024-10-07 10:04:15.276971\nE Step\nM Step Intercepts   |----\n  Deviance = 13307.4148 | Absolute change: 13.6211 | Relative change: 0.00102358\n  Maximum item intercept parameter change: 0.103149\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.222651\n....................................................\nIteration 9     2024-10-07 10:04:15.278711\nE Step\nM Step Intercepts   |----\n  Deviance = 13299.1031 | Absolute change: 8.3117 | Relative change: 0.00062498\n  Maximum item intercept parameter change: 0.078924\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.175285\n....................................................\nIteration 10     2024-10-07 10:04:15.280411\nE Step\nM Step Intercepts   |----\n  Deviance = 13294.0187 | Absolute change: 5.0844 | Relative change: 0.00038245\n  Maximum item intercept parameter change: 0.060597\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.136884\n....................................................\nIteration 11     2024-10-07 10:04:15.282129\nE Step\nM Step Intercepts   |----\n  Deviance = 13290.8879 | Absolute change: 3.1308 | Relative change: 0.00023556\n  Maximum item intercept parameter change: 0.046711\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.106331\n....................................................\nIteration 12     2024-10-07 10:04:15.283849\nE Step\nM Step Intercepts   |----\n  Deviance = 13288.9316 | Absolute change: 1.9563 | Relative change: 0.00014721\n  Maximum item intercept parameter change: 0.036379\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.082384\n....................................................\nIteration 13     2024-10-07 10:04:15.285559\nE Step\nM Step Intercepts   |----\n  Deviance = 13287.6853 | Absolute change: 1.2463 | Relative change: 9.379e-05\n  Maximum item intercept parameter change: 0.028624\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.063589\n....................................................\nIteration 14     2024-10-07 10:04:15.287262\nE Step\nM Step Intercepts   |----\n  Deviance = 13286.8713 | Absolute change: 0.814 | Relative change: 6.127e-05\n  Maximum item intercept parameter change: 0.022698\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.049124\n....................................................\nIteration 15     2024-10-07 10:04:15.28898\nE Step\nM Step Intercepts   |----\n  Deviance = 13286.3246 | Absolute change: 0.5467 | Relative change: 4.115e-05\n  Maximum item intercept parameter change: 0.018155\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.037918\n....................................................\nIteration 16     2024-10-07 10:04:15.290713\nE Step\nM Step Intercepts   |----\n  Deviance = 13285.946 | Absolute change: 0.3786 | Relative change: 2.85e-05\n  Maximum item intercept parameter change: 0.014614\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.029191\n....................................................\nIteration 17     2024-10-07 10:04:15.292415\nE Step\nM Step Intercepts   |----\n  Deviance = 13285.6727 | Absolute change: 0.2733 | Relative change: 2.057e-05\n  Maximum item intercept parameter change: 0.011863\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.022595\n....................................................\nIteration 18     2024-10-07 10:04:15.294147\nE Step\nM Step Intercepts   |----\n  Deviance = 13285.467 | Absolute change: 0.2056 | Relative change: 1.548e-05\n  Maximum item intercept parameter change: 0.009733\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.017481\n....................................................\nIteration 19     2024-10-07 10:04:15.295874\nE Step\nM Step Intercepts   |----\n  Deviance = 13285.3074 | Absolute change: 0.1596 | Relative change: 1.202e-05\n  Maximum item intercept parameter change: 0.008253\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.013624\n....................................................\nIteration 20     2024-10-07 10:04:15.297599\nE Step\nM Step Intercepts   |----\n  Deviance = 13285.1797 | Absolute change: 0.1277 | Relative change: 9.61e-06\n  Maximum item intercept parameter change: 0.007094\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.010852\n....................................................\nIteration 21     2024-10-07 10:04:15.299291\nE Step\nM Step Intercepts   |----\n  Deviance = 13285.075 | Absolute change: 0.1047 | Relative change: 7.88e-06\n  Maximum item intercept parameter change: 0.006166\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.008546\n....................................................\nIteration 22     2024-10-07 10:04:15.300995\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.9875 | Absolute change: 0.0875 | Relative change: 6.59e-06\n  Maximum item intercept parameter change: 0.005411\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.006731\n....................................................\nIteration 23     2024-10-07 10:04:15.302685\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.9132 | Absolute change: 0.0743 | Relative change: 5.59e-06\n  Maximum item intercept parameter change: 0.004789\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.00527\n....................................................\nIteration 24     2024-10-07 10:04:15.304366\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.8495 | Absolute change: 0.0637 | Relative change: 4.8e-06\n  Maximum item intercept parameter change: 0.004271\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.004155\n....................................................\nIteration 25     2024-10-07 10:04:15.306117\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.7944 | Absolute change: 0.0551 | Relative change: 4.15e-06\n  Maximum item intercept parameter change: 0.003837\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.003299\n....................................................\nIteration 26     2024-10-07 10:04:15.307826\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.7464 | Absolute change: 0.0479 | Relative change: 3.61e-06\n  Maximum item intercept parameter change: 0.00347\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.002638\n....................................................\nIteration 27     2024-10-07 10:04:15.309542\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.7046 | Absolute change: 0.0418 | Relative change: 3.15e-06\n  Maximum item intercept parameter change: 0.003157\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.002128\n....................................................\nIteration 28     2024-10-07 10:04:15.31123\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.668 | Absolute change: 0.0366 | Relative change: 2.76e-06\n  Maximum item intercept parameter change: 0.00289\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.001732\n....................................................\nIteration 29     2024-10-07 10:04:15.312944\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.6358 | Absolute change: 0.0321 | Relative change: 2.42e-06\n  Maximum item intercept parameter change: 0.002666\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.001424\n....................................................\nIteration 30     2024-10-07 10:04:15.314647\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.6076 | Absolute change: 0.0282 | Relative change: 2.12e-06\n  Maximum item intercept parameter change: 0.002467\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.001183\n....................................................\nIteration 31     2024-10-07 10:04:15.316345\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.5828 | Absolute change: 0.0248 | Relative change: 1.87e-06\n  Maximum item intercept parameter change: 0.002291\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000993\n....................................................\nIteration 32     2024-10-07 10:04:15.318067\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.561 | Absolute change: 0.0218 | Relative change: 1.64e-06\n  Maximum item intercept parameter change: 0.002138\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000843\n....................................................\nIteration 33     2024-10-07 10:04:15.319793\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.5419 | Absolute change: 0.0192 | Relative change: 1.44e-06\n  Maximum item intercept parameter change: 0.001997\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000723\n....................................................\nIteration 34     2024-10-07 10:04:15.321554\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.525 | Absolute change: 0.0169 | Relative change: 1.27e-06\n  Maximum item intercept parameter change: 0.001867\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000627\n....................................................\nIteration 35     2024-10-07 10:04:15.323299\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.5101 | Absolute change: 0.0149 | Relative change: 1.12e-06\n  Maximum item intercept parameter change: 0.001747\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000549\n....................................................\nIteration 36     2024-10-07 10:04:15.325045\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4971 | Absolute change: 0.0131 | Relative change: 9.8e-07\n  Maximum item intercept parameter change: 0.001636\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000485\n....................................................\nIteration 37     2024-10-07 10:04:15.326772\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4855 | Absolute change: 0.0115 | Relative change: 8.7e-07\n  Maximum item intercept parameter change: 0.001532\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000432\n....................................................\nIteration 38     2024-10-07 10:04:15.328467\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4754 | Absolute change: 0.0101 | Relative change: 7.6e-07\n  Maximum item intercept parameter change: 0.001435\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000388\n....................................................\nIteration 39     2024-10-07 10:04:15.330222\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4665 | Absolute change: 0.0089 | Relative change: 6.7e-07\n  Maximum item intercept parameter change: 0.001345\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000351\n....................................................\nIteration 40     2024-10-07 10:04:15.331959\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4586 | Absolute change: 0.0079 | Relative change: 5.9e-07\n  Maximum item intercept parameter change: 0.001261\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000319\n....................................................\nIteration 41     2024-10-07 10:04:15.333691\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4517 | Absolute change: 0.0069 | Relative change: 5.2e-07\n  Maximum item intercept parameter change: 0.001183\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000291\n....................................................\nIteration 42     2024-10-07 10:04:15.335432\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4456 | Absolute change: 0.0061 | Relative change: 4.6e-07\n  Maximum item intercept parameter change: 0.001109\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000267\n....................................................\nIteration 43     2024-10-07 10:04:15.337187\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4402 | Absolute change: 0.0054 | Relative change: 4e-07\n  Maximum item intercept parameter change: 0.00104\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000246\n....................................................\nIteration 44     2024-10-07 10:04:15.338926\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4355 | Absolute change: 0.0047 | Relative change: 3.6e-07\n  Maximum item intercept parameter change: 0.000976\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000228\n....................................................\nIteration 45     2024-10-07 10:04:15.34065\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4313 | Absolute change: 0.0042 | Relative change: 3.1e-07\n  Maximum item intercept parameter change: 0.000916\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000211\n....................................................\nIteration 46     2024-10-07 10:04:15.342353\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4276 | Absolute change: 0.0037 | Relative change: 2.8e-07\n  Maximum item intercept parameter change: 0.000859\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000196\n....................................................\nIteration 47     2024-10-07 10:04:15.344082\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4244 | Absolute change: 0.0032 | Relative change: 2.4e-07\n  Maximum item intercept parameter change: 0.000806\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000182\n....................................................\nIteration 48     2024-10-07 10:04:15.345842\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4215 | Absolute change: 0.0029 | Relative change: 2.1e-07\n  Maximum item intercept parameter change: 0.000756\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.00017\n....................................................\nIteration 49     2024-10-07 10:04:15.347577\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.419 | Absolute change: 0.0025 | Relative change: 1.9e-07\n  Maximum item intercept parameter change: 0.00071\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000158\n....................................................\nIteration 50     2024-10-07 10:04:15.34929\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4168 | Absolute change: 0.0022 | Relative change: 1.7e-07\n  Maximum item intercept parameter change: 0.000666\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000148\n....................................................\nIteration 51     2024-10-07 10:04:15.351063\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4149 | Absolute change: 0.0019 | Relative change: 1.5e-07\n  Maximum item intercept parameter change: 0.000625\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000138\n....................................................\nIteration 52     2024-10-07 10:04:15.352825\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4131 | Absolute change: 0.0017 | Relative change: 1.3e-07\n  Maximum item intercept parameter change: 0.000586\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000129\n....................................................\nIteration 53     2024-10-07 10:04:15.354557\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4116 | Absolute change: 0.0015 | Relative change: 1.1e-07\n  Maximum item intercept parameter change: 0.00055\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000121\n....................................................\nIteration 54     2024-10-07 10:04:15.356291\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4103 | Absolute change: 0.0013 | Relative change: 1e-07\n  Maximum item intercept parameter change: 0.000516\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000113\n....................................................\nIteration 55     2024-10-07 10:04:15.358043\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4091 | Absolute change: 0.0012 | Relative change: 9e-08\n  Maximum item intercept parameter change: 0.000485\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0.000106\n....................................................\nIteration 56     2024-10-07 10:04:15.359781\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4081 | Absolute change: 0.001 | Relative change: 8e-08\n  Maximum item intercept parameter change: 0.000455\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 9.9e-05\n....................................................\nIteration 57     2024-10-07 10:04:15.361535\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4072 | Absolute change: 9e-04 | Relative change: 7e-08\n  Maximum item intercept parameter change: 0.000427\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 9.3e-05\n....................................................\nIteration 58     2024-10-07 10:04:15.363266\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4064 | Absolute change: 8e-04 | Relative change: 6e-08\n  Maximum item intercept parameter change: 0.000401\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 8.7e-05\n....................................................\nIteration 59     2024-10-07 10:04:15.365026\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4057 | Absolute change: 7e-04 | Relative change: 5e-08\n  Maximum item intercept parameter change: 0.000376\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 8.2e-05\n....................................................\nIteration 60     2024-10-07 10:04:15.374219\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.405 | Absolute change: 6e-04 | Relative change: 5e-08\n  Maximum item intercept parameter change: 0.000353\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 7.6e-05\n....................................................\nIteration 61     2024-10-07 10:04:15.376025\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.4045 | Absolute change: 5e-04 | Relative change: 4e-08\n  Maximum item intercept parameter change: 0.000331\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 7.2e-05\n....................................................\nIteration 62     2024-10-07 10:04:15.377874\nE Step\nM Step Intercepts   |----\n  Deviance = 13284.404 | Absolute change: 5e-04 | Relative change: 4e-08\n  Maximum item intercept parameter change: 0.000311\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 6.7e-05\n....................................................\nIteration 63     2024-10-07 10:04:15.379632\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4036 | Absolute change: 4e-04 | Relative change: 3e-08\n  Maximum item intercept parameter change: 0.000334\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 6.3e-05\n....................................................\nIteration 64     2024-10-07 10:04:15.381275\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4032 | Absolute change: 4e-04 | Relative change: 3e-08\n  Maximum item intercept parameter change: 0.000293\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 7.2e-05\n....................................................\nIteration 65     2024-10-07 10:04:15.382926\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4028 | Absolute change: 4e-04 | Relative change: 3e-08\n  Maximum item intercept parameter change: 0.000273\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 6.5e-05\n....................................................\nIteration 66     2024-10-07 10:04:15.384621\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4025 | Absolute change: 3e-04 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.000255\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 5.9e-05\n....................................................\nIteration 67     2024-10-07 10:04:15.386297\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4023 | Absolute change: 3e-04 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.000238\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 5.4e-05\n....................................................\nIteration 68     2024-10-07 10:04:15.38799\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.402 | Absolute change: 2e-04 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.000222\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 4.9e-05\n....................................................\nIteration 69     2024-10-07 10:04:15.389621\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4018 | Absolute change: 2e-04 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.000207\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 4.5e-05\n....................................................\nIteration 70     2024-10-07 10:04:15.391216\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4016 | Absolute change: 2e-04 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000194\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 4.2e-05\n....................................................\nIteration 71     2024-10-07 10:04:15.392836\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4015 | Absolute change: 2e-04 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000181\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 3.9e-05\n....................................................\nIteration 72     2024-10-07 10:04:15.394433\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4014 | Absolute change: 1e-04 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000169\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 3.6e-05\n....................................................\nIteration 73     2024-10-07 10:04:15.396068\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4012 | Absolute change: 1e-04 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000158\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 3.3e-05\n....................................................\nIteration 74     2024-10-07 10:04:15.39768\nE Step\nM Step Intercepts   |---\n  Deviance = 13284.4011 | Absolute change: 1e-04 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000147\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 3.1e-05\n....................................................\nIteration 75     2024-10-07 10:04:15.399316\nE Step\nM Step Intercepts   |--\n  Deviance = 13284.401 | Absolute change: 1e-04 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000125\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 2.9e-05\n....................................................\nIteration 76     2024-10-07 10:04:15.400806\nE Step\nM Step Intercepts   |--\n  Deviance = 13284.401 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000107\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 1.1e-05\n....................................................\nIteration 77     2024-10-07 10:04:15.402267\nE Step\nM Step Intercepts   |--\n  Deviance = 13284.4009 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000101\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 1.3e-05\n....................................................\nIteration 78     2024-10-07 10:04:15.40376\nE Step\nM Step Intercepts   |--\n  Deviance = 13284.4009 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 9.6e-05\n  Maximum item slope parameter change: 0\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 1.5e-05\n....................................................\nItem Parameters\n   xsi.index                          xsi.label     est\n1          1 disorganized_self.disciplined_Cat1 -3.7971\n2          2 disorganized_self.disciplined_Cat2 -1.7783\n3          3 disorganized_self.disciplined_Cat3 -0.7349\n4          4 disorganized_self.disciplined_Cat4  1.3246\n5          5                      ADHD_OCD_Cat1 -3.9697\n6          6                      ADHD_OCD_Cat2 -1.4140\n7          7                      ADHD_OCD_Cat3 -0.1798\n8          8                      ADHD_OCD_Cat4  3.7415\n9          9               chaotic_orderly_Cat1 -2.6995\n10        10               chaotic_orderly_Cat2 -0.5362\n11        11               chaotic_orderly_Cat3  0.4170\n12        12               chaotic_orderly_Cat4  3.2510\n13        13                 lazy_diligent_Cat1 -5.7702\n14        14                 lazy_diligent_Cat2 -3.3967\n15        15                 lazy_diligent_Cat3 -2.1475\n16        16                 lazy_diligent_Cat4  0.0552\n17        17                 tardy_on.time_Cat1 -3.9361\n18        18                 tardy_on.time_Cat2 -1.6475\n19        19                 tardy_on.time_Cat3 -0.4526\n20        20                 tardy_on.time_Cat4  1.8238\n21        21         spontaneous_scheduled_Cat1 -2.7638\n22        22         spontaneous_scheduled_Cat2 -0.8343\n23        23         spontaneous_scheduled_Cat3 -0.1865\n24        24         spontaneous_scheduled_Cat4  2.5848\n25        25    underachiever_overachiever_Cat1 -5.4051\n26        26    underachiever_overachiever_Cat2 -2.9387\n27        27    underachiever_overachiever_Cat3 -1.2721\n28        28    underachiever_overachiever_Cat4  1.6974\n...................................\nRegression Coefficients\n     [,1]\n[1,]    0\n\nVariance:\n      [,1]\n[1,] 5.702\n\n\nEAP Reliability:\n[1] 0.933\n\n-----------------------------\nStart:  2024-10-07 10:04:15.065714\nEnd:  2024-10-07 10:04:15.413612 \nTime difference of 0.3478987 secs\n\n\n------------------------------------------------------------\nTAM 4.2-21 (2024-02-19 18:52:08) \nR version 4.4.1 (2024-06-14) x86_64, linux-gnu | nodename=fv-az823-739 | login=unknown \n\nDate of Analysis: 2024-10-07 10:04:15.413612 \nTime difference of 0.3478987 secs\nComputation time: 0.3478987 \n\nMultidimensional Item Response Model in TAM \n\nIRT Model: PCM\nCall:\ntam.mml(resp = psych_dat[, -1], irtmodel = \"PCM\")\n\n------------------------------------------------------------\nNumber of iterations = 78 \nNumeric integration with 21 integration points\n\nDeviance = 13284.4 \nLog likelihood = -6642.2 \nNumber of persons = 889 \nNumber of persons used = 889 \nNumber of items = 7 \nNumber of estimated parameters = 29 \n    Item threshold parameters = 28 \n    Item slope parameters = 0 \n    Regression parameters = 0 \n    Variance/covariance parameters = 1 \n\nAIC = 13342  | penalty=58    | AIC=-2*LL + 2*p \nAIC3 = 13371  | penalty=87    | AIC3=-2*LL + 3*p \nBIC = 13481  | penalty=196.91    | BIC=-2*LL + log(n)*p \naBIC = 13389  | penalty=104.68    | aBIC=-2*LL + log((n-2)/24)*p  (adjusted BIC) \nCAIC = 13510  | penalty=225.91    | CAIC=-2*LL + [log(n)+1]*p  (consistent AIC) \nAICc = 13344  | penalty=60.03    | AICc=-2*LL + 2*p + 2*p*(p+1)/(n-p-1)  (bias corrected AIC) \nGHP = 1.07202     | GHP=( -LL + p ) / (#Persons * #Items)  (Gilula-Haberman log penalty) \n\n------------------------------------------------------------\nEAP Reliability\n[1] 0.933\n------------------------------------------------------------\nCovariances and Variances\n      [,1]\n[1,] 5.702\n------------------------------------------------------------\nCorrelations and Standard Deviations (in the diagonal)\n      [,1]\n[1,] 2.388\n------------------------------------------------------------\nRegression Coefficients\n     [,1]\n[1,]    0\n------------------------------------------------------------\nItem Parameters -A*Xsi\n                           item   N     M xsi.item AXsi_.Cat1 AXsi_.Cat2\n1 disorganized_self.disciplined 889 2.593   -1.246     -3.797     -5.575\n2                      ADHD_OCD 889 2.250   -0.455     -3.970     -5.384\n3               chaotic_orderly 889 2.000    0.108     -2.699     -3.236\n4                 lazy_diligent 889 3.142   -2.815     -5.770     -9.167\n5                 tardy_on.time 889 2.484   -1.053     -3.936     -5.584\n6         spontaneous_scheduled 889 2.191   -0.300     -2.764     -3.598\n7    underachiever_overachiever 889 2.783   -1.980     -5.405     -8.344\n  AXsi_.Cat3 AXsi_.Cat4 B.Cat1.Dim1 B.Cat2.Dim1 B.Cat3.Dim1 B.Cat4.Dim1\n1     -6.310     -4.986           1           2           3           4\n2     -5.563     -1.822           1           2           3           4\n3     -2.819      0.432           1           2           3           4\n4    -11.314    -11.259           1           2           3           4\n5     -6.036     -4.212           1           2           3           4\n6     -3.785     -1.200           1           2           3           4\n7     -9.616     -7.919           1           2           3           4\n\nItem Parameters Xsi\n                                      xsi se.xsi\ndisorganized_self.disciplined_Cat1 -3.797  0.175\ndisorganized_self.disciplined_Cat2 -1.778  0.124\ndisorganized_self.disciplined_Cat3 -0.735  0.107\ndisorganized_self.disciplined_Cat4  1.325  0.104\nADHD_OCD_Cat1                      -3.970  0.172\nADHD_OCD_Cat2                      -1.414  0.114\nADHD_OCD_Cat3                      -0.180  0.100\nADHD_OCD_Cat4                       3.741  0.142\nchaotic_orderly_Cat1               -2.699  0.133\nchaotic_orderly_Cat2               -0.536  0.108\nchaotic_orderly_Cat3                0.417  0.105\nchaotic_orderly_Cat4                3.251  0.135\nlazy_diligent_Cat1                 -5.770  0.291\nlazy_diligent_Cat2                 -3.397  0.171\nlazy_diligent_Cat3                 -2.147  0.121\nlazy_diligent_Cat4                  0.055  0.096\ntardy_on.time_Cat1                 -3.936  0.175\ntardy_on.time_Cat2                 -1.647  0.119\ntardy_on.time_Cat3                 -0.453  0.104\ntardy_on.time_Cat4                  1.824  0.109\nspontaneous_scheduled_Cat1         -2.764  0.139\nspontaneous_scheduled_Cat2         -0.834  0.113\nspontaneous_scheduled_Cat3         -0.187  0.105\nspontaneous_scheduled_Cat4          2.585  0.119\nunderachiever_overachiever_Cat1    -5.405  0.254\nunderachiever_overachiever_Cat2    -2.939  0.145\nunderachiever_overachiever_Cat3    -1.272  0.105\nunderachiever_overachiever_Cat4     1.697  0.103\n\nItem Parameters in IRT parameterization\n                           item alpha   beta tau.Cat1 tau.Cat2 tau.Cat3\n1 disorganized_self.disciplined     1 -1.246   -2.551   -0.532    0.512\n2                      ADHD_OCD     1 -0.455   -3.514   -0.959    0.276\n3               chaotic_orderly     1  0.108   -2.808   -0.644    0.309\n4                 lazy_diligent     1 -2.815   -2.955   -0.582    0.667\n5                 tardy_on.time     1 -1.053   -2.883   -0.594    0.600\n6         spontaneous_scheduled     1 -0.300   -2.464   -0.534    0.113\n7    underachiever_overachiever     1 -1.980   -3.425   -0.959    0.708\n  tau.Cat4\n1    2.571\n2    4.197\n3    3.143\n4    2.870\n5    2.877\n6    2.885\n7    3.677\n\n\n                                           xsi     se.xsi\ndisorganized_self.disciplined_Cat1 -3.79709749 0.17457941\ndisorganized_self.disciplined_Cat2 -1.77828685 0.12404654\ndisorganized_self.disciplined_Cat3 -0.73487787 0.10655057\ndisorganized_self.disciplined_Cat4  1.32457648 0.10390882\nADHD_OCD_Cat1                      -3.96970497 0.17206746\nADHD_OCD_Cat2                      -1.41401382 0.11376202\nADHD_OCD_Cat3                      -0.17977218 0.09962925\nADHD_OCD_Cat4                       3.74149496 0.14211581\nchaotic_orderly_Cat1               -2.69946448 0.13307165\nchaotic_orderly_Cat2               -0.53622820 0.10766372\nchaotic_orderly_Cat3                0.41697289 0.10463369\nchaotic_orderly_Cat4                3.25103731 0.13503059\nlazy_diligent_Cat1                 -5.77019884 0.29142669\nlazy_diligent_Cat2                 -3.39668299 0.17080254\nlazy_diligent_Cat3                 -2.14749301 0.12109283\nlazy_diligent_Cat4                  0.05521047 0.09558887\ntardy_on.time_Cat1                 -3.93610335 0.17516854\ntardy_on.time_Cat2                 -1.64749957 0.11924547\ntardy_on.time_Cat3                 -0.45264211 0.10388266\ntardy_on.time_Cat4                  1.82379881 0.10869816\nspontaneous_scheduled_Cat1         -2.76380889 0.13870791\nspontaneous_scheduled_Cat2         -0.83427238 0.11310941\nspontaneous_scheduled_Cat3         -0.18654074 0.10500905\nspontaneous_scheduled_Cat4          2.58478518 0.11940568\nunderachiever_overachiever_Cat1    -5.40509039 0.25403635\nunderachiever_overachiever_Cat2    -2.93873958 0.14531083\nunderachiever_overachiever_Cat3    -1.27212871 0.10459447\nunderachiever_overachiever_Cat4     1.69738710 0.10346930\n\n\ncharacter(0)\n\n\nIteration in WLE/MLE estimation  1   | Maximal change  2.0474 \nIteration in WLE/MLE estimation  2   | Maximal change  1.09 \nIteration in WLE/MLE estimation  3   | Maximal change  0.3975 \nIteration in WLE/MLE estimation  4   | Maximal change  0.0102 \nIteration in WLE/MLE estimation  5   | Maximal change  0.002 \nIteration in WLE/MLE estimation  6   | Maximal change  4e-04 \nIteration in WLE/MLE estimation  7   | Maximal change  1e-04 \n----\n WLE Reliability= 0.918 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIteration in WLE/MLE estimation  1   | Maximal change  2.0474 \nIteration in WLE/MLE estimation  2   | Maximal change  1.09 \nIteration in WLE/MLE estimation  3   | Maximal change  0.3975 \nIteration in WLE/MLE estimation  4   | Maximal change  0.0102 \nIteration in WLE/MLE estimation  5   | Maximal change  0.002 \nIteration in WLE/MLE estimation  6   | Maximal change  4e-04 \nIteration in WLE/MLE estimation  7   | Maximal change  1e-04 \n----\n WLE Reliability= 0.918 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n....................................................\n Plots exported in png format into folder:\n /home/runner/work/IRT_workshop/IRT_workshop/slides/xPL/Plots\n\n\n                           item Outfit Outfit_t Outfit_p Infit Infit_t Infit_p\n1 disorganized_self.disciplined   0.63    -6.18     0.00  0.66   -7.62    0.00\n2                      ADHD_OCD   0.84    -3.25     0.00  0.84   -3.56    0.00\n3               chaotic_orderly   0.90    -1.82     0.07  0.91   -1.92    0.05\n4                 lazy_diligent   0.96    -0.29     0.77  1.01    0.26    0.80\n5                 tardy_on.time   0.65    -6.76     0.00  0.67   -7.71    0.00\n6         spontaneous_scheduled   1.06     1.11     0.27  1.07    1.34    0.18\n7    underachiever_overachiever   1.64     9.05     0.00  1.56    9.84    0.00\n\n\n**** Calculate Residuals \n**** Calculate Counts \n**** Calculate Covariances \n\n\n**** Calculate Residuals \n**** Calculate Counts \n**** Calculate Covariances \n\n\n     MADaQ3    maxaQ3            p\n1 0.2127653 0.5200699 1.149361e-64\n\n\n                           item     Group1\n1 disorganized_self.disciplined 0.05481346\n2                      ADHD_OCD 0.03044422\n3               chaotic_orderly 0.02499056\n4                 lazy_diligent 0.02921001\n5                 tardy_on.time 0.06348273\n6         spontaneous_scheduled 0.01908362\n7    underachiever_overachiever 0.06894770\n\n\n\n\n\nResults of PCM estimation: \n\nCall:  PCM(X = psych_dat) \n\nConditional log-likelihood: -4387.207 \nNumber of iterations: 96 \nNumber of parameters: 31 \n\nItem (Category) Difficulty Parameters (eta): with 0.95 CI:\n                                 Estimate Std. Error lower CI upper CI\nmessy_neat.c2                      -0.813      0.194   -1.193   -0.432\nmessy_neat.c3                       1.239      0.216    0.817    1.662\nmessy_neat.c4                       6.087      0.269    5.558    6.615\ndisorganized_self.disciplined.c1   -1.960      0.193   -2.339   -1.581\ndisorganized_self.disciplined.c2   -1.625      0.211   -2.039   -1.210\ndisorganized_self.disciplined.c3   -0.175      0.224   -0.614    0.263\ndisorganized_self.disciplined.c4    3.485      0.256    2.983    3.987\nADHD_OCD.c1                        -2.135      0.189   -2.506   -1.765\nADHD_OCD.c2                        -1.425      0.205   -1.826   -1.024\nADHD_OCD.c3                         0.640      0.219    0.210    1.070\nADHD_OCD.c4                         6.817      0.287    6.254    7.380\nchaotic_orderly.c1                 -0.677      0.140   -0.952   -0.402\nchaotic_orderly.c2                  0.954      0.174    0.613    1.295\nchaotic_orderly.c3                  3.657      0.214    3.237    4.076\nchaotic_orderly.c4                  9.336      0.295    8.758    9.913\nlazy_diligent.c1                   -4.401      0.345   -5.077   -3.725\nlazy_diligent.c2                   -5.861      0.368   -6.581   -5.140\nlazy_diligent.c3                   -5.889      0.353   -6.580   -5.198\nlazy_diligent.c4                   -3.581      0.338   -4.242   -2.919\ntardy_on.time.c1                   -2.112      0.194   -2.491   -1.733\ntardy_on.time.c2                   -1.642      0.210   -2.053   -1.231\ntardy_on.time.c3                    0.111      0.223   -0.326    0.548\ntardy_on.time.c4                    4.297      0.261    3.785    4.809\nspontaneous_scheduled.c1           -0.754      0.148   -1.044   -0.465\nspontaneous_scheduled.c2            0.553      0.179    0.202    0.905\nspontaneous_scheduled.c3            2.615      0.211    2.201    3.029\nspontaneous_scheduled.c4            7.597      0.276    7.055    8.139\nunderachiever_overachiever.c1      -3.936      0.295   -4.515   -3.358\nunderachiever_overachiever.c2      -4.846      0.307   -5.448   -4.243\nunderachiever_overachiever.c3      -3.954      0.295   -4.533   -3.375\nunderachiever_overachiever.c4       0.084      0.298   -0.501    0.669\n\nItem Easiness Parameters (beta) with 0.95 CI:\n                                      Estimate Std. Error lower CI upper CI\nbeta messy_neat.c1                       1.686      0.174    1.346    2.027\nbeta messy_neat.c2                       0.813      0.194    0.432    1.193\nbeta messy_neat.c3                      -1.239      0.216   -1.662   -0.817\nbeta messy_neat.c4                      -6.087      0.269   -6.615   -5.558\nbeta disorganized_self.disciplined.c1    1.960      0.193    1.581    2.339\nbeta disorganized_self.disciplined.c2    1.625      0.211    1.210    2.039\nbeta disorganized_self.disciplined.c3    0.175      0.224   -0.263    0.614\nbeta disorganized_self.disciplined.c4   -3.485      0.256   -3.987   -2.983\nbeta ADHD_OCD.c1                         2.135      0.189    1.765    2.506\nbeta ADHD_OCD.c2                         1.425      0.205    1.024    1.826\nbeta ADHD_OCD.c3                        -0.640      0.219   -1.070   -0.210\nbeta ADHD_OCD.c4                        -6.817      0.287   -7.380   -6.254\nbeta chaotic_orderly.c1                  0.677      0.140    0.402    0.952\nbeta chaotic_orderly.c2                 -0.954      0.174   -1.295   -0.613\nbeta chaotic_orderly.c3                 -3.657      0.214   -4.076   -3.237\nbeta chaotic_orderly.c4                 -9.336      0.295   -9.913   -8.758\nbeta lazy_diligent.c1                    4.401      0.345    3.725    5.077\nbeta lazy_diligent.c2                    5.861      0.368    5.140    6.581\nbeta lazy_diligent.c3                    5.889      0.353    5.198    6.580\nbeta lazy_diligent.c4                    3.581      0.338    2.919    4.242\nbeta tardy_on.time.c1                    2.112      0.194    1.733    2.491\nbeta tardy_on.time.c2                    1.642      0.210    1.231    2.053\nbeta tardy_on.time.c3                   -0.111      0.223   -0.548    0.326\nbeta tardy_on.time.c4                   -4.297      0.261   -4.809   -3.785\nbeta spontaneous_scheduled.c1            0.754      0.148    0.465    1.044\nbeta spontaneous_scheduled.c2           -0.553      0.179   -0.905   -0.202\nbeta spontaneous_scheduled.c3           -2.615      0.211   -3.029   -2.201\nbeta spontaneous_scheduled.c4           -7.597      0.276   -8.139   -7.055\nbeta underachiever_overachiever.c1       3.936      0.295    3.358    4.515\nbeta underachiever_overachiever.c2       4.846      0.307    4.243    5.448\nbeta underachiever_overachiever.c3       3.954      0.295    3.375    4.533\nbeta underachiever_overachiever.c4      -0.084      0.298   -0.669    0.501\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesign Matrix Block 1:\n                              Location Threshold 1 Threshold 2 Threshold 3\nmessy_neat                     1.52164    -1.68636     0.87371     2.05193\ndisorganized_self.disciplined  0.87116    -1.96031     0.33549     1.44938\nADHD_OCD                       1.70425    -2.13542     0.71080     2.06417\nchaotic_orderly                2.33392    -0.67674     1.63108     2.70220\nlazy_diligent                 -0.89516    -4.40096    -1.45987    -0.02794\ntardy_on.time                  1.07431    -2.11192     0.46992     1.75327\nspontaneous_scheduled          1.89925    -0.75433     1.30753     2.06173\nunderachiever_overachiever     0.02106    -3.93612    -0.90950     0.89170\n                              Threshold 4\nmessy_neat                        4.84727\ndisorganized_self.disciplined     3.66008\nADHD_OCD                          6.17747\nchaotic_orderly                   5.67916\nlazy_diligent                     2.30814\ntardy_on.time                     4.18596\nspontaneous_scheduled             4.98209\nunderachiever_overachiever        4.03816"
  },
  {
    "objectID": "slides/xPL/xPL.html#personenspezifische-kurve-zeichnen",
    "href": "slides/xPL/xPL.html#personenspezifische-kurve-zeichnen",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Personenspezifische Kurve zeichnen?",
    "text": "Personenspezifische Kurve zeichnen?"
  },
  {
    "objectID": "slides/xPL/xPL.html#reversal-vs.-non-reversal.",
    "href": "slides/xPL/xPL.html#reversal-vs.-non-reversal.",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Reversal vs. non-reversal.",
    "text": "Reversal vs. non-reversal."
  },
  {
    "objectID": "slides/xPL/xPL.html#generalized-partial-credit-model",
    "href": "slides/xPL/xPL.html#generalized-partial-credit-model",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Generalized Partial Credit Model?",
    "text": "Generalized Partial Credit Model?"
  },
  {
    "objectID": "slides/xPL/xPL.html#rating-scale-model",
    "href": "slides/xPL/xPL.html#rating-scale-model",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Rating Scale Model?",
    "text": "Rating Scale Model?"
  },
  {
    "objectID": "slides/xPL/xPL.html#beispiele",
    "href": "slides/xPL/xPL.html#beispiele",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beispiele",
    "text": "Beispiele"
  },
  {
    "objectID": "slides/xPL/xPL.html#evtl-wann-welches-modell",
    "href": "slides/xPL/xPL.html#evtl-wann-welches-modell",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Evtl: Wann welches Modell",
    "text": "Evtl: Wann welches Modell"
  },
  {
    "objectID": "slides/xPL/xPL.html#bildquellen",
    "href": "slides/xPL/xPL.html#bildquellen",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Pawel Czerwinski auf Unsplash\n\nFoto von Crawford Jolly auf Unsplash"
  },
  {
    "objectID": "exercises/intro_r/merging_ex.html",
    "href": "exercises/intro_r/merging_ex.html",
    "title": "Merging",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n## Reshape into long format:\npsych_stats &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\n## Take a look at the data sets\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\ntibble [323,596 × 3] (S3: tbl_df/tbl/data.frame)\n $ char_id : chr [1:323596] \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ question: chr [1:323596] \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating  : num [1:323596] 95.7 95.2 6.1 6.2 6.4 ...\n\n\n\n\n\nNow we have gotten to know our characters data set a bit more. However, the personality ratings are not included yet. For that, we need to combine it with the psych_stats data set.\n\nMerge the characters data frame and the psych_stats data frame on a common column.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIdentify the common columns. Are they named the same in both data frames? Look at the documentation of ?merge to see, how you can merge data frames that don’t have identically named columns.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFirst, let’s take a look at both data sets again:\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\ntibble [323,596 × 3] (S3: tbl_df/tbl/data.frame)\n $ char_id : chr [1:323596] \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ question: chr [1:323596] \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating  : num [1:323596] 95.7 95.2 6.1 6.2 6.4 ...\n\n\nIt seems like both data frames have a column containing an ID for the character. We can use that column for merging:\n\ncharacters_stats &lt;- merge(\n  x = characters,\n  y = psych_stats,\n  by.x = \"id\", \n  by.y = \"char_id\"\n)\n\nstr(characters_stats)\n\n'data.frame':   323596 obs. of  9 variables:\n $ id        : chr  \"AD1\" \"AD1\" \"AD1\" \"AD1\" ...\n $ name      : chr  \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" ...\n $ uni_id    : chr  \"AD\" \"AD\" \"AD\" \"AD\" ...\n $ uni_name  : chr  \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" ...\n $ notability: num  76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  68.6 73.3 10.8 22.2 45.1 16.2 86.3 74.7 15.4 36.2 ...\n\n\nWorked like a charm!",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Merging"
    ]
  },
  {
    "objectID": "exercises/intro_r/merging_ex.html#exercise-1",
    "href": "exercises/intro_r/merging_ex.html#exercise-1",
    "title": "Merging",
    "section": "",
    "text": "Merge the characters data frame and the psych_stats data frame on a common column.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIdentify the common columns. Are they named the same in both data frames? Look at the documentation of ?merge to see, how you can merge data frames that don’t have identically named columns.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFirst, let’s take a look at both data sets again:\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\ntibble [323,596 × 3] (S3: tbl_df/tbl/data.frame)\n $ char_id : chr [1:323596] \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ question: chr [1:323596] \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating  : num [1:323596] 95.7 95.2 6.1 6.2 6.4 ...\n\n\nIt seems like both data frames have a column containing an ID for the character. We can use that column for merging:\n\ncharacters_stats &lt;- merge(\n  x = characters,\n  y = psych_stats,\n  by.x = \"id\", \n  by.y = \"char_id\"\n)\n\nstr(characters_stats)\n\n'data.frame':   323596 obs. of  9 variables:\n $ id        : chr  \"AD1\" \"AD1\" \"AD1\" \"AD1\" ...\n $ name      : chr  \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" ...\n $ uni_id    : chr  \"AD\" \"AD\" \"AD\" \"AD\" ...\n $ uni_name  : chr  \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" ...\n $ notability: num  76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  68.6 73.3 10.8 22.2 45.1 16.2 86.3 74.7 15.4 36.2 ...\n\n\nWorked like a charm!",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Merging"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html",
    "href": "exercises/intro_r/subsetting_ex.html",
    "title": "Subsetting",
    "section": "",
    "text": "Vorheriger Code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n\n\n\n\nKorrigiere den folgenden Code, sodass nur die ersten 10 Zeilen und die letzten 3 Spalten ausgewählt werden.\n\ncharacters[4:6, 10]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWir müssen die Zeilen, die wir auswählen wollen, vor dem Komma , schreiben, die Spalten danach.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[1:10, 4:6]\n\n   uni_name notability\n1   Friends       79.7\n2   Friends       76.7\n3   Friends       74.4\n4   Friends       74.3\n5   Friends       72.6\n6   Friends       51.6\n7  Euphoria       86.5\n8  Euphoria       84.2\n9  Euphoria       82.6\n10 Euphoria       65.6\n                                                        link\n1   https://openpsychometrics.org/tests/characters/stats/F/2\n2   https://openpsychometrics.org/tests/characters/stats/F/1\n3   https://openpsychometrics.org/tests/characters/stats/F/5\n4   https://openpsychometrics.org/tests/characters/stats/F/4\n5   https://openpsychometrics.org/tests/characters/stats/F/3\n6   https://openpsychometrics.org/tests/characters/stats/F/6\n7  https://openpsychometrics.org/tests/characters/stats/EU/1\n8  https://openpsychometrics.org/tests/characters/stats/EU/2\n9  https://openpsychometrics.org/tests/characters/stats/EU/6\n10 https://openpsychometrics.org/tests/characters/stats/EU/3\n\n\n\n\n\n\n\nWarum funktioniert der folgende Code nicht? Korrigiere ihn in deinem eigenen Skript.\n\n\ncharacters[uni_name == \"Friends\", ]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nYou need to extract the column from the data frame with $ before you can compare it to the string.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Friends\", ]\n\n  id           name uni_id uni_name notability\n1 F2  Monica Geller      F  Friends       79.7\n2 F1   Rachel Green      F  Friends       76.7\n3 F5  Chandler Bing      F  Friends       74.4\n4 F4 Joey Tribbiani      F  Friends       74.3\n5 F3  Phoebe Buffay      F  Friends       72.6\n6 F6    Ross Geller      F  Friends       51.6\n                                                      link\n1 https://openpsychometrics.org/tests/characters/stats/F/2\n2 https://openpsychometrics.org/tests/characters/stats/F/1\n3 https://openpsychometrics.org/tests/characters/stats/F/5\n4 https://openpsychometrics.org/tests/characters/stats/F/4\n5 https://openpsychometrics.org/tests/characters/stats/F/3\n6 https://openpsychometrics.org/tests/characters/stats/F/6\n                                                                  image_link\n1 https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\n2 https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\n3 https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\n4 https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\n5 https://openpsychometrics.org/tests/characters/test-resources/pics/F/3.jpg\n6 https://openpsychometrics.org/tests/characters/test-resources/pics/F/6.jpg\n\n\n\n\n\n\nWhich characters will this code extract: characters[(characters$uni_name == \"Harry Potter\" | characters$uni_name != \"Harry Potter\") & !(characters$notability &gt; 90), ]?\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\nKind of a trick question: because we select all characters that are from the Harry Potter universe OR are not from there, we select all characters independent of their TV show. But we select all characters that have notability under 90 (beware of the ! in front of the respective comparison).\n\n\n\n\n\nWhich character(s) from “Game of Thrones” has a notability rating over 90? Use Base R.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou need to define a logical vector which contains TRUE values for all “Game of Thrones” characters that have a notability over 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Game of Thrones\" & characters$notability &gt; 90, ]\n\n     id             name uni_id        uni_name notability\n18 GOT2 Tyrion Lannister    GOT Game of Thrones       90.8\n                                                         link\n18 https://openpsychometrics.org/tests/characters/stats/GOT/2\n                                                                     image_link\n18 https://openpsychometrics.org/tests/characters/test-resources/pics/GOT/2.jpg\n\n\nThat’s only Tyrion Lannister.\n\n\n\n\nWhich characters from “How I Met Your Mother” or “Breaking Bad” are included in the data? Use the tidyverse.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the filter() function.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\nfilter(characters, uni_name %in% c(\"How I Met Your Mother\", \"Breaking Bad\"))\n\n       id              name uni_id              uni_name notability\n1  HIMYM4    Barney Stinson  HIMYM How I Met Your Mother       76.0\n2  HIMYM3 Robin Scherbatsky  HIMYM How I Met Your Mother       74.2\n3  HIMYM5       Lily Aldrin  HIMYM How I Met Your Mother       74.1\n4  HIMYM2  Marshall Eriksen  HIMYM How I Met Your Mother       71.0\n5  HIMYM1         Ted Mosby  HIMYM How I Met Your Mother       63.7\n6     BB1      Walter White     BB          Breaking Bad       91.3\n7     BB3     Jesse Pinkman     BB          Breaking Bad       88.9\n8     BB9  Mike Ehrmantraut     BB          Breaking Bad       82.5\n9     BB8         Gus Fring     BB          Breaking Bad       79.6\n10    BB4     Hank Schrader     BB          Breaking Bad       74.8\n11    BB7      Saul Goodman     BB          Breaking Bad       73.8\n12   BB10     Jane Margolis     BB          Breaking Bad       61.3\n13    BB2      Skyler White     BB          Breaking Bad       55.4\n14    BB6       Flynn White     BB          Breaking Bad       46.8\n15    BB5    Marie Schrader     BB          Breaking Bad       27.9\n                                                           link\n1  https://openpsychometrics.org/tests/characters/stats/HIMYM/4\n2  https://openpsychometrics.org/tests/characters/stats/HIMYM/3\n3  https://openpsychometrics.org/tests/characters/stats/HIMYM/5\n4  https://openpsychometrics.org/tests/characters/stats/HIMYM/2\n5  https://openpsychometrics.org/tests/characters/stats/HIMYM/1\n6     https://openpsychometrics.org/tests/characters/stats/BB/1\n7     https://openpsychometrics.org/tests/characters/stats/BB/3\n8     https://openpsychometrics.org/tests/characters/stats/BB/9\n9     https://openpsychometrics.org/tests/characters/stats/BB/8\n10    https://openpsychometrics.org/tests/characters/stats/BB/4\n11    https://openpsychometrics.org/tests/characters/stats/BB/7\n12   https://openpsychometrics.org/tests/characters/stats/BB/10\n13    https://openpsychometrics.org/tests/characters/stats/BB/2\n14    https://openpsychometrics.org/tests/characters/stats/BB/6\n15    https://openpsychometrics.org/tests/characters/stats/BB/5\n                                                                       image_link\n1  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/4.jpg\n2  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/3.jpg\n3  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/5.jpg\n4  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/2.jpg\n5  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/1.jpg\n6     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/1.jpg\n7     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/3.jpg\n8     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/9.jpg\n9     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/8.jpg\n10    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/4.jpg\n11    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/7.jpg\n12   https://openpsychometrics.org/tests/characters/test-resources/pics/BB/10.jpg\n13    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/2.jpg\n14    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/6.jpg\n15    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/5.jpg",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html#frage",
    "href": "exercises/intro_r/subsetting_ex.html#frage",
    "title": "Subsetting",
    "section": "",
    "text": "Korrigiere den folgenden Code, sodass nur die ersten 10 Zeilen und die letzten 3 Spalten ausgewählt werden.\n\ncharacters[4:6, 10]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWir müssen die Zeilen, die wir auswählen wollen, vor dem Komma , schreiben, die Spalten danach.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[1:10, 4:6]\n\n   uni_name notability\n1   Friends       79.7\n2   Friends       76.7\n3   Friends       74.4\n4   Friends       74.3\n5   Friends       72.6\n6   Friends       51.6\n7  Euphoria       86.5\n8  Euphoria       84.2\n9  Euphoria       82.6\n10 Euphoria       65.6\n                                                        link\n1   https://openpsychometrics.org/tests/characters/stats/F/2\n2   https://openpsychometrics.org/tests/characters/stats/F/1\n3   https://openpsychometrics.org/tests/characters/stats/F/5\n4   https://openpsychometrics.org/tests/characters/stats/F/4\n5   https://openpsychometrics.org/tests/characters/stats/F/3\n6   https://openpsychometrics.org/tests/characters/stats/F/6\n7  https://openpsychometrics.org/tests/characters/stats/EU/1\n8  https://openpsychometrics.org/tests/characters/stats/EU/2\n9  https://openpsychometrics.org/tests/characters/stats/EU/6\n10 https://openpsychometrics.org/tests/characters/stats/EU/3",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html#frage-1",
    "href": "exercises/intro_r/subsetting_ex.html#frage-1",
    "title": "Subsetting",
    "section": "",
    "text": "Warum funktioniert der folgende Code nicht? Korrigiere ihn in deinem eigenen Skript.\n\n\ncharacters[uni_name == \"Friends\", ]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nYou need to extract the column from the data frame with $ before you can compare it to the string.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Friends\", ]\n\n  id           name uni_id uni_name notability\n1 F2  Monica Geller      F  Friends       79.7\n2 F1   Rachel Green      F  Friends       76.7\n3 F5  Chandler Bing      F  Friends       74.4\n4 F4 Joey Tribbiani      F  Friends       74.3\n5 F3  Phoebe Buffay      F  Friends       72.6\n6 F6    Ross Geller      F  Friends       51.6\n                                                      link\n1 https://openpsychometrics.org/tests/characters/stats/F/2\n2 https://openpsychometrics.org/tests/characters/stats/F/1\n3 https://openpsychometrics.org/tests/characters/stats/F/5\n4 https://openpsychometrics.org/tests/characters/stats/F/4\n5 https://openpsychometrics.org/tests/characters/stats/F/3\n6 https://openpsychometrics.org/tests/characters/stats/F/6\n                                                                  image_link\n1 https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\n2 https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\n3 https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\n4 https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\n5 https://openpsychometrics.org/tests/characters/test-resources/pics/F/3.jpg\n6 https://openpsychometrics.org/tests/characters/test-resources/pics/F/6.jpg\n\n\n\n\n\n\nWhich characters will this code extract: characters[(characters$uni_name == \"Harry Potter\" | characters$uni_name != \"Harry Potter\") & !(characters$notability &gt; 90), ]?\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\nKind of a trick question: because we select all characters that are from the Harry Potter universe OR are not from there, we select all characters independent of their TV show. But we select all characters that have notability under 90 (beware of the ! in front of the respective comparison).",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html#exercise-3",
    "href": "exercises/intro_r/subsetting_ex.html#exercise-3",
    "title": "Subsetting",
    "section": "",
    "text": "Which character(s) from “Game of Thrones” has a notability rating over 90? Use Base R.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou need to define a logical vector which contains TRUE values for all “Game of Thrones” characters that have a notability over 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Game of Thrones\" & characters$notability &gt; 90, ]\n\n     id             name uni_id        uni_name notability\n18 GOT2 Tyrion Lannister    GOT Game of Thrones       90.8\n                                                         link\n18 https://openpsychometrics.org/tests/characters/stats/GOT/2\n                                                                     image_link\n18 https://openpsychometrics.org/tests/characters/test-resources/pics/GOT/2.jpg\n\n\nThat’s only Tyrion Lannister.\n\n\n\n\nWhich characters from “How I Met Your Mother” or “Breaking Bad” are included in the data? Use the tidyverse.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the filter() function.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\nfilter(characters, uni_name %in% c(\"How I Met Your Mother\", \"Breaking Bad\"))\n\n       id              name uni_id              uni_name notability\n1  HIMYM4    Barney Stinson  HIMYM How I Met Your Mother       76.0\n2  HIMYM3 Robin Scherbatsky  HIMYM How I Met Your Mother       74.2\n3  HIMYM5       Lily Aldrin  HIMYM How I Met Your Mother       74.1\n4  HIMYM2  Marshall Eriksen  HIMYM How I Met Your Mother       71.0\n5  HIMYM1         Ted Mosby  HIMYM How I Met Your Mother       63.7\n6     BB1      Walter White     BB          Breaking Bad       91.3\n7     BB3     Jesse Pinkman     BB          Breaking Bad       88.9\n8     BB9  Mike Ehrmantraut     BB          Breaking Bad       82.5\n9     BB8         Gus Fring     BB          Breaking Bad       79.6\n10    BB4     Hank Schrader     BB          Breaking Bad       74.8\n11    BB7      Saul Goodman     BB          Breaking Bad       73.8\n12   BB10     Jane Margolis     BB          Breaking Bad       61.3\n13    BB2      Skyler White     BB          Breaking Bad       55.4\n14    BB6       Flynn White     BB          Breaking Bad       46.8\n15    BB5    Marie Schrader     BB          Breaking Bad       27.9\n                                                           link\n1  https://openpsychometrics.org/tests/characters/stats/HIMYM/4\n2  https://openpsychometrics.org/tests/characters/stats/HIMYM/3\n3  https://openpsychometrics.org/tests/characters/stats/HIMYM/5\n4  https://openpsychometrics.org/tests/characters/stats/HIMYM/2\n5  https://openpsychometrics.org/tests/characters/stats/HIMYM/1\n6     https://openpsychometrics.org/tests/characters/stats/BB/1\n7     https://openpsychometrics.org/tests/characters/stats/BB/3\n8     https://openpsychometrics.org/tests/characters/stats/BB/9\n9     https://openpsychometrics.org/tests/characters/stats/BB/8\n10    https://openpsychometrics.org/tests/characters/stats/BB/4\n11    https://openpsychometrics.org/tests/characters/stats/BB/7\n12   https://openpsychometrics.org/tests/characters/stats/BB/10\n13    https://openpsychometrics.org/tests/characters/stats/BB/2\n14    https://openpsychometrics.org/tests/characters/stats/BB/6\n15    https://openpsychometrics.org/tests/characters/stats/BB/5\n                                                                       image_link\n1  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/4.jpg\n2  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/3.jpg\n3  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/5.jpg\n4  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/2.jpg\n5  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/1.jpg\n6     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/1.jpg\n7     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/3.jpg\n8     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/9.jpg\n9     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/8.jpg\n10    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/4.jpg\n11    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/7.jpg\n12   https://openpsychometrics.org/tests/characters/test-resources/pics/BB/10.jpg\n13    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/2.jpg\n14    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/6.jpg\n15    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/5.jpg",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/index_intro_r.html",
    "href": "exercises/index_intro_r.html",
    "title": "Einführung in R",
    "section": "",
    "text": "Sortieren nach\n       Voreinstellung\n         \n          Titel\n        \n         \n          Autor:in\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitel\n\n\nAutor:in\n\n\n\n\n\n\nEinlesen von Daten\n\n\nNicklas Hafiz\n\n\n\n\nMerging\n\n\nNicklas Hafiz\n\n\n\n\nMissings\n\n\nNicklas Hafiz\n\n\n\n\nReshaping\n\n\nNicklas Hafiz\n\n\n\n\nSubsetting\n\n\nNicklas Hafiz\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen",
      "Einführung in R"
    ]
  },
  {
    "objectID": "exercises/linking/linking.html",
    "href": "exercises/linking/linking.html",
    "title": "Linking",
    "section": "",
    "text": "library(eatModel)\n\nLoading required package: TAM\n\n\nLoading required package: CDM\n\n\nLoading required package: mvtnorm\n\n\n**********************************\n** CDM 8.2-6 (2022-08-25 15:43:23)       \n** Cognitive Diagnostic Models  **\n**********************************\n\n\n* TAM 4.2-21 (2024-02-19 18:52:08)\n\n\nLoading required package: parallel\n\nlibrary(TAM)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n## Ankeritems auf alle Fälle vorgeben!\n\n\ndata(trends)",
    "crumbs": [
      "Übungen",
      "Linking",
      "Linking"
    ]
  },
  {
    "objectID": "exercises/linking/linking.html#übung-2",
    "href": "exercises/linking/linking.html#übung-2",
    "title": "Linking",
    "section": "Übung 2",
    "text": "Übung 2\n\n## Dif Analyse mit  TAM: https://www.edmeasurementsurveys.com/TAM/Tutorials/7DIF.htm\n## Nutzt 1pl. 2pl vermutlich direkt komplizierter oder? \n## Mit eRm: https://bookdown.org/chua/new_rasch_demo2/DIF.html",
    "crumbs": [
      "Übungen",
      "Linking",
      "Linking"
    ]
  },
  {
    "objectID": "exercises/index_xPL.html",
    "href": "exercises/index_xPL.html",
    "title": "Höher parametrisierte Modelle",
    "section": "",
    "text": "Keine Treffer"
  },
  {
    "objectID": "exercises/index_linking.html",
    "href": "exercises/index_linking.html",
    "title": "Linking",
    "section": "",
    "text": "Sortieren nach\n       Voreinstellung\n         \n          Titel\n        \n         \n          Autor:in\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitel\n\n\nAutor:in\n\n\n\n\n\n\nLinking\n\n\nNicklas Hafiz\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen",
      "Linking"
    ]
  }
]