[
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Folien",
    "section": "",
    "text": "1 Einführung Item Response Theorie\n  Download PDF File\n   \n    Unable to display PDF file. Download instead.\n  \n  \n\n\n2 Einführung in R\n    View slides in full screen\n       \n      \n    \n  \n\n\n3 GLM\n    View slides in full screen\n       \n      \n    \n  \n\n\n4 Linking\n    View slides in full screen\n       \n      \n    \n  \n\n\n5 Höher Parametrisierte Modelle\n    View slides in full screen"
  },
  {
    "objectID": "slides/GLM/glm.html#überblick",
    "href": "slides/GLM/glm.html#überblick",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Überblick",
    "text": "Überblick\n\nGeneralized Linear Modell (GLM)\nLinear Mixed Model (LMM)\nÜbertragung auf IRT Kontext"
  },
  {
    "objectID": "slides/GLM/glm.html#generalized-linear-model",
    "href": "slides/GLM/glm.html#generalized-linear-model",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Generalized Linear Model",
    "text": "Generalized Linear Model\n\\[\ny = Xb+e\n\\]\n\\[\nE(y) = \\mu = g^{-1}(Xb)\n\\]\n\nmit \\(g\\) als Link Funktion\n\nVarianzfunktion auch zeigen?"
  },
  {
    "objectID": "slides/GLM/glm.html#irt-modell-als-glm",
    "href": "slides/GLM/glm.html#irt-modell-als-glm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "IRT Modell als GLM",
    "text": "IRT Modell als GLM\n\\[\ng(\\mu) = ln(\\frac{\\mu}{1-\\mu}) = Xb\n\\]"
  },
  {
    "objectID": "slides/GLM/glm.html#irt-modell-als-glm-1",
    "href": "slides/GLM/glm.html#irt-modell-als-glm-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "IRT Modell als GLM",
    "text": "IRT Modell als GLM\n\nLogistische Regression: Modellierung der Wahrscheinlichkeit einer korrekten Antwort.\nZusammenhang der Variablen linear. Muss dann noch auf die logit-scale gebracht werden (Link Funktion)."
  },
  {
    "objectID": "slides/GLM/glm.html#section",
    "href": "slides/GLM/glm.html#section",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "",
    "text": "Linear Mixed Models\n\n\n\nFoto von Mauro Lima auf Unsplash."
  },
  {
    "objectID": "slides/GLM/glm.html#llm",
    "href": "slides/GLM/glm.html#llm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "LLM",
    "text": "LLM\n\nlibrary(tidyverse)\n\n## Daten laden\nload(here::here(\"raw_data\", \"multilevel_data.rda\"))\n\n## Überblick\nstr(stud_data)\n\ntibble [7,185 × 5] (S3: tbl_df/tbl/data.frame)\n $ school  : chr [1:7185] \"1224\" \"1224\" \"1224\" \"1224\" ...\n $ minority: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ sex     : Factor w/ 2 levels \"Male\",\"Female\": 2 2 1 1 1 1 2 1 2 1 ...\n $ ses     : num [1:7185] -1.528 -0.588 -0.528 -0.668 -0.158 ...\n $ mathach : num [1:7185] 5.88 19.71 20.35 8.78 17.9 ...\n\n\n\nillustration_dat &lt;- stud_data %&gt;% \nfilter(school %in% c(\"1224\", \"1288\", \"1296\", \"1308\", \"1317\", \"1358\", \"1374\", \"1433\", \"1436\"))\n\n## Zentrieren\nillustration_dat &lt;- illustration_dat %&gt;% \n  mutate(ses_cent = ses - mean(ses))\n\n\n\nDaten aus diesem Tutorial"
  },
  {
    "objectID": "slides/GLM/glm.html#option-1-ignorieren",
    "href": "slides/GLM/glm.html#option-1-ignorieren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 1: Ignorieren",
    "text": "Option 1: Ignorieren\n\nggplot(data = illustration_dat , aes(x = ses_cent, y = mathach)) +\n  geom_point(aes(colour = school)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Math Score by Socioeconomic Status\",\n       x = \"Socioeconomic Status\",\n       y = \"Math Score\") +\n       theme_classic() +\n       ylim(c(-5, 25))"
  },
  {
    "objectID": "slides/GLM/glm.html#option-1-ignorieren-1",
    "href": "slides/GLM/glm.html#option-1-ignorieren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 1: Ignorieren",
    "text": "Option 1: Ignorieren\nGenerell eher keine gute Idee:\n\nDie genestete Struktur kann von Interesse sein!\nWir tun so, als ob wir mehr Informationen hätten, als wir letztendlich haben. Das liegt daran, dass Abhängigkeiten zwischen den Daten bestehen. Konsequenz:\n\nStandardfehler werden unterschätzt, unsere Inferenzstatistischen Tests werden eher signifikant."
  },
  {
    "objectID": "slides/GLM/glm.html#option-2-aggregieren",
    "href": "slides/GLM/glm.html#option-2-aggregieren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 2: Aggregieren",
    "text": "Option 2: Aggregieren\n\nillustration_dat %&gt;%\n  group_by(school) %&gt;%\n  summarise(mean_mathach = mean(mathach),\n            mean_ses = mean(ses_cent)) %&gt;%\nggplot(aes(x = mean_ses, y = mean_mathach)) +\n  geom_point(aes(colour = school)) +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Math Score by Socioeconomic Status\",\n       x = \"Mean Socioeconomic Status\",\n       y = \"Mean Math Score\") +\n       theme_classic() +\n       ylim(c(-5, 25))"
  },
  {
    "objectID": "slides/GLM/glm.html#option-2-aggregieren-1",
    "href": "slides/GLM/glm.html#option-2-aggregieren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 2: Aggregieren",
    "text": "Option 2: Aggregieren"
  },
  {
    "objectID": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren",
    "href": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren",
    "text": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren\nVerstehe noch nicht so ganz, wie das grafisch aussehen würde. https://www.cambridge.org/core/journals/political-science-research-and-methods/article/abs/should-i-use-fixed-or-random-effects/12DFCB222123587A37163F2226E85C67\nrandom effect models reduce bias, but can reduce the variance of estimates of coefficients of interest. some sort of regularization\n\nlm(mathach ~ ses_cent + school, data = illustration_dat) %&gt;% \n    summary()\n\nmod2 &lt;- lmer(mathach ~ ses_cent + (1|school), data = illustration_dat) \nranef(mod2)\n\nWird schnell unübersichtlich, lm z.B. gibt uns viele Infos raus, die uns eigentlich gar nicht interssieren. An sich müsste die Grafik ähnlich aussehen wie im nächsten Beispiel? Die Berechnungen sind aber ein bisscehn anders, v.a. wegen Partial pooling."
  },
  {
    "objectID": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren-1",
    "href": "slides/GLM/glm.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren",
    "text": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren"
  },
  {
    "objectID": "slides/GLM/glm.html#option-4-multilevel-modell",
    "href": "slides/GLM/glm.html#option-4-multilevel-modell",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 4: Multilevel-Modell",
    "text": "Option 4: Multilevel-Modell\n\nggplot(data = illustration_dat, aes(x = ses_cent, y = mathach, colour = school)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  labs(title = \"Math Score by Socioeconomic Status\",\n       x = \"Socioeconomic Status\",\n       y = \"Math Score\") +\n       theme_classic() +\n       ylim(c(-5, 25))"
  },
  {
    "objectID": "slides/GLM/glm.html#notizen",
    "href": "slides/GLM/glm.html#notizen",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Notizen",
    "text": "Notizen\nRein Optisch betrachtet scheint es recht wichtig zu sein, auf welche Schule man geht. Die Abweichung von Mittelwert des GesamtSES hat auch einen Einfluss."
  },
  {
    "objectID": "slides/GLM/glm.html#level-1-gleichung",
    "href": "slides/GLM/glm.html#level-1-gleichung",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Level 1 Gleichung",
    "text": "Level 1 Gleichung\nFür jede Gruppe j: \\[\ny_{ij} = \\beta_{0j} + \\beta_{1j}x_{ij} + e_{ij}\n\\]\nAbbildung"
  },
  {
    "objectID": "slides/GLM/glm.html#level-2-gleichung",
    "href": "slides/GLM/glm.html#level-2-gleichung",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Level-2 Gleichung",
    "text": "Level-2 Gleichung\n\\[\n\\beta_{0j} = \\beta_{0}+\\zeta_{0j}\n\\]\n\\[\n\\beta_{1j} = \\beta_1 + \\zeta_{1j}\n\\]\nAbbildung"
  },
  {
    "objectID": "slides/GLM/glm.html#das-gemischte-modell",
    "href": "slides/GLM/glm.html#das-gemischte-modell",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Das gemischte Modell",
    "text": "Das gemischte Modell\nJetzt müssen wir nur noch einsetzen:\n\\[\ny_{ij} = \\beta_{0j} + \\beta_{1j}x_{ij} + e_{ij}\n\\] \\[\n\\beta_{0j} = \\beta_{0}+\\zeta_{0j}\n\\]\n\\[\n\\beta_{1j} = \\beta_1 + \\zeta_{1j}\n\\]\n\\[\ny_{ij} = \\beta_{0}+\\beta_1x_{ij} + \\zeta_{0j} + \\zeta_{1j}x_{ij} + e_{ij}\n\\]"
  },
  {
    "objectID": "slides/GLM/glm.html#section-1",
    "href": "slides/GLM/glm.html#section-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "",
    "text": "Random effects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixed effects"
  },
  {
    "objectID": "slides/GLM/glm.html#random-und-fixed-effects",
    "href": "slides/GLM/glm.html#random-und-fixed-effects",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Random und Fixed effects",
    "text": "Random und Fixed effects\n\n\nRandom Effects\n\nAnnahme eines zugrundeliegenden Gesamtmittelwerts. Von diesem weichen die Gruppen random ab.\nBei Wiederholung würden wir andere Gruppen ziehen.\nPartial Pooling: Regularisierung der Extremen Werte in Richtung Gruppenmittelwert. \n\n\n\nFixed Effects\n\nHier machen wir diese Annahme einfach nicht.\nUns interessieren die tatsächlichen Gruppen, bei Wiederholung würden wird die gleichen ziehen."
  },
  {
    "objectID": "slides/GLM/glm.html#beispiel",
    "href": "slides/GLM/glm.html#beispiel",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Beispiel",
    "text": "Beispiel\nWir untersuchen den Erfolg von Verhaltenstherapie und Psychoanalyse anhand der Rückfallquote nach einem Jahr.\nPatientinnen müssen hier nach Therapeutinnen genested werden. Dabei können wir die Therapeutinnen als random effects betrachten, wir haben sie ja schließlich nur als Mittel zum Zweck aus der Population an Therapeutinnen gezogen. Die Behandlungsform (Verhaltenstherapie, Psychoanalyse) ist hingegen ein fixed effect, da wir nur diese beiden Behandlungsformen untersuchen wollen.\nAnders würde das Ganze aussehen, wenn uns die Erfolgsquote speziell dieser Therapeut*innen interessieren würde. Dann könnten wir sie ebenfalls als fixed effect im Modell mit aufnehmen."
  },
  {
    "objectID": "slides/GLM/glm.html#lme4",
    "href": "slides/GLM/glm.html#lme4",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "lme4",
    "text": "lme4\n\nlibrary(lme4)\n\nmod1 &lt;- lmer(mathach ~ ses_cent + (1|school), data = illustration_dat) \nsummary(mod1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: mathach ~ ses_cent + (1 | school)\n   Data: illustration_dat\n\nREML criterion at convergence: 2091\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.52568 -0.67053 -0.06796  0.74859  2.79564 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept)  8.778   2.963   \n Residual             34.699   5.891   \nNumber of obs: 325, groups:  school, 9\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  13.1169     1.0447  12.555\nses_cent      2.6255     0.5285   4.968\n\nCorrelation of Fixed Effects:\n         (Intr)\nses_cent -0.016"
  },
  {
    "objectID": "slides/GLM/glm.html#raschmodell-als-spezialfall-von-lmm",
    "href": "slides/GLM/glm.html#raschmodell-als-spezialfall-von-lmm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Raschmodell als Spezialfall von LMM",
    "text": "Raschmodell als Spezialfall von LMM\nDafür müssen wir zwei Dinge beachten: - Link Funktion.\n- Entscheidung über Annahme von fixed/random effects von Personen und Items.\n\n\n\nDe Boeck and Wilson (2004)\nDoran et al. (2007)"
  },
  {
    "objectID": "slides/GLM/glm.html#link-funktion",
    "href": "slides/GLM/glm.html#link-funktion",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Link Funktion",
    "text": "Link Funktion"
  },
  {
    "objectID": "slides/GLM/glm.html#fixed-und-random-effects",
    "href": "slides/GLM/glm.html#fixed-und-random-effects",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Fixed und Random Effects",
    "text": "Fixed und Random Effects\n\nEntwicklung Fragebogen um diesen an verschiedenen Stichproben zu nutzen: Person als random, Items als fixed\nEntwicklung von Items für einen großen Fragenkatalog: Items ebenfalls als random"
  },
  {
    "objectID": "slides/GLM/glm.html#exercise",
    "href": "slides/GLM/glm.html#exercise",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Exercise",
    "text": "Exercise\n\nDirekt übertragen auf den IRT-KOntext? Also sagen: Nehmt die Daten aus dem letzten Beispiel und fittet ein LLM Modell.\nDann Vergleich mit TAM."
  },
  {
    "objectID": "slides/GLM/glm.html#prädiktoren",
    "href": "slides/GLM/glm.html#prädiktoren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Prädiktoren",
    "text": "Prädiktoren\n\nBeispiel aufgreifen, zeigen, wass man mit diesen Modell noch machen kann."
  },
  {
    "objectID": "slides/GLM/glm.html#bildquellen",
    "href": "slides/GLM/glm.html#bildquellen",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Breno Machado auf Unsplash"
  },
  {
    "objectID": "slides/xPL/index.html#fahrplan",
    "href": "slides/xPL/index.html#fahrplan",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Fahrplan",
    "text": "Fahrplan"
  },
  {
    "objectID": "slides/xPL/index.html#section",
    "href": "slides/xPL/index.html#section",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Wiederholung: 1PL"
  },
  {
    "objectID": "slides/xPL/index.html#pl-modell",
    "href": "slides/xPL/index.html#pl-modell",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL Modell",
    "text": "1PL Modell\n\\[\nlogit(P(X_{pi}=1)) = \\theta_p - \\beta_i\n\\]\n\nLogit: Transformation unseres linearen Terms, damit die Werte zwischen 0 und 1 liegen. Wahrscheinlichkeit \\(p\\) durch Gegenwahrscheinlichkeit \\(1-p\\).\nInverse der logit ist die logistische Funktion."
  },
  {
    "objectID": "slides/xPL/index.html#pl-modell-umformen",
    "href": "slides/xPL/index.html#pl-modell-umformen",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL Modell: Umformen",
    "text": "1PL Modell: Umformen\n\\[\nlogit(P(X_{pi}=1)) = \\ln\\left(\\frac{P(X_{pi}=1)}{1-P(X_{pi}=1)}\\right) = \\theta_p - \\beta_i\n\\]"
  },
  {
    "objectID": "slides/xPL/index.html#pl-modell-umformen-1",
    "href": "slides/xPL/index.html#pl-modell-umformen-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL Modell: Umformen",
    "text": "1PL Modell: Umformen\n\\[\n\\frac{p_{pi}}{1-p_{pi}} = exp(\\theta_p - \\beta_i)\n\\]\n\\[\np_{pi} = exp(\\theta_p - \\beta_i)*( 1-p_{pi})\n\\]\n\n\nMit \\(p_{pi}\\) für \\(P(X_{pi}=1)\\)"
  },
  {
    "objectID": "slides/xPL/index.html#pl-modell-umformen-2",
    "href": "slides/xPL/index.html#pl-modell-umformen-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL Modell: Umformen",
    "text": "1PL Modell: Umformen\n\\[\np_{pi} + p_{pi} * exp(\\theta_p - \\beta_i) = exp(\\theta_p - \\beta_i)\n\\]\n\n\n\\[\np_{pi} + p_{pi} * exp(\\theta_p - \\beta_i) = exp(\\theta_p - \\beta_i)\n\\]\n\n\n\n\\[\np_{pi}*(1+exp(\\theta_p - \\beta_i)) = exp(\\theta_p - \\beta_i)\n\\]"
  },
  {
    "objectID": "slides/xPL/index.html#pl-schreibweise-1",
    "href": "slides/xPL/index.html#pl-schreibweise-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL Schreibweise 1",
    "text": "1PL Schreibweise 1\n\\[\nP(X_{pi}=1) = \\frac{exp(\\theta_p - \\beta_i)}{1 + exp(\\theta_p - \\beta_i)}\n\\]\n\n\n\\(P(X_{pi}=1)\\) für \\(p_{pi}\\) einsetzen, um die gängige Notation herzustellen"
  },
  {
    "objectID": "slides/xPL/index.html#pl-schreibweise-2",
    "href": "slides/xPL/index.html#pl-schreibweise-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL Schreibweise 2",
    "text": "1PL Schreibweise 2\n\\[\nP(X_{pi}=1) = \\frac{e^{\\theta_p - \\beta_i}}{1 + e^{\\theta_p - \\beta_i}}\n\\]"
  },
  {
    "objectID": "slides/xPL/index.html#pl-schreibweise-3",
    "href": "slides/xPL/index.html#pl-schreibweise-3",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL Schreibweise 3",
    "text": "1PL Schreibweise 3\n\\[\nP(X_{pi}=1) = \\frac{1}{1 + e^{\\color{#9B1B34}{-}\\theta_p \\color{#9B1B34}{+} \\beta_i}}\n\\]"
  },
  {
    "objectID": "slides/xPL/index.html#beispiel",
    "href": "slides/xPL/index.html#beispiel",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beispiel",
    "text": "Beispiel\n\\[\n\\frac{exp(1 - 0.8)}{1 + exp(1 - 0.8)} = 0.55\n\\]\nWahrscheinlichkeit einer richtigen Antwort über 0.5, wenn \\(\\theta_p &gt; \\beta_i\\).\n\n\n\n\\(\\theta_p = 1\\)\n\\(\\beta_i = 0.8\\)"
  },
  {
    "objectID": "slides/xPL/index.html#beispiel-1",
    "href": "slides/xPL/index.html#beispiel-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beispiel",
    "text": "Beispiel\n\\[\n\\frac{exp(0.8 - 1)}{1 + exp(0.8 - 1)} = 0.45\n\\]\nWahrscheinlichkeit einer richtigen Antwort unter 0.5, wenn \\(\\theta_p &lt; \\beta_i\\).\n\n\n\n\\(\\theta_p = 0.8\\)\n\\(\\beta_i = 1\\)"
  },
  {
    "objectID": "slides/xPL/index.html#section-1",
    "href": "slides/xPL/index.html#section-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Höher parametrisierte   IRT Modelle"
  },
  {
    "objectID": "slides/xPL/index.html#neue-paramter",
    "href": "slides/xPL/index.html#neue-paramter",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Neue Paramter",
    "text": "Neue Paramter\nWir können Parameter zu diesem Modell hinzufügen, wodurch wir flexibler in der Modellierung werden:\n\nSchwierigkeit \\(\\beta_i\\) (Intercept)\n\n\n\nSteigung \\(\\alpha\\) (Faktorladung, Diskriminationsparameter)\n\n\n\n\n\nRatewahrscheinlichkeit \\(\\gamma_i\\)"
  },
  {
    "objectID": "slides/xPL/index.html#pl",
    "href": "slides/xPL/index.html#pl",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "3PL",
    "text": "3PL\n\\[\nP(X_{pi}=1) = \\color{#aaa938}{\\gamma_i} + (1-\\color{#aaa938}{\\gamma_i})\\frac{exp(\\color{#F4BA02}{\\alpha_i}(\\theta_p - \\color{#99D9DD}{\\beta_i})))}{1 + exp(\\color{#F4BA02}{\\alpha_i}(\\theta_p - \\color{#99D9DD}{\\beta_i}))}\n\\]\n\nSchwierigkeit\nDiskriminationsparamter\n\nRatewahrscheinlichkeit\n\nz.B. bei 4 Antwortmöglichkeiten: \\(\\gamma_i = 1/4 = 0.25\\)"
  },
  {
    "objectID": "slides/xPL/index.html#pl-1",
    "href": "slides/xPL/index.html#pl-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "2PL",
    "text": "2PL\n\\(\\gamma_i = 0\\)\n\\[\nP(X_{pi}=1) = \\color{#9B1B34}{0} + (1-\\color{#9B1B34}{0})\\frac{exp(\\alpha_i(\\theta_p - \\beta_i)))}{1 + exp(\\alpha_i(\\theta_p - \\beta_i))}\n\\]"
  },
  {
    "objectID": "slides/xPL/index.html#pl-2",
    "href": "slides/xPL/index.html#pl-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "1PL",
    "text": "1PL\n\\(\\alpha_i = 1\\)\n\\[\nP(X_{pi}=1) = 0 + (1-0)\\frac{exp(\\color{#9B1B34}{1}(\\theta_p - \\beta_i)))}{1 + exp(\\color{#9B1B34}{1}(\\theta_p - \\beta_i))}\n\\]"
  },
  {
    "objectID": "slides/xPL/index.html#darstellung",
    "href": "slides/xPL/index.html#darstellung",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Darstellung",
    "text": "Darstellung\n\n\nviewof alpha1 = Inputs.range(\n  [-3, 3], \n  {value: 1, step: .01, label: tex`\\alpha`}\n)\nviewof beta1 = Inputs.range(\n  [-3, 3], \n  {value: 0, step: .01, label: tex`\\beta`}\n)\nviewof gamma1 = Inputs.range(\n  [0, 1], \n  {value: 0, step: .01, label: tex`\\gamma`}\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nline_function = function(alpha, beta, gamma, theta) {\n    return gamma + (1 - gamma) * (Math.exp(alpha * (theta - beta)) / (1 + Math.exp(alpha * (theta - beta))));\n}\n\n// X-Variable\ndata = d3.range(-6, 6, 0.01).map((theta) =&gt; ({\n  x: theta,\n  y1: line_function(alpha1, beta1, gamma1, theta),\n}));\n\nPlot.plot(\n  {\n    x: {grid: false, domain: [-6, 6]}, \n    y: {grid: false, domain: [0, 1]},\n    marks: [\n      Plot.line(data, {x: \"x\", y: \"y1\", stroke: \"#F4BA02\"}),\n    ]\n  }\n)"
  },
  {
    "objectID": "slides/xPL/index.html#simulieren-von-irt-daten",
    "href": "slides/xPL/index.html#simulieren-von-irt-daten",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Simulieren von IRT Daten",
    "text": "Simulieren von IRT Daten\n\n\nJetzt ist ein guter Zeitpunkt, und uns ein sehr mächtiges Werkzeug anzuschauen: Datensimulation."
  },
  {
    "objectID": "slides/xPL/index.html#übung",
    "href": "slides/xPL/index.html#übung",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Übung",
    "text": "Übung\nGeht zur Übung und probiert euch aus."
  },
  {
    "objectID": "slides/xPL/index.html#section-2",
    "href": "slides/xPL/index.html#section-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "",
    "text": "Exkurs:   Tradeoff zwischen\nUnderfit und\nOverfit"
  },
  {
    "objectID": "slides/xPL/index.html#tradeoff-zwischen-underfit-und-overfit",
    "href": "slides/xPL/index.html#tradeoff-zwischen-underfit-und-overfit",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Tradeoff zwischen Underfit und Overfit",
    "text": "Tradeoff zwischen Underfit und Overfit\n\n\n\n\n\n\n\n\n\n\nNach @mcelreath2018statistical, Kapitel 7"
  },
  {
    "objectID": "slides/xPL/index.html#tradeoff-zwischen-underfit-und-overfit-1",
    "href": "slides/xPL/index.html#tradeoff-zwischen-underfit-und-overfit-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Tradeoff zwischen Underfit und Overfit",
    "text": "Tradeoff zwischen Underfit und Overfit"
  },
  {
    "objectID": "slides/xPL/index.html#tradeoff-zwischen-underfit-und-overfit-2",
    "href": "slides/xPL/index.html#tradeoff-zwischen-underfit-und-overfit-2",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Tradeoff zwischen Underfit und Overfit",
    "text": "Tradeoff zwischen Underfit und Overfit"
  },
  {
    "objectID": "slides/xPL/index.html#mögliche-punkte",
    "href": "slides/xPL/index.html#mögliche-punkte",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Mögliche Punkte",
    "text": "Mögliche Punkte\n\n\n\n\n\n\nMehr Parameter müsen also nicht immer auch besser sein. Gerade im IRT-Kontext können komplexere Modelle schnell an ihre Grenzen kommen und nicht konvergieren.\n\n\n\nBei Modellwahl zu beachten: - Gewichtung der Items - Antwortskala - Simulation/Modellfit - Ziel"
  },
  {
    "objectID": "slides/xPL/index.html#beurteilung-von-fit",
    "href": "slides/xPL/index.html#beurteilung-von-fit",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beurteilung von Fit",
    "text": "Beurteilung von Fit\nz.B.: - lokLikelihood/\\(\\chi^2\\) - AIC, BIC"
  },
  {
    "objectID": "slides/xPL/index.html#beispielaufgabe",
    "href": "slides/xPL/index.html#beispielaufgabe",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Beispielaufgabe",
    "text": "Beispielaufgabe\n\nIch bin bequem, neige zur Faulheit.\n\n\n(trift überhaupt nicht zu) 1 … 2 … 3 … 4 … 5 (trift voll und ganz zu)\n\n\n\nBeispielfrage aus dem Big-Five-Inventory (BFI-10)."
  },
  {
    "objectID": "slides/xPL/index.html#grundidee",
    "href": "slides/xPL/index.html#grundidee",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Grundidee",
    "text": "Grundidee\nDen einzelnen Antwortkategorien wird eine eigene Schwierigkeit zugeordnet. Dadurch können wir die Antwortwahrscheinlichkeit in einer bestimmten Kategorie berechnen."
  },
  {
    "objectID": "slides/xPL/index.html#anwendungsbereich",
    "href": "slides/xPL/index.html#anwendungsbereich",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Anwendungsbereich",
    "text": "Anwendungsbereich\nOrdinale Daten (geordnete Antwortkategorien), z.B.:\n\nLikert-Skalen\nItems, die auch mit Teilpunkten bewertet werden können (z.B. in Mathe)"
  },
  {
    "objectID": "slides/xPL/index.html#darstellung-1",
    "href": "slides/xPL/index.html#darstellung-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Darstellung",
    "text": "Darstellung"
  },
  {
    "objectID": "slides/xPL/index.html#formel",
    "href": "slides/xPL/index.html#formel",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Formel",
    "text": "Formel\n\\[\n\\pi_{pix}= P(X_{pi}=x|\\theta_p, \\beta_{ik})= \\frac{exp[\\sum^x_{j=0}(\\theta_p-\\beta_{ij})]}{1+exp[\\sum^k_{j=0}(\\theta_p-\\beta_{ij})]}\n\\] ::: aside\n\nPerson \\(p\\)\n\nItem \\(i\\)\n\nPersonenscore \\(x\\)\n\n\n:::"
  },
  {
    "objectID": "slides/xPL/index.html#partial-credit-model",
    "href": "slides/xPL/index.html#partial-credit-model",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Partial Credit Model",
    "text": "Partial Credit Model\n\\[\n\\pi_{pix}= \\color{#9B1B34}{P(X_{pi}=x|\\theta_p, \\beta_{ik})}= \\frac{exp[\\sum^x_{j=0}(\\theta_p-\\beta_{ij})]}{1+exp[\\sum^k_{j=0}(\\theta_p-\\beta_{ij})]}\n\\]"
  },
  {
    "objectID": "slides/xPL/index.html#partial-credit-model-1",
    "href": "slides/xPL/index.html#partial-credit-model-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Partial Credit Model",
    "text": "Partial Credit Model\n\\[\n\\pi_{pix}= P(X_{pi}=x|\\theta_p, \\beta_{ik})= \\frac{exp[\\sum^x_{j=0}\\color{#9B1B34}{(\\theta_p-\\beta_{ij})}]}{1+exp[\\sum^k_{j=0}(\\theta_p-\\beta_{ij})]}\n\\]\nWichtig:\\(\\beta_{i\\color{#9B1B34}{j}}\\) ist jetzt der Schwellenparameter der Kategorie \\(j\\) des Items \\(i\\)."
  },
  {
    "objectID": "slides/xPL/index.html#raw-score-curve",
    "href": "slides/xPL/index.html#raw-score-curve",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Raw score curve",
    "text": "Raw score curve"
  },
  {
    "objectID": "slides/xPL/index.html#übung-1",
    "href": "slides/xPL/index.html#übung-1",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Übung",
    "text": "Übung\nGehe zur Partial-Credit-Übung und bearbeite sie."
  },
  {
    "objectID": "slides/xPL/index.html#bildquellen",
    "href": "slides/xPL/index.html#bildquellen",
    "title": "Höher parametrisierte IRT Modelle",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Pawel Czerwinski auf Unsplash\n\nFoto von Roman Mager auf Unsplash\n\nhttps://www.bing.com/images/create/image-of-a-woman-writing-equations-on-a-window2c-li/1-670bee21dbf4423ca93d0804834a7f46?id=ujHjvSYHngnLxV45OzbrGQ%3d%3d&view=detailv2&idpp=genimg&thId=OIG3.E7px5jYmHkuo3mmm7QIC&skey=wPdVodkEkkpUXZMJ6uYMCEO41l21b_tAfYC2zWMLPmY&FORM=GCRIDP&mode=overlay\nFoto von Crawford Jolly auf Unsplash\n\nFoto von Javier Allegue Barros auf Unsplash"
  },
  {
    "objectID": "exercises/xPl/pcm.html",
    "href": "exercises/xPl/pcm.html",
    "title": "Partial Credit Model",
    "section": "",
    "text": "library(TAM)\n\nLoading required package: CDM\n\n\nLoading required package: mvtnorm\n\n\n**********************************\n** CDM 8.2-6 (2022-08-25 15:43:23)       \n** Cognitive Diagnostic Models  **\n**********************************\n\n\n* TAM 4.2-21 (2024-02-19 18:52:08)\n\nlibrary(psych)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::%+%()   masks psych::%+%()\n✖ ggplot2::alpha() masks psych::alpha()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\npsych_dat &lt;- read.csv(here::here(\"raw_data\", \"psych_stats.csv\"), sep = \";\") %&gt;%\n  pivot_longer(cols = -char_id, names_to = \"item\", values_to = \"score\") %&gt;%\n  mutate(likert = case_when(score &lt;= 20 ~ 1,\n                            score &lt;= 40 ~ 2, \n                            score &lt;= 60 ~ 3,\n                            score &lt;= 80 ~ 4,\n                            TRUE ~ 5)) %&gt;%\n  select(item, likert, char_id) %&gt;%\n  pivot_wider(names_from = item, values_from = likert) %&gt;%\n  select(char_id, messy_neat, disorganized_self.disciplined, diligent_lazy, on.time_tardy, scheduled_spontaneous, ADHD_OCD, chaotic_orderly, overachiever_underachiever)\n\n## ERstmal: Eine Art Gewissenhaftigkeit wird gemessen.\n## Items:\n# messy_neat, disorganized_self.disciplined, diligent_lazy, on.time_tardy, scheduled_spontaneous, ADHD_OCD, chaotic_orderly, overachiever_underachiever\n\n## Umkodieren! \n# - diligent_lazy, on.time_tardy, scheduled_spontaneous, overachiever_underachiever\n\npsych_dat &lt;- psych_dat %&gt;%\n  mutate(lazy_diligent = 6 - diligent_lazy,\n         tardy_on.time = 6 - on.time_tardy,\n         spontaneous_scheduled = 6 - scheduled_spontaneous,\n         underachiever_overachiever = 6 - overachiever_underachiever) %&gt;%\n  select(-char_id, -diligent_lazy, -on.time_tardy, -scheduled_spontaneous, -overachiever_underachiever) \n\n\n\n#### Hier dann loslegen mit der Übung. Umkodieren evtl. im R-Teil? \n\n## Sind die Daten im richtigen Format? \n## eventuell nicht eindimensional?\n\ncor(psych_dat)\n\n## Ich glaube es muss bei 0 anfangen, hat mir aber keiner gesagt!\npsych_dat &lt;- psych_dat -1\n## Hohe correlationen zwischen den Items. Aber eignelich niucht weiter schlimm oder?\n\nany(is.na(psych_dat))\n\nalpha(psych_dat)$response.freq\n\n\n## Eigentlich sind die response kategorien ganz gut ausgelastet, teilweise die Ränder etwas weniger. \n\npcm_psych &lt;- tam.mml(psych_dat[, -1], irtmodel = \"PCM\")\n\nsummary(pcm_psych)\n\npcm_psych$xsi\n\n## Identify items with disordered category thresholds\ng &lt;- pcm_psych$item_irt\ngg &lt;- g[g$tau.Cat1 &gt; g$tau.Cat2 | g$tau.Cat2 &gt; g$tau.Cat3 | g$tau.Cat3 &gt; g$tau.Cat4, ]\nrownames(gg)\n\n## Jetzt geordnet!\ndeltas &lt;- pcm_psych$xsi\n## HMM, sieht immernoch comisch aus oder? \n## Aber Delta Schnittpunkte stimmen mit dem Plot überein\n\n## Plot the option characteristic curves\nplot(pcm_psych, \n     type = \"items\", \n     export = FALSE, \n     package = \"graphics\", \n     observed = TRUE, \n     low = -6, \n     high = 6)\n\n## Gestrichelt sind die Observed Linien. Aber actually not that weird oder? \n\n# Was genau sagen die verschiednen Kurven typen?\n\n## Plot the empirical and theoretical expected scores curves\n\nplot(pcm_psych, \n     type = \"expected\", \n     ngroups = 6, \n     low  = -6, \n     high = 6,\n     package = \"lattice\", overlay = FALSE)\n\n## Infit/Outfit anschauen\n\nfit &lt;- msq.itemfit(pcm_psych)$itemfit\n(fit &lt;- data.frame(fit[1], round(fit[3:8], 2)))\n\n## Infit und Outfit sollten zwischen 0.5 und 1.5 liegen (hatte noch andere Grenzen im Kopf, quelle ruassuchen. Auch was genau das nochmal heißt). \n## underachiever_overachiever passt nicht so rein, ist auch thematisch weiter weg (nette Illustration, sieht man das noch an irgendwelchen Kurven oder andern Werten?)\n\n\n## Q3 Statistic\nq3 &lt;- tam.modelfit(pcm_psych)$stat.itempair\nq3 &lt;- data.frame(q3[1:2], round(q3[5:6], 2), round(q3[7:8], 4))\n## Actually quite interesting! underachiever_overachiever fällt auch hier auf. \n\n\n## Gut oder schlecht? zuyymindest sehr ähnlich im example. \n(MADaQ3 &lt;- tam.modelfit(pcm_psych)$stat.MADaQ3)\n\n## Values &gt; 0.6 might reflect unacceptable fit\n(item.RMSD &lt;- IRT.itemfit(pcm_psych)$RMSD_bc)\n\n## Tardy_on.time ebenfalls auffällig (auch ein komischer Gegensatz wenn man drüber nachdenkt, evtl. mehrdimensional)\n\n## Hiernach kommt noch einiges, aber wahrscheinlich genug to get started!\nlibrary(eRm)\n\nerm_pcm &lt;- PCM(psych_dat)\nsummary(erm_pcm)\n\nplotPImap(erm_pcm)\nplotICC(erm_pcm, ask = FALSE)\n\n## Scheint anders auszusehen als bei Tam. Nochmal genauer schauen später, aber underachiever_overachiever scheint sich hier erst bei vier die letzte Linie zu kreuzen. \n\nthresholds(erm_pcm)\n\nperson.location.estimate &lt;- person.parameter(erm_pcm)\n\nitem_fit_pcm &lt;- itemfit(person.location.estimate)\n\n\n## Maybe plot standardiyed residuals?\nstresid &lt;- item_fit_pcm$st.res\n\n# before constructing the plots, find the max & min residuals:\nmax.resid &lt;- ceiling(max(stresid))\nmin.resid &lt;- ceiling(min(stresid))\n\nfor(item.number in 1:ncol(stresid)){\n  plot(stresid[, item.number], ylim = c(min.resid, max.resid),\n       main = paste(\"Standardized Residuals for Item \", item.number, sep = \"\"),\n       ylab = \"Standardized Residual\", xlab = \"Person Index\")\n  abline(h = 0, col = \"blue\")\n  abline(h=2, lty = 2, col = \"red\")\n  abline(h=-2, lty = 2, col = \"red\")\n  legend(\"topright\", c(\"Std. Residual\", \"Observed = Expected\", \"+/- 2 SD\"), pch = c(1, NA, NA), \n         lty = c(NA, 1, 2),\n         col = c(\"black\", \"blue\", \"red\"), cex = .8)\n}\n\n## Looks okay I gues? For Item 8 am schlechtesten, passt auch wieder!"
  },
  {
    "objectID": "exercises/xPl/pcm.html#personenspezifische-kurve-zeichnen",
    "href": "exercises/xPl/pcm.html#personenspezifische-kurve-zeichnen",
    "title": "Partial Credit Model",
    "section": "\n1 Personenspezifische Kurve zeichnen?",
    "text": "1 Personenspezifische Kurve zeichnen?"
  },
  {
    "objectID": "exercises/index_glm.html",
    "href": "exercises/index_glm.html",
    "title": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Sortieren nach\n       Voreinstellung\n         \n          Titel\n        \n         \n          Autor:in\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitel\n\n\nAutor:in\n\n\n\n\n\n\nDas Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells\n\n\nNicklas Hafiz\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells"
    ]
  },
  {
    "objectID": "exercises/linking/data.html",
    "href": "exercises/linking/data.html",
    "title": "1. Die Daten",
    "section": "",
    "text": "Lade die Datei q_a_wirt.rds von GitHub herunter (am besten in einen eigenen Daten-Ordner in deinem Projektordner) und in dein R-Skript ein.\n\n\n\n\n\n\nDie Daten stammen aus dem SPIEGEL-Studentenpisa-Test von 2009 und beinhaltet Fragen zu Allgemeinwissen in den Themengebieten Politik, Geschichte, Wirtschaft, Kultur und Naturwissenschaften. Insgesamt haben fast 700.000 Personen den Test bearbeitet. Wir haben die Daten bereits etwas aufbereitet und nur ein Subset an Fragen (Thema Wirtschaft) für diese Übung ausgewählt.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nqa_dat &lt;- readRDS(here::here(\"raw_data\", \"q_a_wirt_b.rds\"))\n\n\n\n\n\nVerschaffe dir einen Überblick über die Daten. In welchem Formt liegen sie vor? Was könnten die verschiedenen Spalten bedeuten?\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDurch Inspektion der Struktur können wir schnell feststellen, dass die Daten im long-Format vorliegen (jede Person hat pro Itemantwort eine eigene Zeile). Wir müssen sie also gleich ins wide-Format umformen.\n\nstr(qa_dat)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   4752 obs. of  8 variables:\n $ T1                : chr  \"1238597633568380\" \"1238597633568380\" \"1238597633568380\" \"1238597633568380\" ...\n $ gender            : num  2 2 2 2 2 2 2 2 2 1 ...\n $ bundeslandStudium : num  3 3 3 3 3 3 3 3 3 3 ...\n $ spiegelReadingfreq: num  1 1 1 1 1 1 1 1 1 1 ...\n $ age               : num  21 21 21 21 21 21 21 21 21 19 ...\n $ answer            : num  0 0 0 1 1 1 1 0 1 0 ...\n $ question_code     : chr  \"3401\" \"3402\" \"3403\" \"3404\" ...\n $ varLabel          : chr  \"Wer ist das? Bitte tragen Sie den Nachnamen ein (FB-Nr. 100)\" \"Wie hoch ist der volle Hartz-IV-Regelsatz für Erwachsene? (FB-Nr. 101)\" \"Wie hoch war 2007 das durchschnittliche Bruttoinlandsprodukt pro Kopf in Deutschland? (FB-Nr. 102)\" \"Was ist ein CEO? (FB-Nr. 103)\" ...\n\n\nAußerdem scheint der Datensatz folgende Variablen zu beinhalten:\n\n\nT1: Personen-ID (aber komisch benannt)\n\ngender: Geschlecht\n\nanswer: Antwort auf die Frage\n\nquestion_code: Fragen-ID\n\nvarLabel: Frage (aber komisch benannt)\n\n\n\n\n\nHmm, die Spaltennamen sind teilweise noch nicht ganz eindeutig. Benenne T1 in ID und varLabel in question um. Klare Benennung hilft uns (und anderen) den Überblick zu behalten.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nIch nutze jetzt einfach mal tidyverse Funktionen dafür, aber es gibt immer mehrere Wege zum Ziel. Im tidyverse gibt es beispielsweise die Funktion rename().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nqa_dat_renamed &lt;- qa_dat %&gt;%\n  rename(ID = T1, question = varLabel)\n\n\n\n\n\nForme jetzt die Daten ins wide-Format um.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nAlle Spalten, die nicht ins wide-Format übertragen werden sollen, müssen in pivot_wider() als id_cols definiert werden: ..., id_cols = c(ID, gender, bundeslandStudium, spiegelReadingfreq, age), ....\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nqa_dat_wide &lt;- qa_dat_renamed %&gt;%\n  pivot_wider(\n    id_cols = c(ID, gender, bundeslandStudium, spiegelReadingfreq, age),\n    names_from = question_code,\n    values_from = answer\n  )\n\n\nsaveRDS(qa_dat_wide, here::here(\"raw_data\", \"qa_dat_wide.rds\"))\n\nJetzt können wir mal testweise schauen ob das geklappt hat:\n\nhead(qa_dat_wide)\n\n# A tibble: 6 × 14\n  ID      gender bundeslandStudium spiegelReadingfreq   age `3401` `3402` `3403`\n  &lt;chr&gt;    &lt;dbl&gt;             &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 123859…      2                 3                  1    21      0      0      0\n2 123841…      1                 3                  1    19      0      1      1\n3 123802…      2                 3                  2    23      0      0      0\n4 123781…      1                 3                  7    23      0      0      1\n5 123765…      2                 3                 NA    23      0      1      1\n6 123883…      2                 3                 NA    23      0      0      1\n# ℹ 6 more variables: `3404` &lt;dbl&gt;, `3405` &lt;dbl&gt;, `3406` &lt;dbl&gt;, `3407` &lt;dbl&gt;,\n#   `3408` &lt;dbl&gt;, `3409` &lt;dbl&gt;\n\n\nYaay, sieht gut aus.",
    "crumbs": [
      "Übungen",
      "Linking",
      "1. Die Daten"
    ]
  },
  {
    "objectID": "exercises/linking/data.html#daten-laden",
    "href": "exercises/linking/data.html#daten-laden",
    "title": "1. Die Daten",
    "section": "",
    "text": "Lade die Datei q_a_wirt.rds von GitHub herunter (am besten in einen eigenen Daten-Ordner in deinem Projektordner) und in dein R-Skript ein.\n\n\n\n\n\n\nDie Daten stammen aus dem SPIEGEL-Studentenpisa-Test von 2009 und beinhaltet Fragen zu Allgemeinwissen in den Themengebieten Politik, Geschichte, Wirtschaft, Kultur und Naturwissenschaften. Insgesamt haben fast 700.000 Personen den Test bearbeitet. Wir haben die Daten bereits etwas aufbereitet und nur ein Subset an Fragen (Thema Wirtschaft) für diese Übung ausgewählt.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nqa_dat &lt;- readRDS(here::here(\"raw_data\", \"q_a_wirt_b.rds\"))",
    "crumbs": [
      "Übungen",
      "Linking",
      "1. Die Daten"
    ]
  },
  {
    "objectID": "exercises/linking/data.html#überblick",
    "href": "exercises/linking/data.html#überblick",
    "title": "1. Die Daten",
    "section": "",
    "text": "Verschaffe dir einen Überblick über die Daten. In welchem Formt liegen sie vor? Was könnten die verschiedenen Spalten bedeuten?\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDurch Inspektion der Struktur können wir schnell feststellen, dass die Daten im long-Format vorliegen (jede Person hat pro Itemantwort eine eigene Zeile). Wir müssen sie also gleich ins wide-Format umformen.\n\nstr(qa_dat)\n\nClasses 'tbl_df', 'tbl' and 'data.frame':   4752 obs. of  8 variables:\n $ T1                : chr  \"1238597633568380\" \"1238597633568380\" \"1238597633568380\" \"1238597633568380\" ...\n $ gender            : num  2 2 2 2 2 2 2 2 2 1 ...\n $ bundeslandStudium : num  3 3 3 3 3 3 3 3 3 3 ...\n $ spiegelReadingfreq: num  1 1 1 1 1 1 1 1 1 1 ...\n $ age               : num  21 21 21 21 21 21 21 21 21 19 ...\n $ answer            : num  0 0 0 1 1 1 1 0 1 0 ...\n $ question_code     : chr  \"3401\" \"3402\" \"3403\" \"3404\" ...\n $ varLabel          : chr  \"Wer ist das? Bitte tragen Sie den Nachnamen ein (FB-Nr. 100)\" \"Wie hoch ist der volle Hartz-IV-Regelsatz für Erwachsene? (FB-Nr. 101)\" \"Wie hoch war 2007 das durchschnittliche Bruttoinlandsprodukt pro Kopf in Deutschland? (FB-Nr. 102)\" \"Was ist ein CEO? (FB-Nr. 103)\" ...\n\n\nAußerdem scheint der Datensatz folgende Variablen zu beinhalten:\n\n\nT1: Personen-ID (aber komisch benannt)\n\ngender: Geschlecht\n\nanswer: Antwort auf die Frage\n\nquestion_code: Fragen-ID\n\nvarLabel: Frage (aber komisch benannt)",
    "crumbs": [
      "Übungen",
      "Linking",
      "1. Die Daten"
    ]
  },
  {
    "objectID": "exercises/linking/data.html#spalten-umbenennen",
    "href": "exercises/linking/data.html#spalten-umbenennen",
    "title": "1. Die Daten",
    "section": "",
    "text": "Hmm, die Spaltennamen sind teilweise noch nicht ganz eindeutig. Benenne T1 in ID und varLabel in question um. Klare Benennung hilft uns (und anderen) den Überblick zu behalten.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nIch nutze jetzt einfach mal tidyverse Funktionen dafür, aber es gibt immer mehrere Wege zum Ziel. Im tidyverse gibt es beispielsweise die Funktion rename().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nqa_dat_renamed &lt;- qa_dat %&gt;%\n  rename(ID = T1, question = varLabel)",
    "crumbs": [
      "Übungen",
      "Linking",
      "1. Die Daten"
    ]
  },
  {
    "objectID": "exercises/linking/data.html#umformen",
    "href": "exercises/linking/data.html#umformen",
    "title": "1. Die Daten",
    "section": "",
    "text": "Forme jetzt die Daten ins wide-Format um.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nAlle Spalten, die nicht ins wide-Format übertragen werden sollen, müssen in pivot_wider() als id_cols definiert werden: ..., id_cols = c(ID, gender, bundeslandStudium, spiegelReadingfreq, age), ....\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nqa_dat_wide &lt;- qa_dat_renamed %&gt;%\n  pivot_wider(\n    id_cols = c(ID, gender, bundeslandStudium, spiegelReadingfreq, age),\n    names_from = question_code,\n    values_from = answer\n  )\n\n\nsaveRDS(qa_dat_wide, here::here(\"raw_data\", \"qa_dat_wide.rds\"))\n\nJetzt können wir mal testweise schauen ob das geklappt hat:\n\nhead(qa_dat_wide)\n\n# A tibble: 6 × 14\n  ID      gender bundeslandStudium spiegelReadingfreq   age `3401` `3402` `3403`\n  &lt;chr&gt;    &lt;dbl&gt;             &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 123859…      2                 3                  1    21      0      0      0\n2 123841…      1                 3                  1    19      0      1      1\n3 123802…      2                 3                  2    23      0      0      0\n4 123781…      1                 3                  7    23      0      0      1\n5 123765…      2                 3                 NA    23      0      1      1\n6 123883…      2                 3                 NA    23      0      0      1\n# ℹ 6 more variables: `3404` &lt;dbl&gt;, `3405` &lt;dbl&gt;, `3406` &lt;dbl&gt;, `3407` &lt;dbl&gt;,\n#   `3408` &lt;dbl&gt;, `3409` &lt;dbl&gt;\n\n\nYaay, sieht gut aus.",
    "crumbs": [
      "Übungen",
      "Linking",
      "1. Die Daten"
    ]
  },
  {
    "objectID": "exercises/linking/dif.html",
    "href": "exercises/linking/dif.html",
    "title": "3. Differential Item Functioning",
    "section": "",
    "text": "source(here::here(\"R\", \"plot_functions.R\"))\nqa_dat_wide &lt;- readRDS(here::here(\"raw_data\", \"qa_dat_wide.rds\"))\nN = 2, M = 5 machine precision = 2.22045e-16\nThis problem is unconstrained.\n\niterations 8\nfunction evaluations 9\nsegments explored during Cauchy searches 1\nBFGS updates skipped 0\nactive bounds at final generalized Cauchy point 0\nnorm of the final projected gradient 1.05021e-08\nfinal function value 0.00200998\n\nfinal  value 0.002010 \nconverged",
    "crumbs": [
      "Übungen",
      "Linking",
      "3. Differential Item Functioning"
    ]
  },
  {
    "objectID": "exercises/linking/dif.html#kalibrierung",
    "href": "exercises/linking/dif.html#kalibrierung",
    "title": "3. Differential Item Functioning",
    "section": "\n1.1 Kalibrierung",
    "text": "1.1 Kalibrierung\nZuerst müssen wir die Daten noch einmal kalibrieren (andere Pakete ermöglichen es auch, beides direkt in einer Funktion zu kombinieren).\nDafür nutzen wir diesmal aber mirt, weil equateIRT den Output daraus verarbeiten kann.\nFitte jetzt mit mirt ein Raschmodell auf beide Subgruppen seperat (männlich und weiblich). Der Datensatz darf nur die Itemspalten enthalten. Setze SE = TRUE um die Modell-Informationsmatrix zu berechnen, das ist gleich für den Waldtest nötig.\n\nlibrary(mirt)\n\nLoading required package: stats4\n\n\nLoading required package: lattice\n\nlibrary(tidyverse)\n\nm_f &lt;- qa_f %&gt;%\n  select(-ID, -gender, -bundeslandStudium, -spiegelReadingfreq, -age) %&gt;%\n  mirt(itemtype = \"Rasch\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -1197.615, Max-Change: 0.23858\nIteration: 2, Log-Lik: -1191.066, Max-Change: 0.13198\nIteration: 3, Log-Lik: -1187.736, Max-Change: 0.08322\nIteration: 4, Log-Lik: -1185.813, Max-Change: 0.05803\nIteration: 5, Log-Lik: -1184.627, Max-Change: 0.04123\nIteration: 6, Log-Lik: -1183.858, Max-Change: 0.03128\nIteration: 7, Log-Lik: -1183.337, Max-Change: 0.02526\nIteration: 8, Log-Lik: -1182.948, Max-Change: 0.01953\nIteration: 9, Log-Lik: -1182.679, Max-Change: 0.01600\nIteration: 10, Log-Lik: -1182.487, Max-Change: 0.01649\nIteration: 11, Log-Lik: -1182.323, Max-Change: 0.01116\nIteration: 12, Log-Lik: -1182.209, Max-Change: 0.00953\nIteration: 13, Log-Lik: -1182.126, Max-Change: 0.01525\nIteration: 14, Log-Lik: -1182.046, Max-Change: 0.00708\nIteration: 15, Log-Lik: -1181.991, Max-Change: 0.00619\nIteration: 16, Log-Lik: -1181.949, Max-Change: 0.01027\nIteration: 17, Log-Lik: -1181.909, Max-Change: 0.00480\nIteration: 18, Log-Lik: -1181.880, Max-Change: 0.00426\nIteration: 19, Log-Lik: -1181.858, Max-Change: 0.00698\nIteration: 20, Log-Lik: -1181.837, Max-Change: 0.00339\nIteration: 21, Log-Lik: -1181.821, Max-Change: 0.00305\nIteration: 22, Log-Lik: -1181.809, Max-Change: 0.00495\nIteration: 23, Log-Lik: -1181.797, Max-Change: 0.00248\nIteration: 24, Log-Lik: -1181.788, Max-Change: 0.00224\nIteration: 25, Log-Lik: -1181.781, Max-Change: 0.00338\nIteration: 26, Log-Lik: -1181.774, Max-Change: 0.00185\nIteration: 27, Log-Lik: -1181.768, Max-Change: 0.00168\nIteration: 28, Log-Lik: -1181.764, Max-Change: 0.00263\nIteration: 29, Log-Lik: -1181.760, Max-Change: 0.00140\nIteration: 30, Log-Lik: -1181.757, Max-Change: 0.00128\nIteration: 31, Log-Lik: -1181.755, Max-Change: 0.00205\nIteration: 32, Log-Lik: -1181.752, Max-Change: 0.00107\nIteration: 33, Log-Lik: -1181.750, Max-Change: 0.00098\nIteration: 34, Log-Lik: -1181.749, Max-Change: 0.00218\nIteration: 35, Log-Lik: -1181.747, Max-Change: 0.00083\nIteration: 36, Log-Lik: -1181.746, Max-Change: 0.00076\nIteration: 37, Log-Lik: -1181.745, Max-Change: 0.00072\nIteration: 38, Log-Lik: -1181.744, Max-Change: 0.00065\nIteration: 39, Log-Lik: -1181.743, Max-Change: 0.00060\nIteration: 40, Log-Lik: -1181.743, Max-Change: 0.00106\nIteration: 41, Log-Lik: -1181.742, Max-Change: 0.00051\nIteration: 42, Log-Lik: -1181.742, Max-Change: 0.00047\nIteration: 43, Log-Lik: -1181.741, Max-Change: 0.00079\nIteration: 44, Log-Lik: -1181.741, Max-Change: 0.00040\nIteration: 45, Log-Lik: -1181.741, Max-Change: 0.00037\nIteration: 46, Log-Lik: -1181.741, Max-Change: 0.00060\nIteration: 47, Log-Lik: -1181.740, Max-Change: 0.00032\nIteration: 48, Log-Lik: -1181.740, Max-Change: 0.00029\nIteration: 49, Log-Lik: -1181.740, Max-Change: 0.00027\nIteration: 50, Log-Lik: -1181.740, Max-Change: 0.00025\nIteration: 51, Log-Lik: -1181.740, Max-Change: 0.00023\nIteration: 52, Log-Lik: -1181.740, Max-Change: 0.00021\nIteration: 53, Log-Lik: -1181.740, Max-Change: 0.00020\nIteration: 54, Log-Lik: -1181.739, Max-Change: 0.00018\nIteration: 55, Log-Lik: -1181.739, Max-Change: 0.00018\nIteration: 56, Log-Lik: -1181.739, Max-Change: 0.00016\nIteration: 57, Log-Lik: -1181.739, Max-Change: 0.00015\nIteration: 58, Log-Lik: -1181.739, Max-Change: 0.00018\nIteration: 59, Log-Lik: -1181.739, Max-Change: 0.00012\nIteration: 60, Log-Lik: -1181.739, Max-Change: 0.00012\nIteration: 61, Log-Lik: -1181.739, Max-Change: 0.00017\nIteration: 62, Log-Lik: -1181.739, Max-Change: 0.00010\n\nCalculating information matrix...\n\nm_m &lt;- qa_m %&gt;%\n  select(-ID, -gender, -bundeslandStudium, -spiegelReadingfreq, -age) %&gt;%\n  mirt(itemtype = \"Rasch\", SE = TRUE)\n\n\nIteration: 1, Log-Lik: -1532.244, Max-Change: 0.15028\nIteration: 2, Log-Lik: -1528.882, Max-Change: 0.09393\nIteration: 3, Log-Lik: -1527.070, Max-Change: 0.06393\nIteration: 4, Log-Lik: -1525.988, Max-Change: 0.04807\nIteration: 5, Log-Lik: -1525.320, Max-Change: 0.03397\nIteration: 6, Log-Lik: -1524.916, Max-Change: 0.02597\nIteration: 7, Log-Lik: -1524.657, Max-Change: 0.02166\nIteration: 8, Log-Lik: -1524.464, Max-Change: 0.01603\nIteration: 9, Log-Lik: -1524.347, Max-Change: 0.01287\nIteration: 10, Log-Lik: -1524.271, Max-Change: 0.01116\nIteration: 11, Log-Lik: -1524.208, Max-Change: 0.00853\nIteration: 12, Log-Lik: -1524.170, Max-Change: 0.00704\nIteration: 13, Log-Lik: -1524.145, Max-Change: 0.00629\nIteration: 14, Log-Lik: -1524.122, Max-Change: 0.00486\nIteration: 15, Log-Lik: -1524.109, Max-Change: 0.00407\nIteration: 16, Log-Lik: -1524.100, Max-Change: 0.00366\nIteration: 17, Log-Lik: -1524.092, Max-Change: 0.00288\nIteration: 18, Log-Lik: -1524.087, Max-Change: 0.00243\nIteration: 19, Log-Lik: -1524.083, Max-Change: 0.00221\nIteration: 20, Log-Lik: -1524.080, Max-Change: 0.00174\nIteration: 21, Log-Lik: -1524.078, Max-Change: 0.00148\nIteration: 22, Log-Lik: -1524.077, Max-Change: 0.00135\nIteration: 23, Log-Lik: -1524.076, Max-Change: 0.00107\nIteration: 24, Log-Lik: -1524.075, Max-Change: 0.00091\nIteration: 25, Log-Lik: -1524.075, Max-Change: 0.00083\nIteration: 26, Log-Lik: -1524.074, Max-Change: 0.00066\nIteration: 27, Log-Lik: -1524.074, Max-Change: 0.00056\nIteration: 28, Log-Lik: -1524.074, Max-Change: 0.00051\nIteration: 29, Log-Lik: -1524.074, Max-Change: 0.00042\nIteration: 30, Log-Lik: -1524.074, Max-Change: 0.00035\nIteration: 31, Log-Lik: -1524.073, Max-Change: 0.00032\nIteration: 32, Log-Lik: -1524.073, Max-Change: 0.00026\nIteration: 33, Log-Lik: -1524.073, Max-Change: 0.00022\nIteration: 34, Log-Lik: -1524.073, Max-Change: 0.00020\nIteration: 35, Log-Lik: -1524.073, Max-Change: 0.00016\nIteration: 36, Log-Lik: -1524.073, Max-Change: 0.00014\nIteration: 37, Log-Lik: -1524.073, Max-Change: 0.00014\nIteration: 38, Log-Lik: -1524.073, Max-Change: 0.00010\nIteration: 39, Log-Lik: -1524.073, Max-Change: 0.00008\n\nCalculating information matrix...",
    "crumbs": [
      "Übungen",
      "Linking",
      "3. Differential Item Functioning"
    ]
  },
  {
    "objectID": "exercises/linking/dif.html#waldtest-1",
    "href": "exercises/linking/dif.html#waldtest-1",
    "title": "3. Differential Item Functioning",
    "section": "\n1.2 Waldtest",
    "text": "1.2 Waldtest\nNutze jetzt die Funktion dif.test() aus dem Paket equateIRT um den Waldtest durchzuführen. Nutze, wie in der vorherigen Übung, die Stocking-Lord Methode zum linken. Welche Items zeigen laut Waldtest DIF?\n\n\n\n\n\n\n\nlibrary(equateIRT)\n\ndif_test &lt;- dif.test(est.mods = list(m_f, m_m), method = \"Stocking-Lord\", purification = FALSE)\n\ndif_test\n\n\n  Test for Differential Item Functioning\n\nItem parameters tested for DIF: intercept\nEquating method used: Stocking-Lord \nReference group: T1  Focal group: T2 \nItem purification not applied\n\n     statistic  p.value      \n3401    12.140 0.000493 ***  \n3402     4.127 0.042210 *    \n3403     5.460 0.019459 *    \n3404     1.671 0.196099      \n3405    42.451 7.25e-11 ***  \n3406     0.901 0.342624      \n3407     5.004 0.025285 *    \n3408    14.929 0.000112 ***  \n3409     0.857 0.354487      \n---\nSignif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nMit purification = TRUE würde ein iteratives Vorgehen verwendet werden, bei dem nacheinander DIF Items entfernt werden, um die Personenfähigkeit ohne die komprimierenden Items zu schätzen. Weil wir aber gleich die Ergebnisse mit unserem Manuellen Vorgehen vergleichen wollen, verzichten wir darauf.\n\n\n\nZuerst einmal zeigen laut Waldtest viele der Items bei einem Signifikanzniveau von 0.05 DIF. Das ist aber auch nicht weiter verwunderlich, da der Test sicherlich nicht in Hinblick auf die Vermeidung von DIF konstruiert wurde.",
    "crumbs": [
      "Übungen",
      "Linking",
      "3. Differential Item Functioning"
    ]
  },
  {
    "objectID": "exercises/linking/dif.html#vergleich-mit-manuellem-linking",
    "href": "exercises/linking/dif.html#vergleich-mit-manuellem-linking",
    "title": "3. Differential Item Functioning",
    "section": "\n1.3 Vergleich mit manuellem Linking",
    "text": "1.3 Vergleich mit manuellem Linking\nDa in dif.test() jetzt genauso gelinkt wurde, können wir jetzt einmal die Ergebnisse aus diesem Vorgehen mit dem aus dem manuellen Linking vergleichen.\nSo sehen die Itemparameter aus, die von dif.test() berechnete wurden:\n\ndif_test$coef_trasf\n\n[[1]]\n           beta1\n3401 -2.40978789\n3402 -0.01907878\n3403 -0.19102453\n3404  0.75291490\n3405  0.19096995\n3406  0.92972284\n3407 -0.95266283\n3408 -0.30686976\n3409  1.65436012\n\n[[2]]\n          beta1\n3401 -1.5885977\n3402 -0.4704207\n3403 -0.6954343\n3404  0.9232955\n3405 -1.0471252\n3406  1.0361797\n3407 -0.6360839\n3408  0.3085281\n3409  1.3261040\n\n\nUnd das hier waren die Parameter, die wir mit TAM gelinkt haben:\n\ndifficulty_link_f\n\n[1]  0.63703272 -0.48116307 -0.25614572 -1.87489822  0.09555167 -1.98778205\n[7] -0.31549713 -1.26012532 -2.27770429\n\ndifficulty_link_m\n\n[1]  1.51485121 -0.87557032 -0.70365354 -1.64743999 -1.08558352 -1.82422270\n[7]  0.05786946 -0.58782743 -2.54877366\n\n\nWas fällt auf?\n:::{.callout-caution collapse = “true”} ## Lösung\nZuerst einmal scheinen die Vorzeichen der Itemschwierigkeiten vertauscht zu sein. Wir habne in dif.test() also die Itemleichtigkeiten geschätzt. Das ist aber leicht durch eine Multiplikation mit -1 zu beheben.\nAnsonsten scheinen mirt und tam die gleichen Ergebnisse bei der Kalibrierung bekommen zu haben. Das Linking ist auch ähnlich, allerdings nicht exakt, obwohl wir die gleiche Mehtode verwendet haben. Wir könnten jetzt noch auf die Suche gehen, was genau beide Funktionen per Default anders machen, aber für uns soll das erst einmal reichen.\n:::",
    "crumbs": [
      "Übungen",
      "Linking",
      "3. Differential Item Functioning"
    ]
  },
  {
    "objectID": "exercises/linking/dif.html#beurteilung",
    "href": "exercises/linking/dif.html#beurteilung",
    "title": "3. Differential Item Functioning",
    "section": "\n1.4 Beurteilung",
    "text": "1.4 Beurteilung\nWir haben jetzt also gesehen, was die dif.test() Funktion unter der Haub macht und Signifikanzwerte erhalten, die uns potenziellen DIF anzeigen.\n\nNatürlich treffen auch hier die üblichen Caveats zu Signifikanztests zu. Bei größer werdender Stichprobe werden so gut wie alle Gruppenunterschiede signifikant. Wir sollten daher auf keinen Fall nur auf die Signifikanz schauen, sondern auch die Effektstärke (z.B. Unterschied in Itemschwierigkeit ziwschen den Gruppen) und unbedingt auch inhaltliche Kriterien in die Beurteilung mit einfließen lassen. Wichtig ist einfach, alles zu kommunizieren, damit nachvollziebar bleibt, was warum getan wurde.\n\nEs gibt also einige Items, die für eine weiter DIF-Analyse in Frage kommen. Wir schauen uns jetzt mal die Unterschiede grafisch an, um auch ein Gefühl für das Ausmaß des DIF zu bekommen.\n\nCode## Für die Fragen benötigt\nqa_dat &lt;- readRDS(here::here(\"raw_data\", \"q_a_wirt_b.rds\"))\n\ngroup_difference &lt;- as.vector(dif_test$coef_trasf[[1]] * -1) - as.vector(dif_test$coef_trasf[[2]] * -1)\n\nquestions &lt;- qa_dat %&gt;%\n  select(question_code, varLabel) %&gt;%\n  unique() %&gt;%\n  mutate(varLabel = stringr::str_wrap(varLabel, 20))\n\n## Prepare Data for\ndif_dat &lt;- data.frame(\n  item = colnames(qa_f[, 6:ncol(qa_f)]),\n  group_difference = group_difference,\n  group_favour = ifelse(group_difference &gt; 0, \"m\", \"f\"),\n  p_value = dif_test$test[, \"p.value\"]\n) %&gt;%\n  mutate(label_x = abs(group_difference) + 0.25) %&gt;%\n  mutate(significance = ifelse(p_value &lt; 0.05, \"Significant\", \"Not Significant\")) %&gt;%\n  left_join(questions, join_by(\"item\" == \"question_code\"))\n\n\nggplot(data = dif_dat, aes(x = abs(group_difference), y = item)) +\n  # Add vertical line at x = 0\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"darkgray\") +\n\n  # Add lines from 0 to the points\n  geom_segment(aes(x = 0, xend = abs(group_difference), y = item, yend = item),\n    linewidth = 0.75, colour = \"grey\"\n  ) +\n\n  # Add the points\n  geom_point(aes(colour = group_favour, shape = significance), size = 3) +\n  geom_label(aes(x = label_x, label = varLabel), size = 2) +\n  # Optional: Customize the theme\n  theme_bg() +\n  scale_colour_manual(values = c(\"#01364C\", \"#9B1B34\", \"#F4BA02\")) +\n  xlim(0, 1.75) +\n  labs(x = \"Gruppenunterschied in Itemschwierigkeit\", y = \"Item\")\n\n\n\n\n\n\n\nVon Interesse ist vielleicht noch bei Item 3401 von wem dort die Rede ist. Es geht um Dieter Zetsche, den ehemaligen Vorstandsvorsitzenden der Daimler AG (Mercedes-Benz-Group).\n[^1]\n[^1] Bild von Matti Blume, heruntergeladen von Wikipedia.\nWie würdest du den DIF beurteilen?",
    "crumbs": [
      "Übungen",
      "Linking",
      "3. Differential Item Functioning"
    ]
  },
  {
    "objectID": "exercises/intro_r/merging_ex.html",
    "href": "exercises/intro_r/merging_ex.html",
    "title": "Merging",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n## Reshape into long format:\npsych_stats &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\n## Take a look at the data sets\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\ntibble [323,596 × 3] (S3: tbl_df/tbl/data.frame)\n $ char_id : chr [1:323596] \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ question: chr [1:323596] \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating  : num [1:323596] 95.7 95.2 6.1 6.2 6.4 ...\n\n\n\n\n\nNow we have gotten to know our characters data set a bit more. However, the personality ratings are not included yet. For that, we need to combine it with the psych_stats data set.\n\nMerge the characters data frame and the psych_stats data frame on a common column.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIdentify the common columns. Are they named the same in both data frames? Look at the documentation of ?merge to see, how you can merge data frames that don’t have identically named columns.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFirst, let’s take a look at both data sets again:\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\ntibble [323,596 × 3] (S3: tbl_df/tbl/data.frame)\n $ char_id : chr [1:323596] \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ question: chr [1:323596] \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating  : num [1:323596] 95.7 95.2 6.1 6.2 6.4 ...\n\n\nIt seems like both data frames have a column containing an ID for the character. We can use that column for merging:\n\ncharacters_stats &lt;- merge(\n  x = characters,\n  y = psych_stats,\n  by.x = \"id\", \n  by.y = \"char_id\"\n)\n\nstr(characters_stats)\n\n'data.frame':   323596 obs. of  9 variables:\n $ id        : chr  \"AD1\" \"AD1\" \"AD1\" \"AD1\" ...\n $ name      : chr  \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" ...\n $ uni_id    : chr  \"AD\" \"AD\" \"AD\" \"AD\" ...\n $ uni_name  : chr  \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" ...\n $ notability: num  76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  68.6 73.3 10.8 22.2 45.1 16.2 86.3 74.7 15.4 36.2 ...\n\n\nWorked like a charm!",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Merging"
    ]
  },
  {
    "objectID": "exercises/intro_r/merging_ex.html#exercise-1",
    "href": "exercises/intro_r/merging_ex.html#exercise-1",
    "title": "Merging",
    "section": "",
    "text": "Merge the characters data frame and the psych_stats data frame on a common column.\n\n\n\n\n\n\nHint\n\n\n\n\n\nIdentify the common columns. Are they named the same in both data frames? Look at the documentation of ?merge to see, how you can merge data frames that don’t have identically named columns.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nFirst, let’s take a look at both data sets again:\n\nstr(characters)\n\n'data.frame':   889 obs. of  7 variables:\n $ id        : chr  \"F2\" \"F1\" \"F5\" \"F4\" ...\n $ name      : chr  \"Monica Geller\" \"Rachel Green\" \"Chandler Bing\" \"Joey Tribbiani\" ...\n $ uni_id    : chr  \"F\" \"F\" \"F\" \"F\" ...\n $ uni_name  : chr  \"Friends\" \"Friends\" \"Friends\" \"Friends\" ...\n $ notability: num  79.7 76.7 74.4 74.3 72.6 51.6 86.5 84.2 82.6 65.6 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/F/2\" \"https://openpsychometrics.org/tests/characters/stats/F/1\" \"https://openpsychometrics.org/tests/characters/stats/F/5\" \"https://openpsychometrics.org/tests/characters/stats/F/4\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\" ...\n\nstr(psych_stats)\n\ntibble [323,596 × 3] (S3: tbl_df/tbl/data.frame)\n $ char_id : chr [1:323596] \"F2\" \"F2\" \"F2\" \"F2\" ...\n $ question: chr [1:323596] \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating  : num [1:323596] 95.7 95.2 6.1 6.2 6.4 ...\n\n\nIt seems like both data frames have a column containing an ID for the character. We can use that column for merging:\n\ncharacters_stats &lt;- merge(\n  x = characters,\n  y = psych_stats,\n  by.x = \"id\", \n  by.y = \"char_id\"\n)\n\nstr(characters_stats)\n\n'data.frame':   323596 obs. of  9 variables:\n $ id        : chr  \"AD1\" \"AD1\" \"AD1\" \"AD1\" ...\n $ name      : chr  \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" \"Michael Bluth\" ...\n $ uni_id    : chr  \"AD\" \"AD\" \"AD\" \"AD\" ...\n $ uni_name  : chr  \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" \"Arrested Development\" ...\n $ notability: num  76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 76.9 ...\n $ link      : chr  \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" \"https://openpsychometrics.org/tests/characters/stats/AD/1\" ...\n $ image_link: chr  \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" \"https://openpsychometrics.org/tests/characters/test-resources/pics/AD/1.jpg\" ...\n $ question  : chr  \"messy_neat\" \"disorganized_self.disciplined\" \"diligent_lazy\" \"on.time_tardy\" ...\n $ rating    : num  68.6 73.3 10.8 22.2 45.1 16.2 86.3 74.7 15.4 36.2 ...\n\n\nWorked like a charm!",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Merging"
    ]
  },
  {
    "objectID": "exercises/intro_r/load_data_ex.html",
    "href": "exercises/intro_r/load_data_ex.html",
    "title": "Einlesen von Daten",
    "section": "",
    "text": "Erstelle einen neuen Ordner data in deinem Arbeitsverzeichnis. Gehe dann auf GitHub, downloade die beiden Datensätze psych_stats.csv und characters.rds, und speichere sie in deinem neu erstellen data Ordner ab.\n\nZum Downloaden von GitHub, klicke auf die Datei. Es öffnet sich eine neue Seite, auf der du oben rechts den Button “Download” findest.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Einlesen von Daten"
    ]
  },
  {
    "objectID": "exercises/intro_r/load_data_ex.html#download",
    "href": "exercises/intro_r/load_data_ex.html#download",
    "title": "Einlesen von Daten",
    "section": "",
    "text": "Erstelle einen neuen Ordner data in deinem Arbeitsverzeichnis. Gehe dann auf GitHub, downloade die beiden Datensätze psych_stats.csv und characters.rds, und speichere sie in deinem neu erstellen data Ordner ab.\n\nZum Downloaden von GitHub, klicke auf die Datei. Es öffnet sich eine neue Seite, auf der du oben rechts den Button “Download” findest.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Einlesen von Daten"
    ]
  },
  {
    "objectID": "exercises/intro_r/load_data_ex.html#einlesen",
    "href": "exercises/intro_r/load_data_ex.html#einlesen",
    "title": "Einlesen von Daten",
    "section": "\n2 2. Einlesen",
    "text": "2 2. Einlesen\nLies beide Datensätze in deinem R-Skript ein. Schaue dir vor allem den psych_stats Datensatz danach genauer an. Hat alles geklappt? Wenn nicht, woran könnte es liegen?\n\n\n\n\n\n\nTipp 1\n\n\n\n\n\nEs handelt sich um eine .rds-Datei und eine .csv-Datei.\n\n\n\n\n\n\n\n\n\nTipp 2\n\n\n\n\n\nÖffne die .csv-Datei und schaue nach, durch welches Zeichen die Werte getrennt sind. Nutze das sep Argument in read.csv!\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Einlesen von Daten"
    ]
  },
  {
    "objectID": "exercises/intro_r/missings_ex.html",
    "href": "exercises/intro_r/missings_ex.html",
    "title": "Missings",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n\n\n\n\n\nDoes the characters data set contain any NAs?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse any() to see if a logical vector contains any TRUE values.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nany(is.na(characters))\n\n[1] FALSE\n\n\nNo, there don’t seem to be any NAs in this data set, which would be great in real life. For this exercise it’s not great, so let’s introduce some NAs manually.\n\n\n\n\nBe careful not to overwrite the characters data frame, so copy it into the new object characters_na before doing anything. Then set the name to NA in the rows 34, 103, 300 and the uni_name to NA in the rows 404, 670.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo overwrite values, you can select them on the left side of the assignment operator &lt;- and assign them a new value on the right side.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters\n\ncharacters_na[c(34, 103, 300), \"name\"] &lt;- NA\ncharacters_na[c(404, 670), \"uni_name\"] &lt;- NA\n\n\n\n\n\nRemove all rows containing missing values in the column name from the characters_na data frame.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters_na[!is.na(characters_na$name), ]\n\nOr:\n\n\nlibrary(tidyverse)\n\ncharacters_na &lt;- characters_na %&gt;%\n  drop_na(name)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Missings"
    ]
  },
  {
    "objectID": "exercises/intro_r/missings_ex.html#exercise-1",
    "href": "exercises/intro_r/missings_ex.html#exercise-1",
    "title": "Missings",
    "section": "",
    "text": "Does the characters data set contain any NAs?\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse any() to see if a logical vector contains any TRUE values.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nany(is.na(characters))\n\n[1] FALSE\n\n\nNo, there don’t seem to be any NAs in this data set, which would be great in real life. For this exercise it’s not great, so let’s introduce some NAs manually.\n\n\n\n\nBe careful not to overwrite the characters data frame, so copy it into the new object characters_na before doing anything. Then set the name to NA in the rows 34, 103, 300 and the uni_name to NA in the rows 404, 670.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nTo overwrite values, you can select them on the left side of the assignment operator &lt;- and assign them a new value on the right side.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters\n\ncharacters_na[c(34, 103, 300), \"name\"] &lt;- NA\ncharacters_na[c(404, 670), \"uni_name\"] &lt;- NA\n\n\n\n\n\nRemove all rows containing missing values in the column name from the characters_na data frame.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters_na &lt;- characters_na[!is.na(characters_na$name), ]\n\nOr:\n\n\nlibrary(tidyverse)\n\ncharacters_na &lt;- characters_na %&gt;%\n  drop_na(name)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Missings"
    ]
  },
  {
    "objectID": "exercises/index_linking.html",
    "href": "exercises/index_linking.html",
    "title": "Linking",
    "section": "",
    "text": "Ziel dieser Übung ist es, grundlegendes Linking in R auszuprobieren, und eine erste Differential Item Functioning (DIF) Analyse durchzuführen.\n\n\n\n\n\n\nDer erste Teil der Übung behandelt noch einmal Datenaufbereitung im IRT Kontext. Wenn du möchtest, kannst du diesen Teil auch erst einmal überspringen und direkt mit den aufbereiteten Daten arbeiten.\n\n\n\n\n\n\n\n\n\n   \n     \n     \n       Sortieren nach\n       Voreinstellung\n         \n          Titel\n        \n         \n          Autor:in\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitel\n\n\nAutor:in\n\n\n\n\n\n\n1. Die Daten\n\n\nNicklas Hafiz\n\n\n\n\n2. Linking\n\n\nNicklas Hafiz\n\n\n\n\n3. Differential Item Functioning\n\n\nNicklas Hafiz\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen",
      "Linking"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IRT Workshop",
    "section": "",
    "text": "0.1 Tag 1\n\nProgramm 1\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n10:00 – 13:00\nEinführung in Modellierung latenter Variablen\nTheoretische Einführung in die Modellierung latenter Variablen in Klassischer Testtheorie und Item Response Theory (IRT) (90 min.; SW)\n\n\n11:30 – 13:00\nEinführung in R\nEinführung in die R-Programmierumgebung. Datenaufbereitung für IRT-Analysen. (90 min.; NH)\n\n\n14:00 – 17:00\nIRT-Modelle in TAM\nÜbung: einfacher IRT-Modelle in TAM. Theoretische Unterscheidung zwischen JML, CML und MML (SW).\n\n\n14:00 – 17:00\nRaschmodell und GLMM\nTheoretische Einführung und praktische Illustration: Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells (GLMM) (NH + SW).\n\n\n14:00 – 17:00\nReliabilität und Validität\nReliabilität, Validität, lokale stochastische Unabhängigkeit\n\n\n\n0.2 Tag 2\n\nProgramm 2\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n09:00 – 12:00\nLinking und Differential Item Functioning\nVerlinkte Items, lokale stochastische Unabhängigkeit, Messinvarianz (90 min.; NH)\n\n\n09:00 – 12:00\nBedeutung von Testdesigns\nDie Bedeutung von Testdesigns. Was kann schiefgehen, wenn Testdesigns ungeeignet sind? (SW)\n\n\n13:00 – 16:00\nHöher parametrisierte Modelle\nHöher parametrisierte Modelle: 2pl, 3pl, partial credit (NH)\n\n\n13:00 – 16:00\nLängsschnittliche Designs\nLängsschnittliche Designs: Wiederholte Messungen für Individuen, Kohorten oder Populationen (SW)\n\n\n\n\n\n\n\n\n0.3 Tag 3\n\nProgramm 3\n\n\n\n\n\n\nZeit\nThema\nBeschreibung\n\n\n\n09:00 – 12:00\nPraktische Überlegungen\nPraktische Überlegungen: Welches Modell für welche Forschungsfrage? Wieviele Personen sind notwendig für welches Forschungsdesign? Theoretische Überlegungen und praktische Empfehlungen (180 min., SW + NH)\n\n\n13:00 – 16:00\nDas ganze Bild\nVollständige “Schritt für Schritt”-Analyse von Forschungsdaten: Datenaufbereitung, Kalibrierung, Plausibilitätsprüfungen, Messinvarianz, Beantworten von Forschungsfragen (180 Min., SW/NH)"
  },
  {
    "objectID": "exercises/index_xPL.html",
    "href": "exercises/index_xPL.html",
    "title": "Höher parametrisierte Modelle",
    "section": "",
    "text": "Keine Treffer"
  },
  {
    "objectID": "exercises/glm/glm.html",
    "href": "exercises/glm/glm.html",
    "title": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Ziel dieser übung ist es, Daten für ein einfachs Raschmodell zu simulieren. Warum? Weil wir so die Datengenerierenden Prozesse besser verstehen können. Also, let’s get started.\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse",
    "crumbs": [
      "Übungen",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells"
    ]
  },
  {
    "objectID": "exercises/glm/glm.html#simulation",
    "href": "exercises/glm/glm.html#simulation",
    "title": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Ziel dieser übung ist es, Daten für ein einfachs Raschmodell zu simulieren. Warum? Weil wir so die Datengenerierenden Prozesse besser verstehen können. Also, let’s get started.\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse",
    "crumbs": [
      "Übungen",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
      "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html",
    "href": "exercises/intro_r/reshaping_ex.html",
    "title": "Reshaping",
    "section": "",
    "text": "Previous code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html#exercise-1",
    "href": "exercises/intro_r/reshaping_ex.html#exercise-1",
    "title": "Reshaping",
    "section": "\n1 Exercise 1",
    "text": "1 Exercise 1\nTake a look at the data frame psych_stats. Which format does it have?\n\nWide format\nLong format\nNone of the above\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nWide format\nLong format\nNone of the above\n\nEach unit of observation, in this case each character, only has one row.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html#exercise-2",
    "href": "exercises/intro_r/reshaping_ex.html#exercise-2",
    "title": "Reshaping",
    "section": "\n2 Exercise 2",
    "text": "2 Exercise 2\nReshape it, so there are only three columns in the data set: char_id, question and rating.\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou can select multiple columns like this: column_1:column_10.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\npsych_stats &lt;- psych_stats %&gt;%\n  pivot_longer(cols = messy_neat:innocent_jaded, \n               names_to = \"question\", \n               values_to = \"rating\")\n\nhead(psych_stats)\n\n# A tibble: 6 × 3\n  char_id question                      rating\n  &lt;chr&gt;   &lt;chr&gt;                          &lt;dbl&gt;\n1 F2      messy_neat                     95.7 \n2 F2      disorganized_self.disciplined  95.2 \n3 F2      diligent_lazy                   6.10\n4 F2      on.time_tardy                   6.2 \n5 F2      competitive_cooperative         6.40\n6 F2      scheduled_spontaneous           6.60\n\n\nNow we have multiple rows for every character, but all question ratings are nicely aligned in one column.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/reshaping_ex.html#exercise-3",
    "href": "exercises/intro_r/reshaping_ex.html#exercise-3",
    "title": "Reshaping",
    "section": "\n3 Exercise 3",
    "text": "3 Exercise 3\nTry to reshape the data into long format again.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\npsych_stats %&gt;%\n  pivot_wider(id_cols = char_id, \n               names_from = \"question\", \n               values_from = \"rating\")\n\n# A tibble: 889 × 365\n   char_id messy_neat disorganized_self.disciplined diligent_lazy on.time_tardy\n   &lt;chr&gt;        &lt;dbl&gt;                         &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n 1 F2           95.7                           95.2          6.10           6.2\n 2 F1           30.2                           25.9         51.8           77.9\n 3 F5           45.3                           42.4         52.2           57.1\n 4 F4           13                             11           78.1           84.1\n 5 F3           20.9                           20.9         45.2           74  \n 6 F6           81                             75.6         20             20.6\n 7 EU1           9.60                          10.4         62.3           85.7\n 8 EU2          27.7                           31.9         23.7           68.3\n 9 EU6          40                             39.6         54.1           73.6\n10 EU3          43.9                           31.1         32.2           58.2\n# ℹ 879 more rows\n# ℹ 360 more variables: competitive_cooperative &lt;dbl&gt;,\n#   scheduled_spontaneous &lt;dbl&gt;, ADHD_OCD &lt;dbl&gt;, chaotic_orderly &lt;dbl&gt;,\n#   motivated_unmotivated &lt;dbl&gt;, bossy_meek &lt;dbl&gt;, persistent_quitter &lt;dbl&gt;,\n#   overachiever_underachiever &lt;dbl&gt;, muddy_washed &lt;dbl&gt;, beautiful_ugly &lt;dbl&gt;,\n#   slacker_workaholic &lt;dbl&gt;, driven_unambitious &lt;dbl&gt;, outlaw_sheriff &lt;dbl&gt;,\n#   precise_vague &lt;dbl&gt;, bad.cook_good.cook &lt;dbl&gt;, manicured_scruffy &lt;dbl&gt;, …\n\n\nThis is how we got it! But scratch that, it was just for the sake of the exercise. We want to use psych_stats in the long format from now on.",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Reshaping"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html",
    "href": "exercises/intro_r/subsetting_ex.html",
    "title": "Subsetting",
    "section": "",
    "text": "Vorheriger Code\n\n\n\n\n\n\n# install.packages(\"tidyverse\")\n# install.packages(\"here\")\n\nlibrary(tidyverse)\nlibrary(here)\n\n## Load the data\ncharacters &lt;- readRDS(file = here::here(\"raw_data\", \"characters.rds\"))\npsych_stats &lt;- read.csv(\n  file = here::here(\"raw_data\", \"psych_stats.csv\"),\n  sep = \";\"\n)\n\n\n\n\n\nKorrigiere den folgenden Code, sodass nur die ersten 10 Zeilen und die letzten 3 Spalten ausgewählt werden.\n\ncharacters[4:6, 10]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWir müssen die Zeilen, die wir auswählen wollen, vor dem Komma , schreiben, die Spalten danach.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[1:10, 4:6]\n\n   uni_name notability\n1   Friends       79.7\n2   Friends       76.7\n3   Friends       74.4\n4   Friends       74.3\n5   Friends       72.6\n6   Friends       51.6\n7  Euphoria       86.5\n8  Euphoria       84.2\n9  Euphoria       82.6\n10 Euphoria       65.6\n                                                        link\n1   https://openpsychometrics.org/tests/characters/stats/F/2\n2   https://openpsychometrics.org/tests/characters/stats/F/1\n3   https://openpsychometrics.org/tests/characters/stats/F/5\n4   https://openpsychometrics.org/tests/characters/stats/F/4\n5   https://openpsychometrics.org/tests/characters/stats/F/3\n6   https://openpsychometrics.org/tests/characters/stats/F/6\n7  https://openpsychometrics.org/tests/characters/stats/EU/1\n8  https://openpsychometrics.org/tests/characters/stats/EU/2\n9  https://openpsychometrics.org/tests/characters/stats/EU/6\n10 https://openpsychometrics.org/tests/characters/stats/EU/3\n\n\n\n\n\n\n\nWarum funktioniert der folgende Code nicht? Korrigiere ihn in deinem eigenen Skript.\n\n\ncharacters[uni_name == \"Friends\", ]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nYou need to extract the column from the data frame with $ before you can compare it to the string.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Friends\", ]\n\n  id           name uni_id uni_name notability\n1 F2  Monica Geller      F  Friends       79.7\n2 F1   Rachel Green      F  Friends       76.7\n3 F5  Chandler Bing      F  Friends       74.4\n4 F4 Joey Tribbiani      F  Friends       74.3\n5 F3  Phoebe Buffay      F  Friends       72.6\n6 F6    Ross Geller      F  Friends       51.6\n                                                      link\n1 https://openpsychometrics.org/tests/characters/stats/F/2\n2 https://openpsychometrics.org/tests/characters/stats/F/1\n3 https://openpsychometrics.org/tests/characters/stats/F/5\n4 https://openpsychometrics.org/tests/characters/stats/F/4\n5 https://openpsychometrics.org/tests/characters/stats/F/3\n6 https://openpsychometrics.org/tests/characters/stats/F/6\n                                                                  image_link\n1 https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\n2 https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\n3 https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\n4 https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\n5 https://openpsychometrics.org/tests/characters/test-resources/pics/F/3.jpg\n6 https://openpsychometrics.org/tests/characters/test-resources/pics/F/6.jpg\n\n\n\n\n\n\nWhich characters will this code extract: characters[(characters$uni_name == \"Harry Potter\" | characters$uni_name != \"Harry Potter\") & !(characters$notability &gt; 90), ]?\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\nKind of a trick question: because we select all characters that are from the Harry Potter universe OR are not from there, we select all characters independent of their TV show. But we select all characters that have notability under 90 (beware of the ! in front of the respective comparison).\n\n\n\n\n\nWhich character(s) from “Game of Thrones” has a notability rating over 90? Use Base R.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou need to define a logical vector which contains TRUE values for all “Game of Thrones” characters that have a notability over 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Game of Thrones\" & characters$notability &gt; 90, ]\n\n     id             name uni_id        uni_name notability\n18 GOT2 Tyrion Lannister    GOT Game of Thrones       90.8\n                                                         link\n18 https://openpsychometrics.org/tests/characters/stats/GOT/2\n                                                                     image_link\n18 https://openpsychometrics.org/tests/characters/test-resources/pics/GOT/2.jpg\n\n\nThat’s only Tyrion Lannister.\n\n\n\n\nWhich characters from “How I Met Your Mother” or “Breaking Bad” are included in the data? Use the tidyverse.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the filter() function.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\nfilter(characters, uni_name %in% c(\"How I Met Your Mother\", \"Breaking Bad\"))\n\n       id              name uni_id              uni_name notability\n1  HIMYM4    Barney Stinson  HIMYM How I Met Your Mother       76.0\n2  HIMYM3 Robin Scherbatsky  HIMYM How I Met Your Mother       74.2\n3  HIMYM5       Lily Aldrin  HIMYM How I Met Your Mother       74.1\n4  HIMYM2  Marshall Eriksen  HIMYM How I Met Your Mother       71.0\n5  HIMYM1         Ted Mosby  HIMYM How I Met Your Mother       63.7\n6     BB1      Walter White     BB          Breaking Bad       91.3\n7     BB3     Jesse Pinkman     BB          Breaking Bad       88.9\n8     BB9  Mike Ehrmantraut     BB          Breaking Bad       82.5\n9     BB8         Gus Fring     BB          Breaking Bad       79.6\n10    BB4     Hank Schrader     BB          Breaking Bad       74.8\n11    BB7      Saul Goodman     BB          Breaking Bad       73.8\n12   BB10     Jane Margolis     BB          Breaking Bad       61.3\n13    BB2      Skyler White     BB          Breaking Bad       55.4\n14    BB6       Flynn White     BB          Breaking Bad       46.8\n15    BB5    Marie Schrader     BB          Breaking Bad       27.9\n                                                           link\n1  https://openpsychometrics.org/tests/characters/stats/HIMYM/4\n2  https://openpsychometrics.org/tests/characters/stats/HIMYM/3\n3  https://openpsychometrics.org/tests/characters/stats/HIMYM/5\n4  https://openpsychometrics.org/tests/characters/stats/HIMYM/2\n5  https://openpsychometrics.org/tests/characters/stats/HIMYM/1\n6     https://openpsychometrics.org/tests/characters/stats/BB/1\n7     https://openpsychometrics.org/tests/characters/stats/BB/3\n8     https://openpsychometrics.org/tests/characters/stats/BB/9\n9     https://openpsychometrics.org/tests/characters/stats/BB/8\n10    https://openpsychometrics.org/tests/characters/stats/BB/4\n11    https://openpsychometrics.org/tests/characters/stats/BB/7\n12   https://openpsychometrics.org/tests/characters/stats/BB/10\n13    https://openpsychometrics.org/tests/characters/stats/BB/2\n14    https://openpsychometrics.org/tests/characters/stats/BB/6\n15    https://openpsychometrics.org/tests/characters/stats/BB/5\n                                                                       image_link\n1  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/4.jpg\n2  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/3.jpg\n3  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/5.jpg\n4  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/2.jpg\n5  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/1.jpg\n6     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/1.jpg\n7     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/3.jpg\n8     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/9.jpg\n9     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/8.jpg\n10    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/4.jpg\n11    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/7.jpg\n12   https://openpsychometrics.org/tests/characters/test-resources/pics/BB/10.jpg\n13    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/2.jpg\n14    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/6.jpg\n15    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/5.jpg",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html#frage",
    "href": "exercises/intro_r/subsetting_ex.html#frage",
    "title": "Subsetting",
    "section": "",
    "text": "Korrigiere den folgenden Code, sodass nur die ersten 10 Zeilen und die letzten 3 Spalten ausgewählt werden.\n\ncharacters[4:6, 10]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWir müssen die Zeilen, die wir auswählen wollen, vor dem Komma , schreiben, die Spalten danach.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[1:10, 4:6]\n\n   uni_name notability\n1   Friends       79.7\n2   Friends       76.7\n3   Friends       74.4\n4   Friends       74.3\n5   Friends       72.6\n6   Friends       51.6\n7  Euphoria       86.5\n8  Euphoria       84.2\n9  Euphoria       82.6\n10 Euphoria       65.6\n                                                        link\n1   https://openpsychometrics.org/tests/characters/stats/F/2\n2   https://openpsychometrics.org/tests/characters/stats/F/1\n3   https://openpsychometrics.org/tests/characters/stats/F/5\n4   https://openpsychometrics.org/tests/characters/stats/F/4\n5   https://openpsychometrics.org/tests/characters/stats/F/3\n6   https://openpsychometrics.org/tests/characters/stats/F/6\n7  https://openpsychometrics.org/tests/characters/stats/EU/1\n8  https://openpsychometrics.org/tests/characters/stats/EU/2\n9  https://openpsychometrics.org/tests/characters/stats/EU/6\n10 https://openpsychometrics.org/tests/characters/stats/EU/3",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html#frage-1",
    "href": "exercises/intro_r/subsetting_ex.html#frage-1",
    "title": "Subsetting",
    "section": "",
    "text": "Warum funktioniert der folgende Code nicht? Korrigiere ihn in deinem eigenen Skript.\n\n\ncharacters[uni_name == \"Friends\", ]\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nYou need to extract the column from the data frame with $ before you can compare it to the string.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Friends\", ]\n\n  id           name uni_id uni_name notability\n1 F2  Monica Geller      F  Friends       79.7\n2 F1   Rachel Green      F  Friends       76.7\n3 F5  Chandler Bing      F  Friends       74.4\n4 F4 Joey Tribbiani      F  Friends       74.3\n5 F3  Phoebe Buffay      F  Friends       72.6\n6 F6    Ross Geller      F  Friends       51.6\n                                                      link\n1 https://openpsychometrics.org/tests/characters/stats/F/2\n2 https://openpsychometrics.org/tests/characters/stats/F/1\n3 https://openpsychometrics.org/tests/characters/stats/F/5\n4 https://openpsychometrics.org/tests/characters/stats/F/4\n5 https://openpsychometrics.org/tests/characters/stats/F/3\n6 https://openpsychometrics.org/tests/characters/stats/F/6\n                                                                  image_link\n1 https://openpsychometrics.org/tests/characters/test-resources/pics/F/2.jpg\n2 https://openpsychometrics.org/tests/characters/test-resources/pics/F/1.jpg\n3 https://openpsychometrics.org/tests/characters/test-resources/pics/F/5.jpg\n4 https://openpsychometrics.org/tests/characters/test-resources/pics/F/4.jpg\n5 https://openpsychometrics.org/tests/characters/test-resources/pics/F/3.jpg\n6 https://openpsychometrics.org/tests/characters/test-resources/pics/F/6.jpg\n\n\n\n\n\n\nWhich characters will this code extract: characters[(characters$uni_name == \"Harry Potter\" | characters$uni_name != \"Harry Potter\") & !(characters$notability &gt; 90), ]?\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nAll Harry Potter characters with a notability over 90.\nAll characters that are not from the Harry Potter universe and have a notability under 90.\nAll characters with a notability over 90.\nAll characters with a notability under 90.\n\nKind of a trick question: because we select all characters that are from the Harry Potter universe OR are not from there, we select all characters independent of their TV show. But we select all characters that have notability under 90 (beware of the ! in front of the respective comparison).",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/intro_r/subsetting_ex.html#exercise-3",
    "href": "exercises/intro_r/subsetting_ex.html#exercise-3",
    "title": "Subsetting",
    "section": "",
    "text": "Which character(s) from “Game of Thrones” has a notability rating over 90? Use Base R.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nYou need to define a logical vector which contains TRUE values for all “Game of Thrones” characters that have a notability over 90.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncharacters[characters$uni_name == \"Game of Thrones\" & characters$notability &gt; 90, ]\n\n     id             name uni_id        uni_name notability\n18 GOT2 Tyrion Lannister    GOT Game of Thrones       90.8\n                                                         link\n18 https://openpsychometrics.org/tests/characters/stats/GOT/2\n                                                                     image_link\n18 https://openpsychometrics.org/tests/characters/test-resources/pics/GOT/2.jpg\n\n\nThat’s only Tyrion Lannister.\n\n\n\n\nWhich characters from “How I Met Your Mother” or “Breaking Bad” are included in the data? Use the tidyverse.\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse the filter() function.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\nfilter(characters, uni_name %in% c(\"How I Met Your Mother\", \"Breaking Bad\"))\n\n       id              name uni_id              uni_name notability\n1  HIMYM4    Barney Stinson  HIMYM How I Met Your Mother       76.0\n2  HIMYM3 Robin Scherbatsky  HIMYM How I Met Your Mother       74.2\n3  HIMYM5       Lily Aldrin  HIMYM How I Met Your Mother       74.1\n4  HIMYM2  Marshall Eriksen  HIMYM How I Met Your Mother       71.0\n5  HIMYM1         Ted Mosby  HIMYM How I Met Your Mother       63.7\n6     BB1      Walter White     BB          Breaking Bad       91.3\n7     BB3     Jesse Pinkman     BB          Breaking Bad       88.9\n8     BB9  Mike Ehrmantraut     BB          Breaking Bad       82.5\n9     BB8         Gus Fring     BB          Breaking Bad       79.6\n10    BB4     Hank Schrader     BB          Breaking Bad       74.8\n11    BB7      Saul Goodman     BB          Breaking Bad       73.8\n12   BB10     Jane Margolis     BB          Breaking Bad       61.3\n13    BB2      Skyler White     BB          Breaking Bad       55.4\n14    BB6       Flynn White     BB          Breaking Bad       46.8\n15    BB5    Marie Schrader     BB          Breaking Bad       27.9\n                                                           link\n1  https://openpsychometrics.org/tests/characters/stats/HIMYM/4\n2  https://openpsychometrics.org/tests/characters/stats/HIMYM/3\n3  https://openpsychometrics.org/tests/characters/stats/HIMYM/5\n4  https://openpsychometrics.org/tests/characters/stats/HIMYM/2\n5  https://openpsychometrics.org/tests/characters/stats/HIMYM/1\n6     https://openpsychometrics.org/tests/characters/stats/BB/1\n7     https://openpsychometrics.org/tests/characters/stats/BB/3\n8     https://openpsychometrics.org/tests/characters/stats/BB/9\n9     https://openpsychometrics.org/tests/characters/stats/BB/8\n10    https://openpsychometrics.org/tests/characters/stats/BB/4\n11    https://openpsychometrics.org/tests/characters/stats/BB/7\n12   https://openpsychometrics.org/tests/characters/stats/BB/10\n13    https://openpsychometrics.org/tests/characters/stats/BB/2\n14    https://openpsychometrics.org/tests/characters/stats/BB/6\n15    https://openpsychometrics.org/tests/characters/stats/BB/5\n                                                                       image_link\n1  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/4.jpg\n2  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/3.jpg\n3  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/5.jpg\n4  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/2.jpg\n5  https://openpsychometrics.org/tests/characters/test-resources/pics/HIMYM/1.jpg\n6     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/1.jpg\n7     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/3.jpg\n8     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/9.jpg\n9     https://openpsychometrics.org/tests/characters/test-resources/pics/BB/8.jpg\n10    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/4.jpg\n11    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/7.jpg\n12   https://openpsychometrics.org/tests/characters/test-resources/pics/BB/10.jpg\n13    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/2.jpg\n14    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/6.jpg\n15    https://openpsychometrics.org/tests/characters/test-resources/pics/BB/5.jpg",
    "crumbs": [
      "Übungen",
      "Einführung in R",
      "Subsetting"
    ]
  },
  {
    "objectID": "exercises/index_intro_r.html",
    "href": "exercises/index_intro_r.html",
    "title": "Einführung in R",
    "section": "",
    "text": "Sortieren nach\n       Voreinstellung\n         \n          Titel\n        \n         \n          Autor:in\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nTitel\n\n\nAutor:in\n\n\n\n\n\n\nEinlesen von Daten\n\n\nNicklas Hafiz\n\n\n\n\nMerging\n\n\nNicklas Hafiz\n\n\n\n\nMissings\n\n\nNicklas Hafiz\n\n\n\n\nReshaping\n\n\nNicklas Hafiz\n\n\n\n\nSubsetting\n\n\nNicklas Hafiz\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen",
      "Einführung in R"
    ]
  },
  {
    "objectID": "exercises/linking/linking.html",
    "href": "exercises/linking/linking.html",
    "title": "2. Linking",
    "section": "",
    "text": "Wenn du die Übung zur Datenaufbereitung nicht gemacht hast, kannst du die aufbereiteten Daten hier herunterladen und dann damit arbeiten. Nimm ansonsten einfach deine selbst aufbereiteten Daten.\n\nqa_dat_wide &lt;- readRDS(here::here(\"raw_data\", \"qa_dat_wide.rds\"))",
    "crumbs": [
      "Übungen",
      "Linking",
      "2. Linking"
    ]
  },
  {
    "objectID": "exercises/linking/linking.html#gruppen-kalibrieren",
    "href": "exercises/linking/linking.html#gruppen-kalibrieren",
    "title": "2. Linking",
    "section": "\n1.1 Gruppen kalibrieren",
    "text": "1.1 Gruppen kalibrieren\nZuerst kalibrieren wir die beiden Gruppen, die wir später auf DIF untersuchen wollen, einzeln. Dadurch können wir dann später die Itemparamter vergleichen. Bilde also zwei Subgruppen, eine für Männer und eine für Frauen.\n\n1.1.1 Subgruppen herstellen\nErstelle dafür 2 Dataframes (qa_f und qa_m), einen nur mit Frauen (1) und einen nur mit Männern (2). Weitere Kategorien gibt es in diesem Datensatz nicht:\n\ntable(qa_dat_wide$gender)\n\n\n  1   2 \n222 303 \n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nqa_f &lt;- qa_dat_wide %&gt;%\n  filter(gender == 1)\n\nqa_m &lt;- qa_dat_wide %&gt;%\n  filter(gender == 2)\n\n\n\n\n\n1.1.2 Kalibrieren\nFitte jetzt für beide Gruppen seperat ein Raschmodell mit TAM.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nDenk daran nur die Spalten, die auch Itemantworten enthalten, in die TAM-Funktion zu geben.\n\n\n\n::: ## Lösung\n\nlibrary(TAM)\n\nLoading required package: CDM\n\n\nLoading required package: mvtnorm\n\n\n**********************************\n** CDM 8.2-6 (2022-08-25 15:43:23)       \n** Cognitive Diagnostic Models  **\n**********************************\n\n\n* TAM 4.2-21 (2024-02-19 18:52:08)\n\n## Rasch Modell fitten, die ersten 5 Spalten enthalten keine Itemantworten und werden entfernt\ntam_f &lt;- tam(qa_f[, 6:ncol(qa_f)], verbose = FALSE)\ntam_m &lt;- tam(qa_m[, 6:ncol(qa_m)], verbose = FALSE)\n\nDie kalibrierten Itemparamter können wir uns so anschauen:\n\ntam_f_difficulty &lt;- tam_f$xsi\ntam_m_difficulty &lt;- tam_m$xsi\n\n:::\n\n1.1.3 Linken\nWir verzichten für diese Übung darauf, den Modellfit zu beurteilen und linken direkt. Nutze dafür die Funktion tam.linking() und Linke mit Stocking-Lord Linking.\n\n\n\n\n\n\nTipp\n\n\n\n\n\nRufe die Hilfeseite der Funktion auf, um zu erkennen, welche Argumente für das geforderte Linking-Verfahren eingestellt werden müssen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ntam_link &lt;- tam.linking(list(tam_f, tam_m), type=\"SL\")\n\nN = 2, M = 5 machine precision = 2.22045e-16\nThis problem is unconstrained.\n\niterations 7\nfunction evaluations 9\nsegments explored during Cauchy searches 1\nBFGS updates skipped 0\nactive bounds at final generalized Cauchy point 0\nnorm of the final projected gradient 4.27656e-07\nfinal function value 0.00180261\n\nfinal  value 0.001803 \nconverged\n\n\n\n\n\n\n1.1.4 Evaluation\nDie Parameter können wir so extrahieren:\n\ndifficulty_link_f &lt;- tam_link$parameters_list[[1]]$xsi\ndifficulty_link_m &lt;- tam_link$parameters_list[[2]]$xsi\n\nVergleiche sie mit den kalibrierten Schwierigkeiten:\n\ntam_f_difficulty &lt;- tam_f$xsi\ntam_m_difficulty &lt;- tam_m$xsi\n\nWas fällt auf?\n\n\n\n\n\n\nLösung\n\n\n\n\n\nZuerst fällt auf, dass sich natürlich nur die Schwierigkeiten für die zweite Gruppe geändert haben. Für Item 1 ist die Schwierigkeit für die Männer relativ stark gestiegen, es ist für die Männer aber nach wie vor deutlich einfacher als für die Frauen. Schon einmal ein guter Kandidat für die DIF Analyse.\n\n\n\nGut, jetzt haben wir ein erstes Linking durchgeführt. Bei der DIF Analyse im nächsten Kapitel machen wir das gleiche nochmal, aber mit anderen Paketen und etwas komprimierter, können die Ergebnisse dann aber auch etwas vergleichen.",
    "crumbs": [
      "Übungen",
      "Linking",
      "2. Linking"
    ]
  },
  {
    "objectID": "exercises/index.html",
    "href": "exercises/index.html",
    "title": "Übungen",
    "section": "",
    "text": "Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEinführung in R\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinking\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHöher parametrisierte Modelle\n\n\nÜbungen\n\n\n\n\n\n\n\n\n\n\n\n\nKeine Treffer",
    "crumbs": [
      "Übungen"
    ]
  },
  {
    "objectID": "exercises/xPl/simulation.html",
    "href": "exercises/xPl/simulation.html",
    "title": "Simulation von IRT Daten",
    "section": "",
    "text": "Wir schauen uns eine ganz simple Version an. Wer interessiert ist, und z.B. Daten für eine Poweranalyse simulieren möchte, findet hier Unterstützung. Installieren und/oder lade folgende Pakete für diese Übung:\n\n## Wenn noch nicht installiert:\n# install.packages(\"tidyverse\")\n# install.packages(\"TAM\")\n\nlibrary(tidyverse)\nlibrary(TAM)\n\n\nZuerst müssen wir festlegen, was wir eigentlich simulieren wollen. Wir starten mit einem 2PL Modell. Wie sah die Gleichung dafür noch einmal aus?\n\\[\nP(X_{is} = 1|\\theta_s,\\beta_i,\\alpha_i) = \\frac{\\exp(\\alpha_i(\\theta_s-\\beta_i))}{1 + \\exp(a_i (\\theta_s - \\beta_i))}\n\\tag{1}\\]\n\nVersuche noch einmal, alle Elemente von Gleichung 1 für dich selbst zu erklären.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir versuchen zu schätzen wie hoch die Wahrscheinlichkeit ist, dass eine Person \\(s\\) ein Item \\(i\\) richtig (\\(X_{is} = 1\\)) beantwortet. Dazu nutzen wir den Diskriminationsparameter \\(\\alpha_i\\) und den Schwierigkeitsparameter \\(\\beta_i\\) von Item \\(i\\) und die Personenfähigkeit \\(\\theta_s\\) von Person \\(s\\).\n\n\n\n\n\nJetzt beginnt der fun part: Schreibe eine Funktion genannt calc_2pl die Gleichung 1 in R Code umsetzt.\n\n\n\n\n\n\n\nDer Aufbau der Funktion könnte so aussehen:\n\ncalc_2pl &lt;- function(alpha, theta, beta){\n}\n\nBefülle sie nun mit Gleichung 1. alpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Diese Werte können dann im Funktionskörper (zwischen {}) genutzt werden, um Gleichung 1 in R Code zu übersetzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nalpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Im Funktionskörper (zwischen {}) werden sie genutzt, um \\(p\\) anhand von Gleichung 1 zu berechnen.\n\n\n\n\nJetzt geht’s los! Wir wollen nun eigene Daten simulieren. Das tolle ist: wir können so alle Aspekte selber festlegen, und daran untersuchen, wie sich das Variieren von bestimmten Parametern auf das Ergebnis auswirkt.\n\n\nZuerst die Items. Baue einen data.frame mit dem Namen items. Er soll 13 Zeilen und 4 Spalten haben und folgendes enthalten:\n\n\n\nitem_id: Die ID des Items, von 1 bis 13.\n\nalpha: Die Diskriminationsparameter, liegen zwischen 0.1 und 2.5 in 13 gleich langen Schritten.\n\nbeta: Die Schwierigkeitsparameter, liegen zwischen -3 und 3 jeweils im Abstand von 0.5.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDie Funktion seq() ist dein Freund. Mehr brauchst du nicht, um die Zahlenreihen zu erzeugen. Schaue dir die Dokumentation an.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.1, 2.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nDas sind also die Itemparameter, die wir in unsere Simulation packen.\n\n\n\n\nJetzt können wir die Personen simulieren. Unser Ziel ist also ein data.frame, der \\(\\theta\\) Werte für die untersuchten Personen enthält. Wir simulieren 100000 Personen, der data.frame sollte also 100000 Zeilen haben. Außerdem benötigen wir zwei Spalten:\n\n\n\nID: Die ID der Person, von 1 bis 100000.\n\ntheta: Die Fähigkeit der Person, die wir simulieren. Wir nehmen an, dass die Fähigkeit normalverteilt ist, mit einem Mittelwert von 0 und einer Standardabweichung von 1.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWir können zufällige Daten aus einer Normalverteilung mit Hilfe der Funktion rnorm() ziehen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(666) \n## Ich setzte hier einen Seed, damit meine zufällig erzeugten Werte replizierbar bleiben.\n## Wenn du den Seed in deinem Skript auf die gleiche Zahl setzt, bekommst du genau die gleichen Zufallswerte und kannst besser vergleichen. \n\n\nsubjects &lt;- data.frame(\n    sub_id = 1:100000,\n    theta = c(rnorm(100000, 0, 1))\n)\n\n\n\n\nPerfekt! Jetzt können wir die Itemantworten simulieren. Dazu sind noch ein paar kleine Schritte nötig:\n\nMerge die beiden data.frames subjects und items zu einem neuen data.frame sim_dat zusammen. Und zwar so, dass wir \\(1000 * 13\\) Zeilen bekommen, also jede Person jedes der 13 Items zugeordnet wird (bisher noch ohne Antwort der Person, nur mit den Itemkennwerten. Das erleichtert uns im nächsten Schritt, die Antworten der Personen zu simulieren).\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNutze die Funktion merge() ohne irgendwelche weiteren Argumente.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- merge(subjects, items)\n\n## Wir schauen mal, ob das hinkommt:\n\nstr(sim_dat)\n\n'data.frame':   1300000 obs. of  6 variables:\n $ sub_id : int  1 2 3 4 5 6 7 8 9 10 ...\n $ theta  : num  0.753 2.014 -0.355 2.028 -2.217 ...\n $ item_id: int  1 1 1 1 1 1 1 1 1 1 ...\n $ b      : num  -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 ...\n $ a      : num  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 ...\n $ c      : num  0 0 0 0 0 0 0 0 0 0 ...\n\n\nUnser finaler data.frame hat 1300000 Zeilen, wie verlangt. Lasst uns auch noch einmal schauen, ob eine zufällige Person alle Items beantwortet hat:\n\nsim_dat %&gt;%\n  filter(sub_id == 420) %&gt;%\n  pull(item_id)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n\nDas sieht gut aus!\n\n\n\n\nJetzt simulieren wir aus diesem Vorbereiteten data.frame die Antworten der Personen, abhängig von ihren Fähigkeiten \\(\\theta\\) (jede Person hat hier einen zufälligen Wert aus einer Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 1\\) bekommen) und den Itemparametern \\(\\alpha\\) und \\(\\beta\\) (die hatten wir einfach als Sequenz festgelegt). Lege eine neue Spalte p in sim_dat an, die für jede Person die Wahrscheinlichkeit enthält, dass sie das jeweilige Item richtig beantwortet. Dafür brauchen wir jetzt unsere Funktion calc_2pl, die wir am Anfang definiert haben! Diese nimmt aus jeder Zeile den theta, alpha und beta Wert als input, und berechnet daraus die Wahrscheinlichkeit, dass die Person das Item richtig beantwortet.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSupereinfach geht das ganze mit der mutate() Funktion aus dem tidyverse.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(p = calc_2pl(a, theta, b))\n\n## Mal nachschauen:\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p\n1      1  0.7533110       1 -3 0.1 0 0.5927465\n2      2  2.0143547       1 -3 0.1 0 0.6227966\n3      3 -0.3551345       1 -3 0.1 0 0.5657389\n4      4  2.0281678       1 -3 0.1 0 0.6231211\n5      5 -2.2168745       1 -3 0.1 0 0.5195681\n6      6  0.7583962       1 -3 0.1 0 0.5928693\n\n\nAuf den ersten Blick sieht das schonmal gut aus. Personen mit niedrigerem \\(\\theta\\) Wert haben auch eine geringere Wahrscheinlichkeit, das Item richtig zu beantworten (vgl. z.B. Zeile 2 und 3).\n\n\n\n\nJetzt sind wir auch schon fast am Ende. Wir müssen lediglich aus den Wahrscheinlichkeiten die tatsächlichen Antworten der Personen simulieren. Nutze die Berechneten Antwortwahrscheinlichkeiten p, um für jede Person und jedes Item einen Wert aus einer Bernoulliverteilung zu ziehen.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEine Bernoulliverteilung ist eine Binomialverteilung mit nur einem Versuch. Wir können daher die Funktion rbinom() nutzen, und das size-Argument auf 1 setzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p answer\n1      1  0.7533110       1 -3 0.1 0 0.5927465      1\n2      2  2.0143547       1 -3 0.1 0 0.6227966      1\n3      3 -0.3551345       1 -3 0.1 0 0.5657389      0\n4      4  2.0281678       1 -3 0.1 0 0.6231211      1\n5      5 -2.2168745       1 -3 0.1 0 0.5195681      1\n6      6  0.7583962       1 -3 0.1 0 0.5928693      1\n\n\nAuch das sieht erst einmal plausibel aus! Toll!\n\n\n\n\nJetzt wollen wir natürlich noch schauen, ob das Ganze so funktioniert hat, wie wir uns das vorgestellt haben. Wir wollen das TAM Paket, um ein 2PL Modell auf die Itemantworten zu fitten. Wenn alles geklappt hat, sollten wir in etwa unsere Itemparameter wiedererkennen.\n\nZuerst müssen wir unsere Daten dafür noch ein bisschen aufbereiten, sprich ins Wide-Format bringen. Probiere das also mal aus!\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIch nutze dafür immer deutlich lieber die tidyverse Funktion pivot_wider() als die base-R Funtkion reshape().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = sub_id)\n\nhead(sim_dat_wide)\n\n# A tibble: 6 × 14\n  sub_id   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`  `10`  `11`  `12`\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1      1     1     1     1     1     1     1     1     0     1     1     0     0\n2      2     1     1     1     1     1     1     1     1     1     1     1     0\n3      3     0     1     1     1     0     1     0     0     0     0     0     0\n4      4     1     1     1     1     1     1     1     1     0     0     0     0\n5      5     1     1     0     1     0     0     0     0     0     0     0     0\n6      6     1     1     0     1     1     1     0     0     0     0     0     0\n# ℹ 1 more variable: `13` &lt;int&gt;\n\n\n\nsaveRDS(sim_dat_wide, here::here(\"raw_data\", \"sim_2pl.rds\"))\n\nDie Spaltennamen sind jetzt unsere Item-Nummern. Pro Zeile finden sich die Antworten der Personen, entweder hat sie das entsprechende Item richtig (1) oder falsch (0) beantwortet.\n\n\n\n\nJetzt können wir das Modell fitten. Nutze dafür wie angekündigt das TAM Paket, und entferne noch die Spalte sub_id, wir geben nur die Itemantworten in die Funktion. Speichere den Funktionsoutput in dem Object sim_dat_2PL.\n\n\n\n\n\n\n\nWir brauchen die Funktion tam.mml.2pl().\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsim_dat_2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"2PL\", verbose = FALSE)\n\n\n\n\n\nSchau dir die Itemparameter an, die das Modell geschätzt hat. Sie finden sich unter sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")]. Vergleiche mit den ursprünglichen Itemparametern, die wir in items festgelegt haben. Was fällt dir auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems_2pl &lt;- apply(sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\nitem_comparison &lt;- cbind(items_2pl, items[, c(\"a\", \"b\")])\n\nitem_comparison\n\n   alpha  beta   a    b\n1   0.11 -2.78 0.1 -3.0\n2   0.31 -2.48 0.3 -2.5\n3   0.50 -2.01 0.5 -2.0\n4   0.70 -1.51 0.7 -1.5\n5   0.90 -1.01 0.9 -1.0\n6   1.10 -0.50 1.1 -0.5\n7   1.29 -0.01 1.3  0.0\n8   1.50  0.49 1.5  0.5\n9   1.72  0.99 1.7  1.0\n10  1.88  1.51 1.9  1.5\n11  2.08  2.00 2.1  2.0\n12  2.32  2.49 2.3  2.5\n13  2.53  2.98 2.5  3.0\n\n\n\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nggplot(data=item_comparison, \n       aes(x = b, y = beta)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() + ## Ein anderes Theme festlegen\n  xlab(TeX(\"\\\\beta\")) + ## Latex Syntax für die Achsenbeschriftung nutzen\n  ylab(TeX(\"\\\\hat{\\\\beta}\"))\n\n\n\n\n\n\n\n\nggplot(data=item_comparison, \n       aes(x = a, y = alpha)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() +\n  xlab(TeX(\"\\\\alpha\")) +\n  ylab(TeX(\"\\\\hat{\\\\alpha}\"))\n\n\n\n\n\n\n\nDas sieht super aus, die Werte stimmen gut überein. Dadurch, dass wir so viele Personen simuliert haben, sehen wir also, dass unsere Simulation gut funktioniert. Wir können das Gerüst dieses Simplen Modells jetzt nutzen, um uns noch spannendere Fragestellungen anzuschauen. Zum Beispiel könnten wir untersuchen, ab welcher Stichprobengröße unser Modell genau genug schätzt, oder wir könnten verschiedene Modelle miteinander vergleichen (Rasch vs. 2PL z.B.). Beides kann uns bei der Studienplanung helfen.\n\n\n\n\nÜbringes: es gibt natürlich auch schon R Pakete, die die Simulationsarbeit für uns übernehmen. Aus didaktischen Gründen haben wir das bisher selber gemacht, aber können uns jetzt ein bisschen Arbeit ersparen, und das ganze von dem Paket catIrt übernehmen lassen. Hier nochmal die gleiche Simulation, aber mit\n\nlibrary(catIrt)\n\ngroup_1 &lt;- simIrt(theta = rnorm(100000, 0, 1), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\ngroup_2 &lt;- simIrt(theta = rnorm(100000, 0, 1.5), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\n\n## Kalibrieren der beiden Gruppen getrennt\ngroup_1_2PL &lt;- tam.mml.2pl(group_1$resp, irtmodel = \"2PL\")\ngroup_2_2PL &lt;- tam.mml.2pl(group_2$resp, irtmodel = \"2PL\")\n\n## Extrahieren der Itemparameter\nitempars_1 &lt;- as.data.frame(apply(group_1_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\nitempars_2 &lt;- as.data.frame(apply(group_2_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(itempars_2) &lt;- c(\"alpha_2\", \"beta_2\")"
  },
  {
    "objectID": "exercises/xPl/simulation.html#gleichung",
    "href": "exercises/xPl/simulation.html#gleichung",
    "title": "Simulation von IRT Daten",
    "section": "",
    "text": "Zuerst müssen wir festlegen, was wir eigentlich simulieren wollen. Wir starten mit einem 2PL Modell. Wie sah die Gleichung dafür noch einmal aus?\n\\[\nP(X_{is} = 1|\\theta_s,\\beta_i,\\alpha_i) = \\frac{\\exp(\\alpha_i(\\theta_s-\\beta_i))}{1 + \\exp(a_i (\\theta_s - \\beta_i))}\n\\tag{1}\\]\n\nVersuche noch einmal, alle Elemente von Gleichung 1 für dich selbst zu erklären.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir versuchen zu schätzen wie hoch die Wahrscheinlichkeit ist, dass eine Person \\(s\\) ein Item \\(i\\) richtig (\\(X_{is} = 1\\)) beantwortet. Dazu nutzen wir den Diskriminationsparameter \\(\\alpha_i\\) und den Schwierigkeitsparameter \\(\\beta_i\\) von Item \\(i\\) und die Personenfähigkeit \\(\\theta_s\\) von Person \\(s\\)."
  },
  {
    "objectID": "exercises/xPl/simulation.html#pl-funktion",
    "href": "exercises/xPl/simulation.html#pl-funktion",
    "title": "Simulation von IRT Daten",
    "section": "",
    "text": "Jetzt beginnt der fun part: Schreibe eine Funktion genannt calc_2pl die Gleichung 1 in R Code umsetzt.\n\n\n\n\n\n\n\nDer Aufbau der Funktion könnte so aussehen:\n\ncalc_2pl &lt;- function(alpha, theta, beta){\n}\n\nBefülle sie nun mit Gleichung 1. alpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Diese Werte können dann im Funktionskörper (zwischen {}) genutzt werden, um Gleichung 1 in R Code zu übersetzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nalpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Im Funktionskörper (zwischen {}) werden sie genutzt, um \\(p\\) anhand von Gleichung 1 zu berechnen."
  },
  {
    "objectID": "exercises/xPl/simulation.html#simulieren-von-daten",
    "href": "exercises/xPl/simulation.html#simulieren-von-daten",
    "title": "Simulation von IRT Daten",
    "section": "",
    "text": "Jetzt geht’s los! Wir wollen nun eigene Daten simulieren. Das tolle ist: wir können so alle Aspekte selber festlegen, und daran untersuchen, wie sich das Variieren von bestimmten Parametern auf das Ergebnis auswirkt.\n\n\nZuerst die Items. Baue einen data.frame mit dem Namen items. Er soll 13 Zeilen und 4 Spalten haben und folgendes enthalten:\n\n\n\nitem_id: Die ID des Items, von 1 bis 13.\n\nalpha: Die Diskriminationsparameter, liegen zwischen 0.1 und 2.5 in 13 gleich langen Schritten.\n\nbeta: Die Schwierigkeitsparameter, liegen zwischen -3 und 3 jeweils im Abstand von 0.5.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDie Funktion seq() ist dein Freund. Mehr brauchst du nicht, um die Zahlenreihen zu erzeugen. Schaue dir die Dokumentation an.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.1, 2.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nDas sind also die Itemparameter, die wir in unsere Simulation packen.\n\n\n\n\nJetzt können wir die Personen simulieren. Unser Ziel ist also ein data.frame, der \\(\\theta\\) Werte für die untersuchten Personen enthält. Wir simulieren 100000 Personen, der data.frame sollte also 100000 Zeilen haben. Außerdem benötigen wir zwei Spalten:\n\n\n\nID: Die ID der Person, von 1 bis 100000.\n\ntheta: Die Fähigkeit der Person, die wir simulieren. Wir nehmen an, dass die Fähigkeit normalverteilt ist, mit einem Mittelwert von 0 und einer Standardabweichung von 1.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWir können zufällige Daten aus einer Normalverteilung mit Hilfe der Funktion rnorm() ziehen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(666) \n## Ich setzte hier einen Seed, damit meine zufällig erzeugten Werte replizierbar bleiben.\n## Wenn du den Seed in deinem Skript auf die gleiche Zahl setzt, bekommst du genau die gleichen Zufallswerte und kannst besser vergleichen. \n\n\nsubjects &lt;- data.frame(\n    sub_id = 1:100000,\n    theta = c(rnorm(100000, 0, 1))\n)\n\n\n\n\nPerfekt! Jetzt können wir die Itemantworten simulieren. Dazu sind noch ein paar kleine Schritte nötig:\n\nMerge die beiden data.frames subjects und items zu einem neuen data.frame sim_dat zusammen. Und zwar so, dass wir \\(1000 * 13\\) Zeilen bekommen, also jede Person jedes der 13 Items zugeordnet wird (bisher noch ohne Antwort der Person, nur mit den Itemkennwerten. Das erleichtert uns im nächsten Schritt, die Antworten der Personen zu simulieren).\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNutze die Funktion merge() ohne irgendwelche weiteren Argumente.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- merge(subjects, items)\n\n## Wir schauen mal, ob das hinkommt:\n\nstr(sim_dat)\n\n'data.frame':   1300000 obs. of  6 variables:\n $ sub_id : int  1 2 3 4 5 6 7 8 9 10 ...\n $ theta  : num  0.753 2.014 -0.355 2.028 -2.217 ...\n $ item_id: int  1 1 1 1 1 1 1 1 1 1 ...\n $ b      : num  -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 ...\n $ a      : num  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 ...\n $ c      : num  0 0 0 0 0 0 0 0 0 0 ...\n\n\nUnser finaler data.frame hat 1300000 Zeilen, wie verlangt. Lasst uns auch noch einmal schauen, ob eine zufällige Person alle Items beantwortet hat:\n\nsim_dat %&gt;%\n  filter(sub_id == 420) %&gt;%\n  pull(item_id)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n\nDas sieht gut aus!\n\n\n\n\nJetzt simulieren wir aus diesem Vorbereiteten data.frame die Antworten der Personen, abhängig von ihren Fähigkeiten \\(\\theta\\) (jede Person hat hier einen zufälligen Wert aus einer Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 1\\) bekommen) und den Itemparametern \\(\\alpha\\) und \\(\\beta\\) (die hatten wir einfach als Sequenz festgelegt). Lege eine neue Spalte p in sim_dat an, die für jede Person die Wahrscheinlichkeit enthält, dass sie das jeweilige Item richtig beantwortet. Dafür brauchen wir jetzt unsere Funktion calc_2pl, die wir am Anfang definiert haben! Diese nimmt aus jeder Zeile den theta, alpha und beta Wert als input, und berechnet daraus die Wahrscheinlichkeit, dass die Person das Item richtig beantwortet.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSupereinfach geht das ganze mit der mutate() Funktion aus dem tidyverse.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(p = calc_2pl(a, theta, b))\n\n## Mal nachschauen:\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p\n1      1  0.7533110       1 -3 0.1 0 0.5927465\n2      2  2.0143547       1 -3 0.1 0 0.6227966\n3      3 -0.3551345       1 -3 0.1 0 0.5657389\n4      4  2.0281678       1 -3 0.1 0 0.6231211\n5      5 -2.2168745       1 -3 0.1 0 0.5195681\n6      6  0.7583962       1 -3 0.1 0 0.5928693\n\n\nAuf den ersten Blick sieht das schonmal gut aus. Personen mit niedrigerem \\(\\theta\\) Wert haben auch eine geringere Wahrscheinlichkeit, das Item richtig zu beantworten (vgl. z.B. Zeile 2 und 3).\n\n\n\n\nJetzt sind wir auch schon fast am Ende. Wir müssen lediglich aus den Wahrscheinlichkeiten die tatsächlichen Antworten der Personen simulieren. Nutze die Berechneten Antwortwahrscheinlichkeiten p, um für jede Person und jedes Item einen Wert aus einer Bernoulliverteilung zu ziehen.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEine Bernoulliverteilung ist eine Binomialverteilung mit nur einem Versuch. Wir können daher die Funktion rbinom() nutzen, und das size-Argument auf 1 setzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p answer\n1      1  0.7533110       1 -3 0.1 0 0.5927465      1\n2      2  2.0143547       1 -3 0.1 0 0.6227966      1\n3      3 -0.3551345       1 -3 0.1 0 0.5657389      0\n4      4  2.0281678       1 -3 0.1 0 0.6231211      1\n5      5 -2.2168745       1 -3 0.1 0 0.5195681      1\n6      6  0.7583962       1 -3 0.1 0 0.5928693      1\n\n\nAuch das sieht erst einmal plausibel aus! Toll!\n\n\n\n\nJetzt wollen wir natürlich noch schauen, ob das Ganze so funktioniert hat, wie wir uns das vorgestellt haben. Wir wollen das TAM Paket, um ein 2PL Modell auf die Itemantworten zu fitten. Wenn alles geklappt hat, sollten wir in etwa unsere Itemparameter wiedererkennen.\n\nZuerst müssen wir unsere Daten dafür noch ein bisschen aufbereiten, sprich ins Wide-Format bringen. Probiere das also mal aus!\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIch nutze dafür immer deutlich lieber die tidyverse Funktion pivot_wider() als die base-R Funtkion reshape().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = sub_id)\n\nhead(sim_dat_wide)\n\n# A tibble: 6 × 14\n  sub_id   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`  `10`  `11`  `12`\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1      1     1     1     1     1     1     1     1     0     1     1     0     0\n2      2     1     1     1     1     1     1     1     1     1     1     1     0\n3      3     0     1     1     1     0     1     0     0     0     0     0     0\n4      4     1     1     1     1     1     1     1     1     0     0     0     0\n5      5     1     1     0     1     0     0     0     0     0     0     0     0\n6      6     1     1     0     1     1     1     0     0     0     0     0     0\n# ℹ 1 more variable: `13` &lt;int&gt;\n\n\n\nsaveRDS(sim_dat_wide, here::here(\"raw_data\", \"sim_2pl.rds\"))\n\nDie Spaltennamen sind jetzt unsere Item-Nummern. Pro Zeile finden sich die Antworten der Personen, entweder hat sie das entsprechende Item richtig (1) oder falsch (0) beantwortet.\n\n\n\n\nJetzt können wir das Modell fitten. Nutze dafür wie angekündigt das TAM Paket, und entferne noch die Spalte sub_id, wir geben nur die Itemantworten in die Funktion. Speichere den Funktionsoutput in dem Object sim_dat_2PL.\n\n\n\n\n\n\n\nWir brauchen die Funktion tam.mml.2pl().\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsim_dat_2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"2PL\", verbose = FALSE)\n\n\n\n\n\nSchau dir die Itemparameter an, die das Modell geschätzt hat. Sie finden sich unter sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")]. Vergleiche mit den ursprünglichen Itemparametern, die wir in items festgelegt haben. Was fällt dir auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems_2pl &lt;- apply(sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\nitem_comparison &lt;- cbind(items_2pl, items[, c(\"a\", \"b\")])\n\nitem_comparison\n\n   alpha  beta   a    b\n1   0.11 -2.78 0.1 -3.0\n2   0.31 -2.48 0.3 -2.5\n3   0.50 -2.01 0.5 -2.0\n4   0.70 -1.51 0.7 -1.5\n5   0.90 -1.01 0.9 -1.0\n6   1.10 -0.50 1.1 -0.5\n7   1.29 -0.01 1.3  0.0\n8   1.50  0.49 1.5  0.5\n9   1.72  0.99 1.7  1.0\n10  1.88  1.51 1.9  1.5\n11  2.08  2.00 2.1  2.0\n12  2.32  2.49 2.3  2.5\n13  2.53  2.98 2.5  3.0\n\n\n\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nggplot(data=item_comparison, \n       aes(x = b, y = beta)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() + ## Ein anderes Theme festlegen\n  xlab(TeX(\"\\\\beta\")) + ## Latex Syntax für die Achsenbeschriftung nutzen\n  ylab(TeX(\"\\\\hat{\\\\beta}\"))\n\n\n\n\n\n\n\n\nggplot(data=item_comparison, \n       aes(x = a, y = alpha)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() +\n  xlab(TeX(\"\\\\alpha\")) +\n  ylab(TeX(\"\\\\hat{\\\\alpha}\"))\n\n\n\n\n\n\n\nDas sieht super aus, die Werte stimmen gut überein. Dadurch, dass wir so viele Personen simuliert haben, sehen wir also, dass unsere Simulation gut funktioniert. Wir können das Gerüst dieses Simplen Modells jetzt nutzen, um uns noch spannendere Fragestellungen anzuschauen. Zum Beispiel könnten wir untersuchen, ab welcher Stichprobengröße unser Modell genau genug schätzt, oder wir könnten verschiedene Modelle miteinander vergleichen (Rasch vs. 2PL z.B.). Beides kann uns bei der Studienplanung helfen."
  },
  {
    "objectID": "exercises/xPl/simulation.html#simirt",
    "href": "exercises/xPl/simulation.html#simirt",
    "title": "Simulation von IRT Daten",
    "section": "",
    "text": "Übringes: es gibt natürlich auch schon R Pakete, die die Simulationsarbeit für uns übernehmen. Aus didaktischen Gründen haben wir das bisher selber gemacht, aber können uns jetzt ein bisschen Arbeit ersparen, und das ganze von dem Paket catIrt übernehmen lassen. Hier nochmal die gleiche Simulation, aber mit\n\nlibrary(catIrt)\n\ngroup_1 &lt;- simIrt(theta = rnorm(100000, 0, 1), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\ngroup_2 &lt;- simIrt(theta = rnorm(100000, 0, 1.5), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\n\n## Kalibrieren der beiden Gruppen getrennt\ngroup_1_2PL &lt;- tam.mml.2pl(group_1$resp, irtmodel = \"2PL\")\ngroup_2_2PL &lt;- tam.mml.2pl(group_2$resp, irtmodel = \"2PL\")\n\n## Extrahieren der Itemparameter\nitempars_1 &lt;- as.data.frame(apply(group_1_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\nitempars_2 &lt;- as.data.frame(apply(group_2_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(itempars_2) &lt;- c(\"alpha_2\", \"beta_2\")"
  },
  {
    "objectID": "exercises/xPl/model_selection.html",
    "href": "exercises/xPl/model_selection.html",
    "title": "Modellselektion",
    "section": "",
    "text": "Das 2PL Modell haben wir schon gefittet (und wir wissen ja, dass das richtig ist, weil wir die Daten selbst generiert haben). Wie aber verhalten sich das 1PL Modell und das 3PL Modell?"
  },
  {
    "objectID": "exercises/xPl/model_selection.html#pl",
    "href": "exercises/xPl/model_selection.html#pl",
    "title": "Modellselektion",
    "section": "\n1.1 2PL",
    "text": "1.1 2PL\n\n1.1.1 Erwartet vs. beobachtet\nAls Baseline schauen wir uns ein paar Fit-Eigenschaften von unserem 2PL Modell an, das wir so gefittet hatten:\n\nlibrary(TAM)\nlibrary(tidyverse)\n\nsim_dat_wide &lt;- readRDS(here::here(\"raw_data\", \"sim_2pl.rds\"))\n\nsim_dat_2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"2PL\", verbose = FALSE)\n\nZuerst interessiert uns wie gut unsere tatsächlichen Werte mit den Modellerwarungen übereinstimmen. Nutze folgende Funktion um die Itemplots zu erstellen (kommt aus TAM):\n\nplot(sim_dat_2PL,\n  type = \"items\",\n  export = FALSE,\n  observed = TRUE,\n  package = \"graphics\"\n)\n\nFällt dir etwas auf?\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot(sim_dat_2PL,\n  type = \"items\",\n  export = FALSE,\n  observed = TRUE,\n  package = \"graphics\"\n)\n\nIteration in WLE/MLE estimation  1   | Maximal change  2.2568 \nIteration in WLE/MLE estimation  2   | Maximal change  0.6867 \nIteration in WLE/MLE estimation  3   | Maximal change  0.3037 \nIteration in WLE/MLE estimation  4   | Maximal change  0.1007 \nIteration in WLE/MLE estimation  5   | Maximal change  0.0286 \nIteration in WLE/MLE estimation  6   | Maximal change  0.0077 \nIteration in WLE/MLE estimation  7   | Maximal change  0.002 \nIteration in WLE/MLE estimation  8   | Maximal change  5e-04 \nIteration in WLE/MLE estimation  9   | Maximal change  1e-04 \nIteration in WLE/MLE estimation  10   | Maximal change  0 \n----\n WLE Reliability= 0.593 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.2 Itemfit\nAls nächstes schauen wir uns die Infit und Outfit - Werte der Items an. Wende dafür die Funktion tam.fit() auf dein gefittetes TAM-Modell an.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nfit_2PL &lt;- tam.fit(sim_dat_2PL)\n\nItem fit calculation based on 5 simulations\n|**********|\n|----------|\n\nfit_2PL$itemfit\n\n   parameter    Outfit    Outfit_t    Outfit_p Outfit_pholm     Infit\n1          1 0.9999729 -0.02669323 0.978704415    1.0000000 0.9999696\n2          2 0.9998803 -0.04714882 0.962394621    1.0000000 1.0000102\n3          3 0.9995378 -0.14294764 0.886331536    1.0000000 1.0002062\n4          4 0.9998664 -0.03848309 0.969302515    1.0000000 0.9998973\n5          5 0.9993633 -0.20179421 0.840077610    1.0000000 1.0005081\n6          6 0.9991957 -0.27434564 0.783819015    1.0000000 0.9999665\n7          7 0.9972820 -0.90456484 0.365695967    1.0000000 0.9984569\n8          8 1.0012163  0.34250913 0.731967777    1.0000000 0.9989553\n9          9 1.0015803  0.33414240 0.738272105    1.0000000 0.9983691\n10        10 1.0008431  0.11491596 0.908511735    1.0000000 1.0020490\n11        11 0.9893119 -1.12206799 0.261833534    1.0000000 1.0019442\n12        12 0.9500104 -3.06664448 0.002164762    0.0261981 1.0037740\n13        13 0.9171266 -3.08797727 0.002015239    0.0261981 0.9983081\n       Infit_t   Infit_p Infit_pholm\n1  -0.02996133 0.9760979           1\n2   0.00493709 0.9960608           1\n3   0.06474206 0.9483794           1\n4  -0.02929140 0.9766322           1\n5   0.16107560 0.8720339           1\n6  -0.01067736 0.9914809           1\n7  -0.51265966 0.6081894           1\n8  -0.29394324 0.7688013           1\n9  -0.34853112 0.7274413           1\n10  0.30700014 0.7588433           1\n11  0.19328053 0.8467393           1\n12  0.22589319 0.8212845           1\n13 -0.04677111 0.9626957           1\n\n\nManchmal kann es auch helfen, sich das ganze als Plot ausgeben zu lassen:\n\nCode# Definieren einer eigenen Plot-Funkktion\nplot_infit_outfit &lt;- function(tam_obj){\nfit_tam &lt;- tam.fit(tam_obj)$itemfit\n\nfit_plotdat &lt;- fit_tam %&gt;%\n  # Als Faktor umwandeln, damit die Sortierung im Plot stimmt\n  mutate(Item = factor(parameter, levels = unique(parameter[order(as.numeric(parameter))]))) %&gt;%\n  select(Item, Outfit, Infit) %&gt;%\n  pivot_longer(cols = c(Outfit, Infit), names_to = \"fit\", values_to = \"value\")\n\nggplot(fit_plotdat, aes(x = value, y = Item)) +\n  geom_point(colour = \"#F4BA02\") +\n  facet_grid(. ~ fit, scales = \"fixed\") +\n  xlim(0.4, 1.6) +\n  theme_bg() +\n  geom_vline(xintercept = 0.5, linetype = \"dotted\", colour = \"#9B1B34\") +\n  geom_vline(xintercept = 1.5, linetype = \"dotted\", colour = \"#9B1B34\")\n}\n\nplot_infit_outfit(sim_dat_2PL)\n\nItem fit calculation based on 5 simulations\n|**********|\n|----------|\n\n\n\n\n\n\n\n\nWenig überraschend sind die Werte fast perfekt."
  },
  {
    "objectID": "exercises/xPl/model_selection.html#pl-1",
    "href": "exercises/xPl/model_selection.html#pl-1",
    "title": "Modellselektion",
    "section": "\n1.2 1PL",
    "text": "1.2 1PL\nJetzt wollen wir uns noch zwei alternative Modelle anschauen: Das 1PL Modell und das 3PL Modell. Fitte das 1PL mit TAM und schaue dir ebenfalls die Itemplots und die Fit-Statistiken an.\n\n\n\n\n\n\n\nsim_dat_1PL &lt;- tam(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"1PL\", verbose = FALSE)\n\nplot(sim_dat_1PL,\n  type = \"items\",\n  export = FALSE,\n  observed = TRUE,\n  package = \"graphics\"\n)\n\nIteration in WLE/MLE estimation  1   | Maximal change  2.6387 \nIteration in WLE/MLE estimation  2   | Maximal change  1.1571 \nIteration in WLE/MLE estimation  3   | Maximal change  0.118 \nIteration in WLE/MLE estimation  4   | Maximal change  0.0371 \nIteration in WLE/MLE estimation  5   | Maximal change  0.0132 \nIteration in WLE/MLE estimation  6   | Maximal change  0.0045 \nIteration in WLE/MLE estimation  7   | Maximal change  0.0016 \nIteration in WLE/MLE estimation  8   | Maximal change  5e-04 \nIteration in WLE/MLE estimation  9   | Maximal change  2e-04 \nIteration in WLE/MLE estimation  10   | Maximal change  1e-04 \n----\n WLE Reliability= 0.599 \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnd die Infit und Outfitwerte, geplottet mit meiner eigenen Funktion (weiter oben definiert):\n\nCodeplot_infit_outfit(sim_dat_1PL)\n\nItem fit calculation based on 5 simulations\n|**********|\n|----------|\n\n\n\n\n\n\n\n\nHier können wir schön sehen, dass der Fit schon deutlich abnimmt, wenn wir die Steigung ignorieren (die wir ja bewusst simuliert haben)."
  },
  {
    "objectID": "exercises/xPl/model_selection.html#pl-2",
    "href": "exercises/xPl/model_selection.html#pl-2",
    "title": "Modellselektion",
    "section": "\n1.3 3PL",
    "text": "1.3 3PL\nFitte jetzt ein 3PL Modell. Nimm für die simulierten Daten eine 50 % Chance an, das Item durch raten zu lösen.\n\n## Probably just instable because the data is wrong?\n\nsim_dat_3PL &lt;- tam.mml.3pl(sim_dat_wide %&gt;% select(-sub_id), \n                           verbose = FALSE, guess = rep(0.5, 13))\n\nsummary(sim_dat_3PL)\n\nplot(sim_dat_3PL,\n  type = \"items\",\n  export = FALSE,\n  observed = TRUE,\n  package = \"graphics\"\n)\n\ntam.fit(sim_dat_3PL)\n\n### Try mirt\nlibrary(mirt)\nsim_dat_3PL &lt;- mirt(sim_dat_wide %&gt;% select(-sub_id), 1, itemtype = \"3PL\", verbose = FALSE, guess = rep(0.25, 13))\nsummary(sim_dat_3PL)\ncoef(sim_dat_3PL, IRTpars = TRUE, simplify = TRUE)\n\n\nitemfit(sim_dat_3PL, fit_stats = \"infit\") # typical for Rasch modeling\n\n# install.packages(\"devtools\")\n# devtools::install_github(\"masurp/ggmirt\")\nlibrary(ggmirt)\nitemfitPlot(sim_dat_3PL)\ntracePlot(sim_dat_3PL)"
  },
  {
    "objectID": "slides/Linking/linking.html#fahrplan",
    "href": "slides/Linking/linking.html#fahrplan",
    "title": "Linking",
    "section": "Fahrplan",
    "text": "Fahrplan"
  },
  {
    "objectID": "slides/Linking/linking.html#wiederholung-voraussetzungen-für-irt",
    "href": "slides/Linking/linking.html#wiederholung-voraussetzungen-für-irt",
    "title": "Linking",
    "section": "Wiederholung: Voraussetzungen für IRT",
    "text": "Wiederholung: Voraussetzungen für IRT\n\n\n\n\nEindimmensionalität: Die Lösungswahrscheinlichkeit eines Items wird lediglich durch \\(\\theta_p\\) beeinflusst (und die Itemparameter), wobei die Dimension von \\(\\theta_p\\) gleich eins ist. Das Item misst also nur ein Konstrukt.\n\n\n\n\n\nLokal stochastische Unabhängigkeit: Nach Kontrolle für die Personenfähigkeit korrelieren die Items nicht mehr. Der einzige Grund dafür, dass die Items zusammenhängen, ist also, dass die Antwort von diesem Konstrukt beeinflusst wird. Durch die Kontrolle für die Personenfähigkeit halten wir also den Fähigkeitswert konstant (alle Personen haben die gleiche Fähigkeit).\nEin Modell mit lokaler Abhängigkeit hat wichtige Kovarianz zwischen den Items nicht entdeckt.\n\n\n\n\n\n\n\n\n\n\nÜbrigens\n\n\nItems können mehrdimensional aber trotzdem lokal unabhängig sein, wenn alle Items die gleichen Dimensionen messen. Andersherum sind Items immer lokal unabängig, wenn sie eindimensional sind."
  },
  {
    "objectID": "slides/Linking/linking.html#section",
    "href": "slides/Linking/linking.html#section",
    "title": "Linking",
    "section": "",
    "text": "Differential Item\nFunctioning (DIF)"
  },
  {
    "objectID": "slides/Linking/linking.html#das-problem",
    "href": "slides/Linking/linking.html#das-problem",
    "title": "Linking",
    "section": "Das Problem",
    "text": "Das Problem\nFunktionieren die Items in verschiedenen Gruppen (z.B. Geschlecht, Kultur, Fähigkeit …) auf dieselbe Art und Weise? Gibt es also echte Mittelwertsunterschiede zwischen beiden Gruppen, oder sind die Unterschiede auf besondere Interaktionen zwischen Items und Gruppen zurückzuführen?"
  },
  {
    "objectID": "slides/Linking/linking.html#section-1",
    "href": "slides/Linking/linking.html#section-1",
    "title": "Linking",
    "section": "",
    "text": "Der Legende nach soll Rugby während eines Fußballspiels in der gleichnamigen Stadt entstanden sein. Als der Mannschaft von William Webb Ellis 1823 eine Niederlage bevorstand, packte dieser den Ball mit den Händen und legte ihn ins Tor des Gegners. Obwohl berechtigte Zweifel am Wahrheitsgehalt der Geschichte bestehen – der Ball wurde bereits zuvor in den meisten Spielvarianten mit der Hand getragen –, ist der Pokal der Rugby-Union-Weltmeisterschaft nach William Webb Ellis benannt (der Webb Ellis Cup).\n1863 wurde der englische Fußballverband Football Association (FA) mit dem Ziel gegründet, die noch vielfältigen Fußballregeln zu vereinheitlichen. Aufgrund von Streitigkeiten über Regeländerungen zogen sich einige Vereine aus dem Verband zurück und gründeten am 26. Januar 1871 mit der Rugby Football Union (RFU) einen konkurrierenden Verband, der in der Folgezeit nach und nach die Regeln der Rugby School standardisierte. Bereits am 27. März desselben Jahres fand in Edinburgh zwischen Schottland und England das erste Länderspiel statt.\n1895 erfolgte aufgrund eines Streits über den Amateurgedanken eine weitere Trennung, diesmal innerhalb der RFU. 21 Vereine, vor allem aus Arbeitervierteln Nordenglands, spalteten sich als Northern Rugby Union (heute Rugby Football League) ab, legten ihre eigenen Regeln fest und erlaubten die Professionalisierung des Sports. Aus den veränderten Regeln entwickelte sich die Variante Rugby League. Bis heute existieren beide Varianten des Rugbys nebeneinander. Internationale Begegnungen von Nationalmannschaften werden sowohl nach den Regeln der Rugby Union wie auch nach denen der Rugby League abgehalten. Seit 1995 sind im Rugby Union ebenfalls Profisportler zugelassen.\n\n\n\nWikipedia"
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel",
    "href": "slides/Linking/linking.html#beispiel",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\n\n\nWelche Unterarten von Rugby gibt es laut Text?"
  },
  {
    "objectID": "slides/Linking/linking.html#differential-item-functioning",
    "href": "slides/Linking/linking.html#differential-item-functioning",
    "title": "Linking",
    "section": "Differential Item Functioning",
    "text": "Differential Item Functioning\n\nDIF: Item Characteristic Curves (also mind. einer der Paramter im IRT Modell) unterscheiden sich in verschiedenen Subgruppen.\n\nGrund: Item ist nicht eindimensional.\n\nDIF-Untersuchung ist damit auch eine Untersuchung der Testvalidität!\n\n\n\n\n\n\n\nMögliche Fähigkeitsunterschiede zwischen den Gruppen auf dem gemessenen Konstrukt interessieren uns hier nicht. Die rechnen wir gleich in Kapitel 23 raus."
  },
  {
    "objectID": "slides/Linking/linking.html#schwierigkeit",
    "href": "slides/Linking/linking.html#schwierigkeit",
    "title": "Linking",
    "section": "Schwierigkeit",
    "text": "Schwierigkeit"
  },
  {
    "objectID": "slides/Linking/linking.html#diskriminationsparameter",
    "href": "slides/Linking/linking.html#diskriminationsparameter",
    "title": "Linking",
    "section": "Diskriminationsparameter",
    "text": "Diskriminationsparameter"
  },
  {
    "objectID": "slides/Linking/linking.html#wie-ghen-wir-damit-um",
    "href": "slides/Linking/linking.html#wie-ghen-wir-damit-um",
    "title": "Linking",
    "section": "Wie ghen wir damit um?",
    "text": "Wie ghen wir damit um?\nWir schauen uns die Itemparameter in der Reference group und in der Focal group an.\n\nNaive Lösung: Einfach die verschiedenen Subgruppen einzeln kalibrieren und dann die ICRs/Itemparameter anschauen.\n\nWarum funktioniert das so nicht?"
  },
  {
    "objectID": "slides/Linking/linking.html#warum-funktioniert-das-nicht",
    "href": "slides/Linking/linking.html#warum-funktioniert-das-nicht",
    "title": "Linking",
    "section": "Warum funktioniert das nicht?",
    "text": "Warum funktioniert das nicht?\nWerte aus verschiedenen Kalibrierungen können nicht ohne weiteres vergleichen werden, da die Skalen arbiträr festgelegt werden.\n \nWir müssen also vorher linken!"
  },
  {
    "objectID": "slides/Linking/linking.html#section-2",
    "href": "slides/Linking/linking.html#section-2",
    "title": "Linking",
    "section": "",
    "text": "Linking"
  },
  {
    "objectID": "slides/Linking/linking.html#wiederholung-kalibrierung",
    "href": "slides/Linking/linking.html#wiederholung-kalibrierung",
    "title": "Linking",
    "section": "Wiederholung: Kalibrierung",
    "text": "Wiederholung: Kalibrierung\nDie kalibrierten Itemparameter und Personenfähigkeiten gelten erst einmal nur für diese bestimmte Kombintation aus Items und Personen.\n\nWARUM?"
  },
  {
    "objectID": "slides/Linking/linking.html#wiederholung-kalibrierung-1",
    "href": "slides/Linking/linking.html#wiederholung-kalibrierung-1",
    "title": "Linking",
    "section": "Wiederholung: Kalibrierung",
    "text": "Wiederholung: Kalibrierung\n\nSkala der Latenten Variable wird arbiträr festgelegt (meist auf einen Mittelwert von 0 und eine SD von 1).\nModell ist sonst nicht idenfiziert.\nItemparameter aus versch. Kalibrierungen dadurch nicht auf der selben Skala.\nSie können also nicht direkt miteinander verglichen werden."
  },
  {
    "objectID": "slides/Linking/linking.html#problem",
    "href": "slides/Linking/linking.html#problem",
    "title": "Linking",
    "section": "Problem",
    "text": "Problem\n\n\nDas Problem\nInvarianz-Eigenschaft von IRT: Itemparameter sind gleich über verschiedene Gruppen. Die Wahrscheinlichkeit für eine korrekte Antwort auf ein Item hängt also nur von \\(\\theta\\) ab. Nicht von anderen Personen in der Stichprobe.\n\n\nDie Lösung\nWir müssen die Werte, die wir aus diesen unterschiedlichen Kalibrierungen bekommen, irgendwie in einen Zusammenhang setzen."
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel-1",
    "href": "slides/Linking/linking.html#beispiel-1",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nWenn wir eine sehr leistungsstarke Stichprobe haben, und eine sehr leistungsschwache, dann wird nach der Kalibrierung trotzdem bei beiden der Mittelwert der Latenten Variable 0 und die SD 1 sein. Mittelschwere Items werden aber in der schwachen Gruppe eher positive Schwierigkeiten haben, in der starken Gruppe eher negative."
  },
  {
    "objectID": "slides/Linking/linking.html#beispiel-2",
    "href": "slides/Linking/linking.html#beispiel-2",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nGroup 1: \\(\\theta \\sim N(0,1)\\)\nGroup 2: \\(\\theta \\sim N(1, 1.4)\\)\n \nFür die Kalibrierung legen wir jetzt aber fest, dass gilt: Gruppe 1: \\(\\hat{\\theta} \\sim N(0,1)\\)\nGruppe 2: \\(\\hat{\\theta} \\sim N(0,1)\\)\n\n\n\n\n\n\nDie Bedeutung des Skalenursprungs (0) unterscheidet sich, dadurch unterscheiden sich auch die Itemparameter."
  },
  {
    "objectID": "slides/Linking/linking.html#illustration",
    "href": "slides/Linking/linking.html#illustration",
    "title": "Linking",
    "section": "Illustration",
    "text": "Illustration\nWir nehmen an, dass die gleiche Person in Gruppe 1 und in Gruppe 2 getestet wird. Gruppe 2 ist dabei insgesamt stärker als Gruppe 1.\n\n\n\n\n\n\n\n\n\n\n\nMit der gleichen Fähigkeit würde sie in Gruppe 2 einen niedrigeren Fähigkeitswert zugewiesen bekommen, da diese Gruppe einfach besser ist als Gruppe 1.\n\n\n\nGrafik nach diesem Workshop."
  },
  {
    "objectID": "slides/Linking/linking.html#illustration-2",
    "href": "slides/Linking/linking.html#illustration-2",
    "title": "Linking",
    "section": "Illustration 2",
    "text": "Illustration 2\n\n\nDas gleiche Item wird in Gruppe 2 als leichter geschätzt als in Gruppe 1, einfach weil die Lösungswahrscheinlichkeit in Gruppe 2 insgesamt höher ist."
  },
  {
    "objectID": "slides/Linking/linking.html#schwierigkeit-1",
    "href": "slides/Linking/linking.html#schwierigkeit-1",
    "title": "Linking",
    "section": "Schwierigkeit",
    "text": "Schwierigkeit"
  },
  {
    "objectID": "slides/Linking/linking.html#diskriminationsparameter-1",
    "href": "slides/Linking/linking.html#diskriminationsparameter-1",
    "title": "Linking",
    "section": "Diskriminationsparameter",
    "text": "Diskriminationsparameter"
  },
  {
    "objectID": "slides/Linking/linking.html#schlusfolgerung",
    "href": "slides/Linking/linking.html#schlusfolgerung",
    "title": "Linking",
    "section": "Schlusfolgerung",
    "text": "Schlusfolgerung\nWir brauchen also einen Referenzrahmen um unsere Testergebnisse interpretieren zu können.\nLösung: Linking"
  },
  {
    "objectID": "slides/Linking/linking.html#sec-linking",
    "href": "slides/Linking/linking.html#sec-linking",
    "title": "Linking",
    "section": "Linking: Anwendungsbereiche",
    "text": "Linking: Anwendungsbereiche\nImmer, wenn wir Werte aus verschiedenen Kalibrierungen miteinander vergleichen wollen:\n\nDIF\nTests, die in verschiedenen Jahren bearbeitet wurden\nAdaptives Testen\n\nGanz egal welcher Anwendungsfall, das Szenario ist das gleiche: Wir haben verschiedene Testformen, und wollen die Scores auf eine gemeinsame Skala bringen. - Dafür haben wir zwei Möglichkeiten: - Gemeinsame Items - Gemeinsame Personen"
  },
  {
    "objectID": "slides/Linking/linking.html#übung",
    "href": "slides/Linking/linking.html#übung",
    "title": "Linking",
    "section": "Übung",
    "text": "Übung\nGehe zur ersten Übung zum Thema Linking/DIF. Es geht hier nochmal um Datenaufbereitung."
  },
  {
    "objectID": "slides/Linking/linking.html#gemeinsame-personen",
    "href": "slides/Linking/linking.html#gemeinsame-personen",
    "title": "Linking",
    "section": "Gemeinsame Personen",
    "text": "Gemeinsame Personen\nPersonen bearbeiten beide Tests. Personenfähigkeit wird basierend auf einem Referenztest geschätzt, und dann fixiert und konstant gehalten, wenn andere Testformen bearbeitet werden. Die Fähigkeitswerte werden dann genutzt, um Itemparameter auf beiden Testformen zu schätzen."
  },
  {
    "objectID": "slides/Linking/linking.html#ankeritems",
    "href": "slides/Linking/linking.html#ankeritems",
    "title": "Linking",
    "section": "Ankeritems",
    "text": "Ankeritems\n\n\nAnkeritems sind gemeinsame Items, die in beiden Testformen vorhanden sind. Hauptproblem bei der Auswahl: Sie sollten in beiden Gruppen nicht unterschiedlich funktionieren, es sollte also kein Differential Item Functioning (DIF) geben."
  },
  {
    "objectID": "slides/Linking/linking.html#linking-verfahren-grundidee",
    "href": "slides/Linking/linking.html#linking-verfahren-grundidee",
    "title": "Linking",
    "section": "Linking Verfahren: Grundidee",
    "text": "Linking Verfahren: Grundidee\nDie \\(\\theta\\) scores der Focal group müssen so transformiert werden, dass sie auf einer gemeinsamen Skala mit den Scores der Reference group liegen:\n\\[\n\\theta_R = A \\theta_F + B\n\\]\nZiel: “Linking constants” \\(A\\) und \\(B\\) zu finden, welche die Itemparameter aus den beiden Gruppen auf der selben Skala plazieren."
  },
  {
    "objectID": "slides/Linking/linking.html#linking-methoden",
    "href": "slides/Linking/linking.html#linking-methoden",
    "title": "Linking",
    "section": "Linking Methoden",
    "text": "Linking Methoden\n\nDie häufigsten Methoden:\n\nmean-mean ()\nmean-sigma ()\nStocking-Lord ()\nHaebermann ()"
  },
  {
    "objectID": "slides/Linking/linking.html#sec-transf",
    "href": "slides/Linking/linking.html#sec-transf",
    "title": "Linking",
    "section": "mean-sigma Transformationen",
    "text": "mean-sigma Transformationen\nGrundlegend sind einige einfache Transformationen:\n\n\\(\\theta^* = x\\theta+y\\)\n\\(\\beta^* = x\\beta=y\\)\n\\(\\alpha^*=\\frac{\\alpha}{x}\\)\n\\(c^* = c\\)\n\nZiel ist es, die Linkingkonstanten \\(x\\) und \\(y\\) zu finden."
  },
  {
    "objectID": "slides/Linking/linking.html#finden-der-linkingkonstanten",
    "href": "slides/Linking/linking.html#finden-der-linkingkonstanten",
    "title": "Linking",
    "section": "Finden der Linkingkonstanten",
    "text": "Finden der Linkingkonstanten\n\n\n\\(\\overline{\\beta}_R\\) und \\(\\overline{\\beta}_F\\) als Mittelwert der geschätzten Itemschwierigkeiten in Referenz- und Fokusgruppe\n\n\\(\\sigma_R\\) und \\(\\sigma_F\\) als Standardabweichung der geschätzten Itemschwierigkeiten in Referenz- und Fokusgruppe."
  },
  {
    "objectID": "slides/Linking/linking.html#finden-der-linkingkonstanten-1",
    "href": "slides/Linking/linking.html#finden-der-linkingkonstanten-1",
    "title": "Linking",
    "section": "Finden der Linkingkonstanten",
    "text": "Finden der Linkingkonstanten\n\\[\nx = \\frac{\\sigma_R}{\\sigma_F}\n\\]\n\n\n\n\n\n\nMean-mean Linking\n\n\nDie mean-mean Methode nutzt hier statt der Standardabweichung der Itemschwierigkeiten die Mittelwerte (Erwartungswerte) der Diskriminationsparamter. In der Praxis werden beide Methoden eher weniger genutzt.\n\n\n\n\\[\ny = \\overline{\\beta}_R - x(\\overline{\\beta}_F)\n\\]\nUnd dann einsetzen in \\[\n\\theta* = x\\theta+y\n\\] \\[\nB_F^* = x\\beta_F + y\n\\]"
  },
  {
    "objectID": "slides/Linking/linking.html#mean-sigma",
    "href": "slides/Linking/linking.html#mean-sigma",
    "title": "Linking",
    "section": "mean-sigma",
    "text": "mean-sigma\nProbleme: linking constants können stark von Outliern beeinflusst werden, und von den differential standards errors of the item difficutly estimates Es gibt aber auch Robuste Verfahren.\nAlternative: Characteristic curve methods"
  },
  {
    "objectID": "slides/Linking/linking.html#characteristic-curve-methods",
    "href": "slides/Linking/linking.html#characteristic-curve-methods",
    "title": "Linking",
    "section": "Characteristic curve methods",
    "text": "Characteristic curve methods\nVersuch, die Linking constants so zu berechnen, dass die test charactersitic curves so ähnlich wie möglich sind. Nutzen daher alle Itemparameter um die Linkingkonstanten zu finden. Ist rechnerisch aufwändiger.\n\nHaebara-Linking\nStocking-Lord"
  },
  {
    "objectID": "slides/Linking/linking.html#stocking-lord",
    "href": "slides/Linking/linking.html#stocking-lord",
    "title": "Linking",
    "section": "Stocking-Lord",
    "text": "Stocking-Lord\n\\[\n\\sum_{\\theta}\\left[\\sum_j P(Y_i = 1|\\theta, a_{R_i}, b_{R_i}, c_{R_i})  - \\sum_j P(Y_i=1|\\theta,\\frac{a_{F_i}}{x}, xb_{F_i}+y, c_{F_i})\\right]^2\n\\]\n\ni: Item"
  },
  {
    "objectID": "slides/Linking/linking.html#stocking-lord-1",
    "href": "slides/Linking/linking.html#stocking-lord-1",
    "title": "Linking",
    "section": "Stocking-Lord",
    "text": "Stocking-Lord\n\\[\n\\sum_{\\theta}\\left[\\color{#9B1B34}{\\sum_i P(Y_i = 1|\\theta, \\alpha_{R_i}, \\beta_{R_i}, c_{R_i})}  - \\sum_i P(Y_i=1|\\theta,\\frac{\\alpha_{F_i}}{x}, x\\beta_{F_i}+y, c_{F_i})\\right]^2\n\\] - Summe der Test Characteristic Curves über alle Items."
  },
  {
    "objectID": "slides/Linking/linking.html#stocking-lord-2",
    "href": "slides/Linking/linking.html#stocking-lord-2",
    "title": "Linking",
    "section": "Stocking-Lord",
    "text": "Stocking-Lord\n\\[\n\\sum_{\\theta}\\left[\\sum_i P(Y_i = 1|\\theta, \\alpha_{R_i}, \\beta_{R_i}, c_{R_i})  - \\sum_i P(Y_i=1|\\theta,\\color{#9B1B34}{\\frac{\\alpha_{F_i}}{x}, x\\beta_{F_i}+y, c_{F_i}})\\right]^2\n\\]\n\nDas sind unsere Transformationen von Kapitel 29."
  },
  {
    "objectID": "slides/Linking/linking.html#haebara",
    "href": "slides/Linking/linking.html#haebara",
    "title": "Linking",
    "section": "Haebara",
    "text": "Haebara\n\\[\n\\sum_{\\theta}\\color{#9B1B34}{\\sum_i}\\left[P(Y_i = 1|\\theta, \\alpha_{R_i}, \\beta_{R_i}, c_{R_i}) - P(Y_i=1|\\theta,\\frac{\\alpha_{F_i}}{x}, x\\beta_{F_i}+y, c_{F_i})\\right]^2\n\\] Sehr ähnlich, nur dass wir hier die Item Characteristic Curves verwenden."
  },
  {
    "objectID": "slides/Linking/linking.html#haebara-und-stocking-lord",
    "href": "slides/Linking/linking.html#haebara-und-stocking-lord",
    "title": "Linking",
    "section": "Haebara und Stocking-Lord",
    "text": "Haebara und Stocking-Lord\nIn beiden Fällen wird die Gleichung so optimiert, dass die Linkingkonstanten \\(x\\) und \\(y\\) so bestimmt werden, dass der Unterschied zwischen den Test/Item Characteristic Curves der Referenz- und Fokusgruppe minimiert wird."
  },
  {
    "objectID": "slides/Linking/linking.html#übung-1",
    "href": "slides/Linking/linking.html#übung-1",
    "title": "Linking",
    "section": "Übung",
    "text": "Übung\nLöse die Übungsaufgaben zum Linking."
  },
  {
    "objectID": "slides/Linking/linking.html#section-3",
    "href": "slides/Linking/linking.html#section-3",
    "title": "Linking",
    "section": "",
    "text": "Zurück zum Anfang: Differential Item Functioning\nWir haben jetzt gesehen, wie man Item- und Personenparamter aus verschiedenen Kalibrierungen auf die selbe Skala bringen kann. Jetzt können wir auf das Eingangsproblem dieser Session zurückkommen: DIF."
  },
  {
    "objectID": "slides/Linking/linking.html#dif-finden",
    "href": "slides/Linking/linking.html#dif-finden",
    "title": "Linking",
    "section": "DIF finden",
    "text": "DIF finden\nViele verschiedene Verfahren, meist wird folgende Frage untersucht: Wurden Items in bestimmten Gruppen häufiger beantwortet wurden als in anderen Gruppen, bzw. wurden die Itemparamter in bestimmten Gruppen anders geschätzt (nachdem gelinkt wurde)?\nEs werden also entweder die beobacheteten Testscores oder die latenten Fähigkeitswert zur Berechnung genutzt.\n\n\nSiehe Berrı́o et al. (2020) für eine ausführliche Übersicht zu verschiedenen DIF-Findungs Ansätzen."
  },
  {
    "objectID": "slides/Linking/linking.html#ansätze",
    "href": "slides/Linking/linking.html#ansätze",
    "title": "Linking",
    "section": "Ansätze",
    "text": "Ansätze\nObserved Score Ansätze\nZ.B. der bekannte Mantel-Haenszel Test. Nutzen Kontingenztabellen, um zu schauen, ob sich die Antwortmusster der einzelenen Items in den verschiedenen Gruppen unterscheiden.\nLikelihood Ratio Test\nVergleich von Modellen mit zwischen Gruppen fixierten Parametern eines Items, und Modellen mit frei geschätzten Parametern."
  },
  {
    "objectID": "slides/Linking/linking.html#ansätze-1",
    "href": "slides/Linking/linking.html#ansätze-1",
    "title": "Linking",
    "section": "Ansätze",
    "text": "Ansätze\nLogistische Regression\nLogistische Regression Interaktionsterm zwischen Gruppenzugehörigkeit und Itemschwierigkeit/Personenfähigkeit gibt.\nLord’s Chi Quadrat Test/Wald Test\nIRT Ansatz, Vergleich von Itemparametern zwischen den Gruppen.\nRaschtrees\nGruppensplitting, kann auch diverse Interaktionen zwischen Variablen einfach untersuchen."
  },
  {
    "objectID": "slides/Linking/linking.html#regularisierung",
    "href": "slides/Linking/linking.html#regularisierung",
    "title": "Linking",
    "section": "Regularisierung",
    "text": "Regularisierung"
  },
  {
    "objectID": "slides/Linking/linking.html#iteratives-vorgehen",
    "href": "slides/Linking/linking.html#iteratives-vorgehen",
    "title": "Linking",
    "section": "Iteratives Vorgehen",
    "text": "Iteratives Vorgehen\n\n\n\n\n\n\nOft werden die Methoden iterativ angewandt, da beim anfänglichen Matchen der Gruppen ja auch eventuell DIF-Items für die Berechnung der Scores verwendet werden."
  },
  {
    "objectID": "slides/Linking/linking.html#welche-denn-jetzt",
    "href": "slides/Linking/linking.html#welche-denn-jetzt",
    "title": "Linking",
    "section": "Welche denn jetzt?",
    "text": "Welche denn jetzt?\nAbhängig vom Modell, der Fragestellung und den Daten.\nFür kleine Datensätze eventuell eher Verfahren wählen die auf beobachtete Scores zurückgreifen (nicht auf geschätzte Trait-Variablen).\nSehr große Datensätze mit vielen Kovariaten (und damit auch vielen verschiedenen Gruppen und Gruppen-Interaktionen) könnten von Machine-Learning profitieren, z.B. Rasch-Trees.\nAnsonste Simulation von Daten und ausprobieren.\n\n\n\n\n\n\nGenerell ist es keine gute Idee, einfach nach p-Werten zu gehen, um Items dann blind auszuschließen. Stattdessen sollten die Itemschwierigkeitsunterschiede zwischen den Gruppen beurteilt, und auch das Item selbst inhaltlich untersucht werden.\n\n\n\nhttps://cran.r-project.org/web/packages/difR/difR.pdf"
  },
  {
    "objectID": "slides/Linking/linking.html#übung-2",
    "href": "slides/Linking/linking.html#übung-2",
    "title": "Linking",
    "section": "Übung",
    "text": "Übung\nBitte bearbeite die DIF-Übung."
  },
  {
    "objectID": "slides/Linking/linking.html#section-4",
    "href": "slides/Linking/linking.html#section-4",
    "title": "Linking",
    "section": "",
    "text": "Pause"
  },
  {
    "objectID": "slides/Linking/linking.html#literatur",
    "href": "slides/Linking/linking.html#literatur",
    "title": "Linking",
    "section": "Literatur",
    "text": "Literatur\n\n\nBerrı́o, Á. I., Gomez-Benito, J., & Arias-Patiño, E. M. (2020). Developments and trends in research on methods of detecting differential item functioning. Educational Research Review, 31, 100340."
  },
  {
    "objectID": "slides/Linking/linking.html#bildquellen",
    "href": "slides/Linking/linking.html#bildquellen",
    "title": "Linking",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Annie Spratt auf Unsplash\n\nFoto von Martin Wettstein auf Unsplash\n\nFoto von Martin Wettstein auf Unsplash\n\nFoto von Bryson Hammer auf Unsplash.\nErstellt mit Bing Bild-Ersteller.\nFoto von Quino Al auf Unsplash\n\nFoto von James Coleman auf Unsplash\n\nhttps://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/Flag_of_Germany.svg/1920px-Flag_of_Germany.svg.png\nhttps://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Flag_of_New_Zealand.svg/800px-Flag_of_New_Zealand.svg.png\nFoto von Casey Allen auf Unsplash"
  },
  {
    "objectID": "slides/IntroR/introR.html#überblick",
    "href": "slides/IntroR/introR.html#überblick",
    "title": "Einführung in R",
    "section": "Überblick",
    "text": "Überblick\n\nArbeiten mit R und RStudio\nGrundlegende Operationen in R: Daten laden, Pakete installieren …\nDatenmanipulation und Transformation in R\n\n\n\n\n\n\n\nZiel\n\n\nAm Ende der Session solltet ihr mit den Grundlagen in R vertraut sein, sodass ihr den Rest des Workshops in R bestreiten könnt."
  },
  {
    "objectID": "slides/IntroR/introR.html#section",
    "href": "slides/IntroR/introR.html#section",
    "title": "Einführung in R",
    "section": "",
    "text": "RStudio Interface"
  },
  {
    "objectID": "slides/IntroR/introR.html#section-1",
    "href": "slides/IntroR/introR.html#section-1",
    "title": "Einführung in R",
    "section": "",
    "text": "Beim ersten Öffnen wird RStudio in etwa so aussehen:"
  },
  {
    "objectID": "slides/IntroR/introR.html#section-2",
    "href": "slides/IntroR/introR.html#section-2",
    "title": "Einführung in R",
    "section": "",
    "text": "Das Fenster hat 4 Bereiche:"
  },
  {
    "objectID": "slides/IntroR/introR.html#script-pane",
    "href": "slides/IntroR/introR.html#script-pane",
    "title": "Einführung in R",
    "section": "1) Script Pane",
    "text": "1) Script Pane\nEditieren von Skripten (Datein, in denen Code gespeichert wird) und ausführen von Code (crtl + enter (Windows) oder command + return (macOS).\n\n# Our first line of code:\nprint(\"Hello World!\")\n\n[1] \"Hello World!\"\n\n\n\n\n\n\n\n\nÜbrigens: Codezeilen, die mit einem # beginnen, sind auskommentiert und werden nicht ausgewertet."
  },
  {
    "objectID": "slides/IntroR/introR.html#console",
    "href": "slides/IntroR/introR.html#console",
    "title": "Einführung in R",
    "section": "2) Console",
    "text": "2) Console\nHier erscheint der Output aus unseren Skripten. Wir können auch direkt in der Konsole arbeiten und Befehle mit enter ausführen:\n\n10 + 5\n\n[1] 15\n\n\n\n\n\n\n\n\nHier geschriebener Code wird nicht gespeichert. Nutze die Konsole also, um Dinge auszuprobieren, schreibe aber alles Wichtige in Skripte."
  },
  {
    "objectID": "slides/IntroR/introR.html#workspace",
    "href": "slides/IntroR/introR.html#workspace",
    "title": "Einführung in R",
    "section": "3) Workspace",
    "text": "3) Workspace\nIm Environment-Tab erhalten wir einen Überblick über die Objekte, die derzeit in unserer R-Sitzung geladen sind.\nWir können auch den Befehlsverlauf einsehen und einige weitere Dinge, die wir jetzt nicht benötigen."
  },
  {
    "objectID": "slides/IntroR/introR.html#plots-datein-hilfe",
    "href": "slides/IntroR/introR.html#plots-datein-hilfe",
    "title": "Einführung in R",
    "section": "4) Plots, Datein, Hilfe …",
    "text": "4) Plots, Datein, Hilfe …\nPlots, die wir in einer R-Sitzung erstellen, werden im Plot-Tab ausgegeben.\nBeim Aufrufen der Hilfefunktion öffnet sich die Dokumentation im Hilfe-Tab.\n\n\n\n\n\n\nHilfe in R\n\n\nDie Dokumentation kann mit ?funktionsname aufgerufen werden. Das ist eines der wichtigsten Werkzeuge bei der Arbeit in R.\n\n\n\nDer Dateien-Tab ermöglicht es uns, die Dateien in unserem Arbeitsverzeichnis zu verwalten."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-3",
    "href": "slides/IntroR/introR.html#section-3",
    "title": "Einführung in R",
    "section": "",
    "text": "Los Geht’s!"
  },
  {
    "objectID": "slides/IntroR/introR.html#grundlegende-operationen",
    "href": "slides/IntroR/introR.html#grundlegende-operationen",
    "title": "Einführung in R",
    "section": "Grundlegende Operationen",
    "text": "Grundlegende Operationen\n\n\nc(): Vektor erstellen\n\nseq() oder :: Sequenzen erstellen\n\n&, |, !: Logische Operatoren (und, oder, nicht)"
  },
  {
    "objectID": "slides/IntroR/introR.html#datenstrukturen",
    "href": "slides/IntroR/introR.html#datenstrukturen",
    "title": "Einführung in R",
    "section": "Datenstrukturen:",
    "text": "Datenstrukturen:\n\n\n\nHomogeneous\nHeterogeneous\n\n\n\n1d\natomic vector\nlist\n\n\n2d\nmatrix\ndata.frame\n\n\nnd\narray\n\n\n\n\n\n\nTabelle aus Advanced R."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-4",
    "href": "slides/IntroR/introR.html#section-4",
    "title": "Einführung in R",
    "section": "",
    "text": "Basic Setup"
  },
  {
    "objectID": "slides/IntroR/introR.html#rstudio-projekte",
    "href": "slides/IntroR/introR.html#rstudio-projekte",
    "title": "Einführung in R",
    "section": "RStudio Projekte",
    "text": "RStudio Projekte\nHilft ungemein beim Organisieren von Dateien und Code!\n\n\n\n\n\n\nÜbung\n\n\nErstelle einen neuen Ordner (falls noch nicht getan) für diesen Workshop, und lege darin ein RStudio Projekt an (File - New Project)."
  },
  {
    "objectID": "slides/IntroR/introR.html#skripte",
    "href": "slides/IntroR/introR.html#skripte",
    "title": "Einführung in R",
    "section": "Skripte",
    "text": "Skripte\nHier kommt der Code rein!\n\n\n\n\n\n\nÜbung\n\n\nErstelle einen neuen Unterordner und lege darin ein R-Skript and (File - New File - R Script). In diesen kommen dann die Übungsaufgaben und Notizen aus dem Workshop. Leg am besten für jedes Thema ein eigenes Skript an, damit sie übersichtlich bleiben."
  },
  {
    "objectID": "slides/IntroR/introR.html#pakete",
    "href": "slides/IntroR/introR.html#pakete",
    "title": "Einführung in R",
    "section": "Pakete",
    "text": "Pakete\n\n\nPakete sind Erweiterungen zum base R und funktionieren ein bisschen wie Apps im Playstore:\n\n\n Einmalig installieren:\n\n\ninstall.packages(\"packagename\")\n\n\n\n Bei jeder Nutzung in die R-Session laden:\n\n\nlibrary(packagename)"
  },
  {
    "objectID": "slides/IntroR/introR.html#tidyverse",
    "href": "slides/IntroR/introR.html#tidyverse",
    "title": "Einführung in R",
    "section": "tidyverse",
    "text": "tidyverse\n\n\n\n\nVerbreitete Paketsammlung in R für so ziemlich jede Stufe der Datenauswertung. Der meiste Code den wird schreiben wird wahrscheinlich aus einer Mischung aus base R und tidyverse bestehen."
  },
  {
    "objectID": "slides/IntroR/introR.html#tidyverse-pipe-operator",
    "href": "slides/IntroR/introR.html#tidyverse-pipe-operator",
    "title": "Einführung in R",
    "section": "\ntidyverse: Pipe Operator",
    "text": "tidyverse: Pipe Operator\n%&gt;%\n\nsum(seq(from = 1, to = mean(c(45:100), na.rm = TRUE), by = 0.1))\n\n[1] 26313\n\n\nwird zu:\n\nlibrary(tidyverse)\n\nc(45:100) %&gt;%\n  mean(na.rm = TRUE) %&gt;%\n  seq(from = 1, to = ., by = 0.1) %&gt;%\n  sum\n\n[1] 26313"
  },
  {
    "objectID": "slides/IntroR/introR.html#section-5",
    "href": "slides/IntroR/introR.html#section-5",
    "title": "Einführung in R",
    "section": "",
    "text": "Daten und Pfade"
  },
  {
    "objectID": "slides/IntroR/introR.html#einlesen-von-daten",
    "href": "slides/IntroR/introR.html#einlesen-von-daten",
    "title": "Einführung in R",
    "section": "Einlesen von Daten",
    "text": "Einlesen von Daten\n\n\n\n\n\n\n\n\n\n\nData type\nImport\nExport\n\n\n\nR objects (.Rdata, .rda)\nload()\nsave()\n\n\nsingle R object (.rds)\nreadRDS()\nsaveRDS()\n\n\ntext-files (.txt)\nread.table()\nwrite.table()\n\n\n.csv-files (.csv)\nread.csv()\nwrite.csv()\n\n\nExcel-files (.xlsx)\nreadxl::read_excel()\nwritexl::write_xlsx()\n\n\nSPSS-files (.sav)\nhaven::read_sav()\nhaven::write_sav()\n\n\nSAS-files (.sas)\nhaven::read_sas()\nhaven::write_sas()\n\n\nStata-files (.stata)\nhaven::read_dta()\nhaven::write_dta()"
  },
  {
    "objectID": "slides/IntroR/introR.html#exkurs-here-paket",
    "href": "slides/IntroR/introR.html#exkurs-here-paket",
    "title": "Einführung in R",
    "section": "Exkurs: here-Paket",
    "text": "Exkurs: here-Paket\nhere ist ein Paket zum Erstellen von Dateipfaden. Dadurch können Probleme mit relativen und absoluten Pfaden vermieden werden.\nC:\\Users\\hafiznij\\Documents\\GitHub\\IRT_workshop\\raw_data\\athletes.rds wird zu:here::here(\"raw_data\", \"athletes.rds\").\nAlso:\n\n# install.packages(\"here\")\nathletes &lt;- readRDS(here::here(\"raw_data\", \"athletes.rds\"))"
  },
  {
    "objectID": "slides/IntroR/introR.html#einlesen-von-daten-1",
    "href": "slides/IntroR/introR.html#einlesen-von-daten-1",
    "title": "Einführung in R",
    "section": "Einlesen von Daten",
    "text": "Einlesen von Daten\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übung zum Einlesen von Daten."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-7",
    "href": "slides/IntroR/introR.html#section-7",
    "title": "Einführung in R",
    "section": "",
    "text": "Datenmanipulation und Transformation"
  },
  {
    "objectID": "slides/IntroR/introR.html#überblick-bekommen",
    "href": "slides/IntroR/introR.html#überblick-bekommen",
    "title": "Einführung in R",
    "section": "Überblick bekommen",
    "text": "Überblick bekommen\n\n\n\nView()\nstr()\nhead()"
  },
  {
    "objectID": "slides/IntroR/introR.html#view",
    "href": "slides/IntroR/introR.html#view",
    "title": "Einführung in R",
    "section": "View()",
    "text": "View()\n\n\nÖffnet den Datensatz in einem neuem Fenster:\n\nView(athletes)"
  },
  {
    "objectID": "slides/IntroR/introR.html#str",
    "href": "slides/IntroR/introR.html#str",
    "title": "Einführung in R",
    "section": "str()",
    "text": "str()\n\nStruktur der Daten:\n\n\nstr(athletes)\n\n'data.frame':   270767 obs. of  16 variables:\n $ NOC   : chr  \"AFG\" \"AFG\" \"AFG\" \"AFG\" ...\n $ ID    : int  132181 87371 44977 502 109153 29626 1076 121376 80210 87374 ...\n $ Name  : chr  \"Najam Yahya\" \"Ahmad Jahan Nuristani\" \"Mohammad Halilula\" \"Ahmad Shah Abouwi\" ...\n $ Sex   : chr  \"M\" \"M\" \"M\" \"M\" ...\n $ Age   : int  NA NA 28 NA 24 28 28 NA NA NA ...\n $ Height: int  NA NA 163 NA NA 168 NA NA NA NA ...\n $ Weight: num  NA NA 57 NA 74 73 NA NA 57 NA ...\n $ Team  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ Games : chr  \"1956 Summer\" \"1948 Summer\" \"1980 Summer\" \"1956 Summer\" ...\n $ Year  : int  1956 1948 1980 1956 1964 1960 1936 1956 1972 1956 ...\n $ Season: chr  \"Summer\" \"Summer\" \"Summer\" \"Summer\" ...\n $ City  : chr  \"Melbourne\" \"London\" \"Moskva\" \"Melbourne\" ...\n $ Sport : chr  \"Hockey\" \"Hockey\" \"Wrestling\" \"Hockey\" ...\n $ Event : chr  \"Hockey Men's Hockey\" \"Hockey Men's Hockey\" \"Wrestling Men's Bantamweight, Freestyle\" \"Hockey Men's Hockey\" ...\n $ Medal : chr  NA NA NA NA ...\n $ Region: chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ..."
  },
  {
    "objectID": "slides/IntroR/introR.html#head",
    "href": "slides/IntroR/introR.html#head",
    "title": "Einführung in R",
    "section": "head()",
    "text": "head()\n\nErste Zeilen:\n\n\nhead(athletes)\n\n  NOC     ID                  Name Sex Age Height Weight        Team\n1 AFG 132181           Najam Yahya   M  NA     NA     NA Afghanistan\n2 AFG  87371 Ahmad Jahan Nuristani   M  NA     NA     NA Afghanistan\n3 AFG  44977     Mohammad Halilula   M  28    163     57 Afghanistan\n4 AFG    502     Ahmad Shah Abouwi   M  NA     NA     NA Afghanistan\n5 AFG 109153    Shakar Khan Shakar   M  24     NA     74 Afghanistan\n6 AFG  29626  Sultan Mohammad Dost   M  28    168     73 Afghanistan\n        Games Year Season      City     Sport\n1 1956 Summer 1956 Summer Melbourne    Hockey\n2 1948 Summer 1948 Summer    London    Hockey\n3 1980 Summer 1980 Summer    Moskva Wrestling\n4 1956 Summer 1956 Summer Melbourne    Hockey\n5 1964 Summer 1964 Summer     Tokyo Wrestling\n6 1960 Summer 1960 Summer      Roma Wrestling\n                                    Event Medal      Region\n1                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n2                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n3 Wrestling Men's Bantamweight, Freestyle  &lt;NA&gt; Afghanistan\n4                     Hockey Men's Hockey  &lt;NA&gt; Afghanistan\n5 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan\n6 Wrestling Men's Welterweight, Freestyle  &lt;NA&gt; Afghanistan"
  },
  {
    "objectID": "slides/IntroR/introR.html#einen-überblick-bekommen-übung",
    "href": "slides/IntroR/introR.html#einen-überblick-bekommen-übung",
    "title": "Einführung in R",
    "section": "Einen Überblick bekommen: Übung",
    "text": "Einen Überblick bekommen: Übung\n\n\n\n\n\n\nÜbung 1\n\n\nWie viele Zeilen und Spalten hat der in der letzten Übung eingelesene Datensatz characters?\n\n\n\n\n\n\n\n\n\nÜbung 2\n\n\nAus welcher Show stammen die ersten Charactere im Datensatz?"
  },
  {
    "objectID": "slides/IntroR/introR.html#einfaches-subsetting",
    "href": "slides/IntroR/introR.html#einfaches-subsetting",
    "title": "Einführung in R",
    "section": "Einfaches Subsetting",
    "text": "Einfaches Subsetting\n\n\n# Auswahl der Spalten\nathletes[c(1,4), c(\"Year\", \"Sport\")]\n\n  Year  Sport\n1 1956 Hockey\n4 1956 Hockey"
  },
  {
    "objectID": "slides/IntroR/introR.html#konditionales-subsetting",
    "href": "slides/IntroR/introR.html#konditionales-subsetting",
    "title": "Einführung in R",
    "section": "Konditionales Subsetting",
    "text": "Konditionales Subsetting\n\nathletes_de &lt;- athletes[athletes$Team == \"Germany\", ]\nhead(athletes_de)\n\n       NOC     ID                   Name Sex Age Height Weight    Team\n107246 GER   7385     Dirk Peter Balster   M  26    195     90 Germany\n107247 GER 114424 Kathleen Stark (-Kern)   F  16    166     51 Germany\n...\n\n\nAlle Zeilen, in denen Team gleich Germany ist.\n\n\n\n\n\n\nWas passiert hier genau?\n\n\nWir erzeugen einen Boolean Vektor (besteht aus TRUE und FALSE), der anzeigt, welche Zeilen ausgewählt werden sollen:\n\nathletes$Team == \"Germany\"\n\n    [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n...\n\n\nDieser indiziert dann die Zeilen, die ausgewählt werden sollen."
  },
  {
    "objectID": "slides/IntroR/introR.html#komplexes-konditionales-subsetting",
    "href": "slides/IntroR/introR.html#komplexes-konditionales-subsetting",
    "title": "Einführung in R",
    "section": "Komplexes konditionales Subsetting",
    "text": "Komplexes konditionales Subsetting\nDiese Prinzip können wir uns zu Nutze machen, um mehrere Bedingungen zu verknüpfen:\n\nathletes_3 &lt;- athletes[(athletes$Sport == \"Judo\") & (athletes$Weight &gt; 100 | athletes$Weight &lt; 50), ]\nhead(athletes_3)\n\n      NOC    ID                Name  Sex Age Height Weight    Team       Games\nNA   &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.1 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.2 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\nNA.3 &lt;NA&gt;    NA                &lt;NA&gt; &lt;NA&gt;  NA     NA     NA    &lt;NA&gt;        &lt;NA&gt;\n471   ALG 13895 Mohamed Bouaichaoui    M  25    178    120 Algeria 2004 Summer\n...\n\n\n\n\n\n\n\n\nNA\n\n\nViele der Zeilen enthalten nur NA Werte. Das schauen wir uns gleich im Kapitel Kapitel 1.7 genauer an."
  },
  {
    "objectID": "slides/IntroR/introR.html#subsetting-zeilen-tidyverse",
    "href": "slides/IntroR/introR.html#subsetting-zeilen-tidyverse",
    "title": "Einführung in R",
    "section": "Subsetting Zeilen: Tidyverse\n",
    "text": "Subsetting Zeilen: Tidyverse\n\n\nlibrary(tidyverse)\n\nathletes %&gt;%\n  filter(Sport == \"Judo\", (Weight &gt; 100 | Weight &lt; 50)) %&gt;%\n  head\n\n  NOC    ID                   Name Sex Age Height Weight      Team       Games\n1 ALG 13895    Mohamed Bouaichaoui   M  25    178    120   Algeria 2004 Summer\n2 ALG 82643          Meriem Moussa   F  20    150     48   Algeria 2008 Summer\n3 ALG 80035        Boualem Miloudi   M  23    192    106   Algeria 1988 Summer\n...\n\n\n\n\n\n\n\n\nNA\n\n\nHier werden NA Werte automatisch ignoriert."
  },
  {
    "objectID": "slides/IntroR/introR.html#subsetting-spalten-tidyverse",
    "href": "slides/IntroR/introR.html#subsetting-spalten-tidyverse",
    "title": "Einführung in R",
    "section": "Subsetting Spalten: Tidyverse\n",
    "text": "Subsetting Spalten: Tidyverse\n\n\nathletes %&gt;%\n  select(Year, Sport) %&gt;%\n  head\n\n  Year     Sport\n1 1956    Hockey\n2 1948    Hockey\n3 1980 Wrestling\n4 1956    Hockey\n5 1964 Wrestling\n6 1960 Wrestling"
  },
  {
    "objectID": "slides/IntroR/introR.html#übung-3",
    "href": "slides/IntroR/introR.html#übung-3",
    "title": "Einführung in R",
    "section": "Übung",
    "text": "Übung\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übungen zum Subsetting."
  },
  {
    "objectID": "slides/IntroR/introR.html#sec-missings",
    "href": "slides/IntroR/introR.html#sec-missings",
    "title": "Einführung in R",
    "section": "Fehlende Werte",
    "text": "Fehlende Werte\n\nNA"
  },
  {
    "objectID": "slides/IntroR/introR.html#arbeit-mit-fehlenden-werten",
    "href": "slides/IntroR/introR.html#arbeit-mit-fehlenden-werten",
    "title": "Einführung in R",
    "section": "Arbeit mit fehlenden Werten",
    "text": "Arbeit mit fehlenden Werten\n\n\nNAs in der Spalte Weight auswählen:\n\n\nis.na(athletes$Weight)\n\n    [1]  TRUE  TRUE FALSE  TRUE FALSE FALSE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\n...\n\n\n\n\nNAs in der Spalte Weight beim Subsetting nicht beachten:\n\n\nathletes[(athletes$Sport == \"Judo\") & (athletes$Weight &gt; 100 | athletes$Weight &lt; 50) & !is.na(athletes$Weight), ]\n\n       NOC     ID                                 Name Sex Age Height Weight\n471    ALG  13895                  Mohamed Bouaichaoui   M  25    178  120.0\n673    ALG  82643                        Meriem Moussa   F  20    150   48.0\n..."
  },
  {
    "objectID": "slides/IntroR/introR.html#fehlende-werte-entfernen",
    "href": "slides/IntroR/introR.html#fehlende-werte-entfernen",
    "title": "Einführung in R",
    "section": "Fehlende Werte entfernen",
    "text": "Fehlende Werte entfernen\n\nathletes_na &lt;- athletes[!is.na(athletes$Weight), ]\nhead(athletes_na)\n\n   NOC     ID                 Name Sex Age Height Weight        Team\n3  AFG  44977    Mohammad Halilula   M  28    163     57 Afghanistan\n5  AFG 109153   Shakar Khan Shakar   M  24     NA     74 Afghanistan\n...\n\n\n\n## tidyverse:\nathletes_na &lt;- athletes %&gt;%\n  drop_na(Weight)\nhead(athletes_na)\n\n  NOC     ID                 Name Sex Age Height Weight        Team       Games\n1 AFG  44977    Mohammad Halilula   M  28    163     57 Afghanistan 1980 Summer\n2 AFG 109153   Shakar Khan Shakar   M  24     NA     74 Afghanistan 1964 Summer\n...\n\n\nBeides entfernt alle Zeilen, die in der Spalte Weight ein NA haben."
  },
  {
    "objectID": "slides/IntroR/introR.html#section-8",
    "href": "slides/IntroR/introR.html#section-8",
    "title": "Einführung in R",
    "section": "",
    "text": "Reshaping"
  },
  {
    "objectID": "slides/IntroR/introR.html#wide-format",
    "href": "slides/IntroR/introR.html#wide-format",
    "title": "Einführung in R",
    "section": "Wide-Format",
    "text": "Wide-Format\n\ninhabitants_wide &lt;- data.frame(\n  country = c(\"China\", \"India\", \"USA\"),\n  inhabitants_2021 = c(1425893465 , 1407563842, NA),\n  inhabitants_2022 = c(1425857720, 1420939232, 338903174)\n)\n\nhead(inhabitants_wide)\n\n  country inhabitants_2021 inhabitants_2022\n1   China       1425893465       1425857720\n2   India       1407563842       1420939232\n3     USA               NA        338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#long-format",
    "href": "slides/IntroR/introR.html#long-format",
    "title": "Einführung in R",
    "section": "Long-Format",
    "text": "Long-Format\n\n\n  country         variable      value\n1   China             area    9597000\n2   China inhabitants_2022 1425857720\n3   India             area    3287000\n4   India inhabitants_2022 1420939232\n5     USA             area    9834000\n6     USA inhabitants_2022  338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#von-wide-zu-long",
    "href": "slides/IntroR/introR.html#von-wide-zu-long",
    "title": "Einführung in R",
    "section": "Von Wide zu Long",
    "text": "Von Wide zu Long\n\ninhabitants_long_2 &lt;- inhabitants_wide %&gt;%\n  pivot_longer(\n    ## Spalten die gereshaped werden sollen\n    cols = c(\"inhabitants_2022\", \"inhabitants_2021\"),\n    ## Neue Spalte, in der die bisherigen Spaltennamen gespeichert werden\n    names_to = \"year\",\n    ## Neue Spalte, in der die bisherigen Werte gespeichert werden\n    values_to = \"inhabitants\"\n  )\n\nhead(inhabitants_long)\n\n  country         variable      value\n1   China             area    9597000\n2   China inhabitants_2022 1425857720\n3   India             area    3287000\n4   India inhabitants_2022 1420939232\n5     USA             area    9834000\n6     USA inhabitants_2022  338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#von-long-zu-wide",
    "href": "slides/IntroR/introR.html#von-long-zu-wide",
    "title": "Einführung in R",
    "section": "Von Long zu Wide",
    "text": "Von Long zu Wide\n\ninhabitants_wide_2 &lt;- inhabitants_long %&gt;%\n  pivot_wider(\n    id_cols = \"country\",\n    names_from = \"variable\",\n    values_from = \"value\"\n  )\n\nhead(inhabitants_wide_2)\n\n# A tibble: 3 × 3\n  country    area inhabitants_2022\n  &lt;chr&gt;     &lt;dbl&gt;            &lt;dbl&gt;\n1 China   9597000       1425857720\n2 India   3287000       1420939232\n3 USA     9834000        338903174"
  },
  {
    "objectID": "slides/IntroR/introR.html#übung-5",
    "href": "slides/IntroR/introR.html#übung-5",
    "title": "Einführung in R",
    "section": "Übung",
    "text": "Übung\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übung zum Reshaping."
  },
  {
    "objectID": "slides/IntroR/introR.html#merging",
    "href": "slides/IntroR/introR.html#merging",
    "title": "Einführung in R",
    "section": "Merging",
    "text": "Merging\n\n\nVorbereitung\nZuerst müssen wir die Daten laden und für das Beispiel vorbereiten.\n\nworld_coordinates &lt;- readRDS(file = here::here(\"raw_data\", \"world_coordinates.rds\"))\n\n## Count the number of gold medal winners in each country\nmedal_counts &lt;- athletes %&gt;%\n  filter(Medal == \"Gold\") %&gt;%\n  group_by(Region) %&gt;%\n  count(Medal) \n\nmedal_counts\n\n# A tibble: 99 × 3\n# Groups:   Region [99]\n   Region     Medal     n\n..."
  },
  {
    "objectID": "slides/IntroR/introR.html#merging-1",
    "href": "slides/IntroR/introR.html#merging-1",
    "title": "Einführung in R",
    "section": "Merging",
    "text": "Merging\nSchaue dir die Dokumentation von merge an für Infos zu den Argumenten.\n\nmedal_countries &lt;- merge(\n  x = medal_counts,\n  y = world_coordinates,\n  by.x = \"Region\",\n  by.y = \"region\",\n  all.x = FALSE,\n  all.y = TRUE\n)\n\nhead(medal_countries)\n\n       Region Medal  n     long      lat group order subregion\n1 Afghanistan  &lt;NA&gt; NA 74.89131 37.23164     2    12      &lt;NA&gt;\n2 Afghanistan  &lt;NA&gt; NA 74.84023 37.22505     2    13      &lt;NA&gt;\n3 Afghanistan  &lt;NA&gt; NA 74.76738 37.24917     2    14      &lt;NA&gt;\n4 Afghanistan  &lt;NA&gt; NA 74.73896 37.28564     2    15      &lt;NA&gt;\n5 Afghanistan  &lt;NA&gt; NA 74.72666 37.29072     2    16      &lt;NA&gt;\n6 Afghanistan  &lt;NA&gt; NA 74.66895 37.26670     2    17      &lt;NA&gt;"
  },
  {
    "objectID": "slides/IntroR/introR.html#merging-im-tidyverse",
    "href": "slides/IntroR/introR.html#merging-im-tidyverse",
    "title": "Einführung in R",
    "section": "Merging im tidyverse\n",
    "text": "Merging im tidyverse\n\n\nmedal_countries &lt;- world_coordinates %&gt;%\n  left_join(medal_counts, join_by(region == Region))\nhead(medal_countries)\n\n       long      lat group order region subregion Medal  n\n1 -69.89912 12.45200     1     1  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n2 -69.89571 12.42300     1     2  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n3 -69.94219 12.43853     1     3  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n4 -70.00415 12.50049     1     4  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n5 -70.06612 12.54697     1     5  Aruba      &lt;NA&gt;  &lt;NA&gt; NA\n6 -70.05088 12.59707     1     6  Aruba      &lt;NA&gt;  &lt;NA&gt; NA"
  },
  {
    "objectID": "slides/IntroR/introR.html#übung-7",
    "href": "slides/IntroR/introR.html#übung-7",
    "title": "Einführung in R",
    "section": "Übung",
    "text": "Übung\n\n\n\n\n\n\nÜbung\n\n\nBitte bearbeite die Übung zum Merging."
  },
  {
    "objectID": "slides/IntroR/introR.html#funktionen",
    "href": "slides/IntroR/introR.html#funktionen",
    "title": "Einführung in R",
    "section": "Funktionen",
    "text": "Funktionen"
  },
  {
    "objectID": "slides/IntroR/introR.html#basics",
    "href": "slides/IntroR/introR.html#basics",
    "title": "Einführung in R",
    "section": "Basics",
    "text": "Basics\n\nfunction_name &lt;- function(argument_1, argument_2, ...){\n  result &lt;- argument_1 + argument_2\n  return(result)\n}\n\nMotivation\n\nAlles was etwas in R tut ist eine Funktion.\nSuperhilfreich, sich eigene Funktionen zu schreiben, weil das eine Menge Code-Duplikationen vermeidet (und die sind schlecht)."
  },
  {
    "objectID": "slides/IntroR/introR.html#beispiel",
    "href": "slides/IntroR/introR.html#beispiel",
    "title": "Einführung in R",
    "section": "Beispiel",
    "text": "Beispiel\n\nsum_num &lt;- function(x, y, z = 0){\n  result &lt;- x + y + z\n  return(result)\n}\n\nsum_num(x = 1, y = 1, z = 2)\n\n[1] 4\n\nsum_num(x = 1, y = 1)\n\n[1] 2"
  },
  {
    "objectID": "slides/IntroR/introR.html#bildquellen",
    "href": "slides/IntroR/introR.html#bildquellen",
    "title": "Einführung in R",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Mohammad Rahmani auf Unsplash\n\nFoto von Adi Goldstein auf Unsplash\n\nIcons from icons8.de."
  },
  {
    "objectID": "slides/IntroR/introR.html#bildquellen-1",
    "href": "slides/IntroR/introR.html#bildquellen-1",
    "title": "Einführung in R",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von elnaz asadi auf Unsplash\n\nFoto von Mika Baumeister auf Unsplash\n\nhttps://upload.wikimedia.org/wikipedia/commons/f/ff/Tidyverse_hex_logo.png\nhttps://raw.githubusercontent.com/allisonhorst/stats-illustrations/master/rstats-artwork/here.png\nFoto von Suzanne D. Williams auf Unsplash"
  },
  {
    "objectID": "slides/IntroR/introR.html#bildquellen-2",
    "href": "slides/IntroR/introR.html#bildquellen-2",
    "title": "Einführung in R",
    "section": "Bildquellen",
    "text": "Bildquellen\n\nFoto von Zoe Holling auf Unsplash\n\nFoto von Steinar Engeland auf Unsplash\n\nFoto von Muhil Mohan auf Unsplash"
  }
]