[
  {
    "objectID": "exercises/Vorraussetzungen.html",
    "href": "exercises/Vorraussetzungen.html",
    "title": "IRT Voraussetzungen",
    "section": "",
    "text": "Wir schauen uns eine ganz simple Version an. Wer interessiert ist, und z.B. Daten für eine Poweranalyse simulieren möchte, findet hier Unterstützung. Installieren und/oder lade folgende Pakete für diese Übung:\n\n## Wenn noch nicht installiert:\n# install.packages(\"tidyverse\")\n# install.packages(\"TAM\")\n\nlibrary(tidyverse)\nlibrary(TAM)\n\n\nZuerst müssen wir festlegen, was wir eigentlich simulieren wollen. Wir starten mit einem 2PL Modell. Wie sah die Gleichung dafür noch einmal aus?\n\\[\nP(X_{is} = 1|\\theta_s,\\beta_i,\\alpha_i) = \\frac{\\exp(\\alpha_i(\\theta_s-\\beta_i))}{1 + \\exp(a_i (\\theta_s - \\beta_i))}\n\\tag{1}\\]\n\nVersuche noch einmal, alle Elemente von Gleichung 1 für dich selbst zu erklären.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir versuchen zu schätzen wie hoch die Wahrscheinlichkeit ist, dass eine Person \\(s\\) ein Item \\(i\\) richtig (\\(X_{is} = 1\\)) beantwortet. Dazu nutzen wir den Diskriminationsparameter \\(\\alpha_i\\) und den Schwierigkeitsparameter \\(\\beta_i\\) von Item \\(i\\) und die Personenfähigkeit \\(\\theta_s\\) von Person \\(s\\).\n\n\n\n\n\nJetzt beginnt der fun part: Schreibe eine Funktion genannt calc_2pl die Gleichung 1 in R Code umsetzt.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nDer Aufbau der Funktion könnte so aussehen:\n\ncalc_2pl &lt;- function(alpha, theta, beta){\n}\n\nBefülle sie nun mit Gleichung 1. alpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Diese Werte können dann im Funktionskörper (zwischen {}) genutzt werden, um Gleichung 1 in R Code zu übersetzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nalpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Im Funktionskörper (zwischen {}) werden sie genutzt, um \\(p\\) anhand von Gleichung 1 zu berechnen.\n\n\n\n\nJetzt geht’s los! Wir wollen nun eigene Daten simulieren. Das tolle ist: wir können so alle Aspekte selber festlegen, und daran untersuchen, wie sich das Variieren von bestimmten Parametern auf das Ergebnis auswirkt.\n\n\nZuerst die Items. Baue einen data.frame mit dem Namen items. Er soll 13 Zeilen und 4 Spalten haben und folgendes enthalten:\n\n\n\nitem_id: Die ID des Items, von 1 bis 13.\n\nalpha: Die Diskriminationsparameter, liegen zwischen 0.5 und 1.5 in 13 gleich langen Schritten.\n\nbeta: Die Schwierigkeitsparameter, liegen zwischen -3 und 3 jeweils im Abstand von 0.5.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDie Funktion seq() ist dein Freund. Mehr brauchst du nicht, um die Zahlenreihen zu erzeugen. Schaue dir die Dokumentation an.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 1.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nDas sind also die Itemparameter, die wir in unsere Simulation packen.\n\n\n\n\nJetzt können wir die Personen simulieren. Unser Ziel ist also ein data.frame, der \\(\\theta\\) Werte für die untersuchten Personen enthält. Wir simulieren 100000 Personen, der data.frame sollte also 100000 Zeilen haben. Außerdem benötigen wir zwei Spalten:\n\n\n\nID: Die ID der Person, von 1 bis 100000.\n\ntheta: Die Fähigkeit der Person, die wir simulieren. Wir nehmen an, dass die Fähigkeit normalverteilt ist, mit einem Mittelwert von 0 und einer Standardabweichung von 1.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWir können zufällige Daten aus einer Normalverteilung mit Hilfe der Funktion rnorm() ziehen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(666) \n## Ich setzte hier einen Seed, damit meine zufällig erzeugten Werte replizierbar bleiben.\n## Wenn du den Seed in deinem Skript auf die gleiche Zahl setzt, bekommst du genau die gleichen Zufallswerte und kannst besser vergleichen. \n\n\nsubjects &lt;- data.frame(\n    sub_id = 1:100000,\n    theta = c(rnorm(100000, 0, 1))\n)\n\n\n\n\nPerfekt! Jetzt können wir die Itemantworten simulieren. Dazu sind noch ein paar kleine Schritte nötig:\n\nMerge die beiden data.frames subjects und items zu einem neuen data.frame sim_dat zusammen. Und zwar so, dass wir \\(1000 * 13\\) Zeilen bekommen, also jede Person jedes der 13 Items zugeordnet wird (bisher noch ohne Antwort der Person, nur mit den Itemkennwerten. Das erleichtert uns im nächsten Schritt, die Antworten der Personen zu simulieren).\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNutze die Funktion merge() ohne irgendwelche weiteren Argumente.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- merge(subjects, items)\n\n## Wir schauen mal, ob das hinkommt:\n\nstr(sim_dat)\n\n'data.frame':   1300000 obs. of  6 variables:\n $ sub_id : int  1 2 3 4 5 6 7 8 9 10 ...\n $ theta  : num  0.753 2.014 -0.355 2.028 -2.217 ...\n $ item_id: int  1 1 1 1 1 1 1 1 1 1 ...\n $ b      : num  -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 ...\n $ a      : num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n $ c      : num  0 0 0 0 0 0 0 0 0 0 ...\n\n\nUnser finaler data.frame hat 1300000 Zeilen, wie verlangt. Lasst uns auch noch einmal schauen, ob eine zufällige Person alle Items beantwortet hat:\n\nsim_dat %&gt;%\n  filter(sub_id == 420) %&gt;%\n  pull(item_id)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n\nDas sieht gut aus!\n\n\n\n\nJetzt simulieren wir aus diesem Vorbereiteten data.frame die Antworten der Personen, abhängig von ihren Fähigkeiten \\(\\theta\\) (jede Person hat hier einen zufälligen Wert aus einer Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 1\\) bekommen) und den Itemparametern \\(\\alpha\\) und \\(\\beta\\) (die hatten wir einfach als Sequenz festgelegt). Lege eine neue Spalte p in sim_dat an, die für jede Person die Wahrscheinlichkeit enthält, dass sie das jeweilige Item richtig beantwortet. Dafür brauchen wir jetzt unsere Funktion calc_2pl, die wir am Anfang definiert haben! Diese nimmt aus jeder Zeile den theta, alpha und beta Wert als input, und berechnet daraus die Wahrscheinlichkeit, dass die Person das Item richtig beantwortet.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSupereinfach geht das ganze mit der mutate() Funktion aus dem tidyverse.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(p = calc_2pl(a, theta, b))\n\n## Mal nachschauen:\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p\n1      1  0.7533110       1 -3 0.5 0 0.8672265\n2      2  2.0143547       1 -3 0.5 0 0.9246434\n3      3 -0.3551345       1 -3 0.5 0 0.7895862\n4      4  2.0281678       1 -3 0.5 0 0.9251233\n5      5 -2.2168745       1 -3 0.5 0 0.5966588\n6      6  0.7583962       1 -3 0.5 0 0.8675190\n\n\nAuf den ersten Blick sieht das schonmal gut aus. Personen mit niedrigerem \\(\\theta\\) Wert haben auch eine geringere Wahrscheinlichkeit, das Item richtig zu beantworten (vgl. z.B. Zeile 2 und 3).\n\n\n\n\nJetzt sind wir auch schon fast am Ende. Wir müssen lediglich aus den Wahrscheinlichkeiten die tatsächlichen Antworten der Personen simulieren. Nutze die Berechneten Antwortwahrscheinlichkeiten p, um für jede Person und jedes Item einen Wert aus einer Bernoulliverteilung zu ziehen.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEine Bernoulliverteilung ist eine Binomialverteilung mit nur einem Versuch. Wir können daher die Funktion rbinom() nutzen, und das size-Argument auf 1 setzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p answer\n1      1  0.7533110       1 -3 0.5 0 0.8672265      1\n2      2  2.0143547       1 -3 0.5 0 0.9246434      1\n3      3 -0.3551345       1 -3 0.5 0 0.7895862      0\n4      4  2.0281678       1 -3 0.5 0 0.9251233      1\n5      5 -2.2168745       1 -3 0.5 0 0.5966588      1\n6      6  0.7583962       1 -3 0.5 0 0.8675190      1\n\n\nAuch das sieht erst einmal plausibel aus! Toll!\n\n\n\n\nJetzt wollen wir natürlich noch schauen, ob das Ganze so funktioniert hat, wie wir uns das vorgestellt haben. Wir wollen das TAM Paket, um ein 2PL Modell auf die Itemantworten zu fitten. Wenn alles geklappt hat, sollten wir in etwa unsere Itemparameter wiedererkennen.\n\nZuerst müssen wir unsere Daten dafür noch ein bisschen aufbereiten, sprich ins Wide-Format bringen. Probiere das also mal aus!\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIch nutze dafür immer deutlich lieber die tidyverse Funktion pivot_wider() als die base-R Funtkion reshape().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = sub_id)\n\nhead(sim_dat_wide)\n\n# A tibble: 6 × 14\n  sub_id   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`  `10`  `11`  `12`\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1      1     1     1     1     1     1     0     1     0     1     1     0     0\n2      2     1     1     1     1     1     1     1     1     1     1     1     0\n3      3     0     1     1     1     0     0     0     0     0     1     0     0\n4      4     1     1     1     1     1     1     1     1     0     0     0     0\n5      5     1     1     0     1     0     0     0     0     0     0     0     0\n6      6     1     1     0     1     1     1     0     0     0     0     0     0\n# ℹ 1 more variable: `13` &lt;int&gt;\n\n\nDie Spaltennamen sind jetzt unsere Item-Nummern. Pro Zeile finden sich die Antworten der Personen, entweder hat sie das entsprechende Item richtig (1) oder falsch (0) beantwortet.\n\n\n\n\nJetzt können wir das Modell fitten. Nutze dafür wie angekündigt das TAM Paket, und entferne noch die Spalte sub_id, wir geben nur die Itemantworten in die Funktion. Speichere den Funktionsoutput in dem Object sim_dat_2PL.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWir brauchen die Funktion tam.mml.2pl().\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsim_dat_2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"2PL\")\n\n....................................................\nProcessing Data      2024-09-20 19:22:33.137996 \n    * Response Data: 100000 Persons and  13 Items \n    * Numerical integration with 21 nodes\n    * Created Design Matrices   ( 2024-09-20 19:22:33.196433 )\n    * Calculated Sufficient Statistics   ( 2024-09-20 19:22:33.296772 )\n....................................................\nIteration 1     2024-09-20 19:22:33.335009\nE Step\nM Step Intercepts   |----\nM Step Slopes       |---\n  Deviance = 1267150.8426\n  Maximum item intercept parameter change: 0.419556\n  Maximum item slope parameter change: 0.209449\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 2     2024-09-20 19:22:33.550578\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1256572.3453 | Absolute change: 10578.5 | Relative change: 0.00841853\n  Maximum item intercept parameter change: 0.142116\n  Maximum item slope parameter change: 0.13129\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 3     2024-09-20 19:22:33.766566\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1255075.8194 | Absolute change: 1496.526 | Relative change: 0.00119238\n  Maximum item intercept parameter change: 0.085173\n  Maximum item slope parameter change: 0.070548\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 4     2024-09-20 19:22:33.952976\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254560.5132 | Absolute change: 515.3062 | Relative change: 0.00041075\n  Maximum item intercept parameter change: 0.064561\n  Maximum item slope parameter change: 0.041601\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 5     2024-09-20 19:22:34.071733\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254359.2843 | Absolute change: 201.2289 | Relative change: 0.00016042\n  Maximum item intercept parameter change: 0.050987\n  Maximum item slope parameter change: 0.030886\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 6     2024-09-20 19:22:34.202771\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254269.9949 | Absolute change: 89.2894 | Relative change: 7.119e-05\n  Maximum item intercept parameter change: 0.04019\n  Maximum item slope parameter change: 0.023359\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 7     2024-09-20 19:22:34.432925\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254226.1047 | Absolute change: 43.8902 | Relative change: 3.499e-05\n  Maximum item intercept parameter change: 0.031482\n  Maximum item slope parameter change: 0.017898\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 8     2024-09-20 19:22:34.540102\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254203.2462 | Absolute change: 22.8585 | Relative change: 1.823e-05\n  Maximum item intercept parameter change: 0.02456\n  Maximum item slope parameter change: 0.013847\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 9     2024-09-20 19:22:34.658156\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254191.0072 | Absolute change: 12.239 | Relative change: 9.76e-06\n  Maximum item intercept parameter change: 0.019126\n  Maximum item slope parameter change: 0.01079\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 10     2024-09-20 19:22:34.791916\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254184.3636 | Absolute change: 6.6436 | Relative change: 5.3e-06\n  Maximum item intercept parameter change: 0.014893\n  Maximum item slope parameter change: 0.008455\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 11     2024-09-20 19:22:34.886319\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254180.7248 | Absolute change: 3.6388 | Relative change: 2.9e-06\n  Maximum item intercept parameter change: 0.011608\n  Maximum item slope parameter change: 0.006653\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 12     2024-09-20 19:22:35.104815\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254178.7154 | Absolute change: 2.0093 | Relative change: 1.6e-06\n  Maximum item intercept parameter change: 0.009062\n  Maximum item slope parameter change: 0.005253\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 13     2024-09-20 19:22:35.1993\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254177.5963 | Absolute change: 1.1192 | Relative change: 8.9e-07\n  Maximum item intercept parameter change: 0.007088\n  Maximum item slope parameter change: 0.004157\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 14     2024-09-20 19:22:35.316946\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.967 | Absolute change: 0.6293 | Relative change: 5e-07\n  Maximum item intercept parameter change: 0.005555\n  Maximum item slope parameter change: 0.003297\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 15     2024-09-20 19:22:35.450535\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.6097 | Absolute change: 0.3573 | Relative change: 2.8e-07\n  Maximum item intercept parameter change: 0.004363\n  Maximum item slope parameter change: 0.002619\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 16     2024-09-20 19:22:35.544827\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.4047 | Absolute change: 0.205 | Relative change: 1.6e-07\n  Maximum item intercept parameter change: 0.003433\n  Maximum item slope parameter change: 0.002083\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 17     2024-09-20 19:22:35.671092\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.286 | Absolute change: 0.1188 | Relative change: 9e-08\n  Maximum item intercept parameter change: 0.002706\n  Maximum item slope parameter change: 0.001658\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 18     2024-09-20 19:22:35.801812\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.2165 | Absolute change: 0.0695 | Relative change: 6e-08\n  Maximum item intercept parameter change: 0.002137\n  Maximum item slope parameter change: 0.001321\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 19     2024-09-20 19:22:36.004565\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1755 | Absolute change: 0.041 | Relative change: 3e-08\n  Maximum item intercept parameter change: 0.00169\n  Maximum item slope parameter change: 0.001053\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 20     2024-09-20 19:22:36.099653\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1511 | Absolute change: 0.0244 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.001338\n  Maximum item slope parameter change: 0.00084\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 21     2024-09-20 19:22:36.21282\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1364 | Absolute change: 0.0146 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.001061\n  Maximum item slope parameter change: 0.00067\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 22     2024-09-20 19:22:36.325525\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1276 | Absolute change: 0.0088 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000842\n  Maximum item slope parameter change: 0.000535\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 23     2024-09-20 19:22:36.438725\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1222 | Absolute change: 0.0054 | Relative change: 0\n  Maximum item intercept parameter change: 0.000669\n  Maximum item slope parameter change: 0.000427\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 24     2024-09-20 19:22:36.55673\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1189 | Absolute change: 0.0033 | Relative change: 0\n  Maximum item intercept parameter change: 0.000532\n  Maximum item slope parameter change: 0.000341\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 25     2024-09-20 19:22:36.66921\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1169 | Absolute change: 0.002 | Relative change: 0\n  Maximum item intercept parameter change: 0.000423\n  Maximum item slope parameter change: 0.000272\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 26     2024-09-20 19:22:36.781784\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1156 | Absolute change: 0.0012 | Relative change: 0\n  Maximum item intercept parameter change: 0.000337\n  Maximum item slope parameter change: 0.000218\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 27     2024-09-20 19:22:36.964662\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1149 | Absolute change: 8e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000268\n  Maximum item slope parameter change: 0.000174\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 28     2024-09-20 19:22:37.077341\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1144 | Absolute change: 5e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000214\n  Maximum item slope parameter change: 0.000139\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 29     2024-09-20 19:22:37.171724\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1141 | Absolute change: 3e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.00017\n  Maximum item slope parameter change: 0.000111\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 30     2024-09-20 19:22:37.283681\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1139 | Absolute change: 2e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000136\n  Maximum item slope parameter change: 8.9e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 31     2024-09-20 19:22:37.395682\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1138 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000108\n  Maximum item slope parameter change: 7.1e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 32     2024-09-20 19:22:37.509831\nE Step\nM Step Intercepts   |-\nM Step Slopes       |-\n  Deviance = 1254176.1137 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 8.6e-05\n  Maximum item slope parameter change: 5.7e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nItem Parameters\n   xsi.index xsi.label     est\n1          1         1 -1.5085\n2          2         2 -1.4816\n3          3         3 -1.3370\n4          4         4 -1.1347\n5          5         5 -0.8444\n6          6         6 -0.4600\n7          7         7 -0.0038\n8          8         8  0.5308\n9          9         9  1.1642\n10        10        10  1.8783\n11        11        11  2.6740\n12        12        12  3.4901\n13        13        13  4.4630\n...................................\nRegression Coefficients\n     [,1]\n[1,]    0\n\nVariance:\n     [,1]\n[1,]    1\n\n\nEAP Reliability:\n[1] 0.626\n\n-----------------------------\nStart:  2024-09-20 19:22:33.134783\nEnd:  2024-09-20 19:22:37.867532 \nTime difference of 4.732749 secs\n\n\n\n\n\n\nSchau dir die Itemparameter an, die das Modell geschätzt hat. Sie finden sich unter sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")]. Vergleiche mit den ursprünglichen Itemparametern, die wir in items festgelegt haben. Was fällt dir auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems_2pl &lt;- apply(sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\nitem_comparison &lt;- cbind(items_2pl, items[, c(\"a\", \"b\")])\n\nitem_comparison\n\n   alpha  beta         a    b\n1   0.52 -2.92 0.5000000 -3.0\n2   0.59 -2.53 0.5833333 -2.5\n3   0.66 -2.04 0.6666667 -2.0\n4   0.75 -1.52 0.7500000 -1.5\n5   0.84 -1.01 0.8333333 -1.0\n6   0.92 -0.50 0.9166667 -0.5\n7   1.00  0.00 1.0000000  0.0\n8   1.09  0.49 1.0833333  0.5\n9   1.17  1.00 1.1666667  1.0\n10  1.24  1.52 1.2500000  1.5\n11  1.35  1.97 1.3333333  2.0\n12  1.38  2.52 1.4166667  2.5\n13  1.47  3.03 1.5000000  3.0\n\n\n\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nggplot(data=item_comparison, \n       aes(x = b, y = beta)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() + ## Ein anderes Theme festlegen\n  xlab(TeX(\"\\\\beta\")) + ## Latex Syntax für die Achsenbeschriftung nutzen\n  ylab(TeX(\"\\\\hat{\\\\beta}\"))\n\n\n\n\n\n\n\n\nggplot(data=item_comparison, \n       aes(x = a, y = alpha)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() +\n  xlab(TeX(\"\\\\alpha\")) +\n  ylab(TeX(\"\\\\hat{\\\\alpha}\"))\n\n\n\n\n\n\n\nDas sieht super aus, die Werte stimmen gut überein. Dadurch, dass wir so viele Personen simuliert haben, sehen wir also, dass unsere Simulation gut funktioniert. Wir können das Gerüst dieses Simplen Modells jetzt nutzen, um uns noch spannendere Fragestellungen anzuschauen."
  },
  {
    "objectID": "exercises/Vorraussetzungen.html#gleichung",
    "href": "exercises/Vorraussetzungen.html#gleichung",
    "title": "IRT Voraussetzungen",
    "section": "",
    "text": "Zuerst müssen wir festlegen, was wir eigentlich simulieren wollen. Wir starten mit einem 2PL Modell. Wie sah die Gleichung dafür noch einmal aus?\n\\[\nP(X_{is} = 1|\\theta_s,\\beta_i,\\alpha_i) = \\frac{\\exp(\\alpha_i(\\theta_s-\\beta_i))}{1 + \\exp(a_i (\\theta_s - \\beta_i))}\n\\tag{1}\\]\n\nVersuche noch einmal, alle Elemente von Gleichung 1 für dich selbst zu erklären.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nWir versuchen zu schätzen wie hoch die Wahrscheinlichkeit ist, dass eine Person \\(s\\) ein Item \\(i\\) richtig (\\(X_{is} = 1\\)) beantwortet. Dazu nutzen wir den Diskriminationsparameter \\(\\alpha_i\\) und den Schwierigkeitsparameter \\(\\beta_i\\) von Item \\(i\\) und die Personenfähigkeit \\(\\theta_s\\) von Person \\(s\\)."
  },
  {
    "objectID": "exercises/Vorraussetzungen.html#pl-funktion",
    "href": "exercises/Vorraussetzungen.html#pl-funktion",
    "title": "IRT Voraussetzungen",
    "section": "",
    "text": "Jetzt beginnt der fun part: Schreibe eine Funktion genannt calc_2pl die Gleichung 1 in R Code umsetzt.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nDer Aufbau der Funktion könnte so aussehen:\n\ncalc_2pl &lt;- function(alpha, theta, beta){\n}\n\nBefülle sie nun mit Gleichung 1. alpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Diese Werte können dann im Funktionskörper (zwischen {}) genutzt werden, um Gleichung 1 in R Code zu übersetzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nalpha, theta und beta sind hier also die Funktionsargumente (weil sie innerhalb der Klammern von function() stehen), und müssen beim späteren Aufruf der Funktion von der nutzenden Person mit Werten befüllt werden. Im Funktionskörper (zwischen {}) werden sie genutzt, um \\(p\\) anhand von Gleichung 1 zu berechnen."
  },
  {
    "objectID": "exercises/Vorraussetzungen.html#simulieren-von-daten",
    "href": "exercises/Vorraussetzungen.html#simulieren-von-daten",
    "title": "IRT Voraussetzungen",
    "section": "",
    "text": "Jetzt geht’s los! Wir wollen nun eigene Daten simulieren. Das tolle ist: wir können so alle Aspekte selber festlegen, und daran untersuchen, wie sich das Variieren von bestimmten Parametern auf das Ergebnis auswirkt.\n\n\nZuerst die Items. Baue einen data.frame mit dem Namen items. Er soll 13 Zeilen und 4 Spalten haben und folgendes enthalten:\n\n\n\nitem_id: Die ID des Items, von 1 bis 13.\n\nalpha: Die Diskriminationsparameter, liegen zwischen 0.5 und 1.5 in 13 gleich langen Schritten.\n\nbeta: Die Schwierigkeitsparameter, liegen zwischen -3 und 3 jeweils im Abstand von 0.5.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nDie Funktion seq() ist dein Freund. Mehr brauchst du nicht, um die Zahlenreihen zu erzeugen. Schaue dir die Dokumentation an.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 1.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nDas sind also die Itemparameter, die wir in unsere Simulation packen.\n\n\n\n\nJetzt können wir die Personen simulieren. Unser Ziel ist also ein data.frame, der \\(\\theta\\) Werte für die untersuchten Personen enthält. Wir simulieren 100000 Personen, der data.frame sollte also 100000 Zeilen haben. Außerdem benötigen wir zwei Spalten:\n\n\n\nID: Die ID der Person, von 1 bis 100000.\n\ntheta: Die Fähigkeit der Person, die wir simulieren. Wir nehmen an, dass die Fähigkeit normalverteilt ist, mit einem Mittelwert von 0 und einer Standardabweichung von 1.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nWir können zufällige Daten aus einer Normalverteilung mit Hilfe der Funktion rnorm() ziehen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nset.seed(666) \n## Ich setzte hier einen Seed, damit meine zufällig erzeugten Werte replizierbar bleiben.\n## Wenn du den Seed in deinem Skript auf die gleiche Zahl setzt, bekommst du genau die gleichen Zufallswerte und kannst besser vergleichen. \n\n\nsubjects &lt;- data.frame(\n    sub_id = 1:100000,\n    theta = c(rnorm(100000, 0, 1))\n)\n\n\n\n\nPerfekt! Jetzt können wir die Itemantworten simulieren. Dazu sind noch ein paar kleine Schritte nötig:\n\nMerge die beiden data.frames subjects und items zu einem neuen data.frame sim_dat zusammen. Und zwar so, dass wir \\(1000 * 13\\) Zeilen bekommen, also jede Person jedes der 13 Items zugeordnet wird (bisher noch ohne Antwort der Person, nur mit den Itemkennwerten. Das erleichtert uns im nächsten Schritt, die Antworten der Personen zu simulieren).\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nNutze die Funktion merge() ohne irgendwelche weiteren Argumente.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- merge(subjects, items)\n\n## Wir schauen mal, ob das hinkommt:\n\nstr(sim_dat)\n\n'data.frame':   1300000 obs. of  6 variables:\n $ sub_id : int  1 2 3 4 5 6 7 8 9 10 ...\n $ theta  : num  0.753 2.014 -0.355 2.028 -2.217 ...\n $ item_id: int  1 1 1 1 1 1 1 1 1 1 ...\n $ b      : num  -3 -3 -3 -3 -3 -3 -3 -3 -3 -3 ...\n $ a      : num  0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 ...\n $ c      : num  0 0 0 0 0 0 0 0 0 0 ...\n\n\nUnser finaler data.frame hat 1300000 Zeilen, wie verlangt. Lasst uns auch noch einmal schauen, ob eine zufällige Person alle Items beantwortet hat:\n\nsim_dat %&gt;%\n  filter(sub_id == 420) %&gt;%\n  pull(item_id)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13\n\n\nDas sieht gut aus!\n\n\n\n\nJetzt simulieren wir aus diesem Vorbereiteten data.frame die Antworten der Personen, abhängig von ihren Fähigkeiten \\(\\theta\\) (jede Person hat hier einen zufälligen Wert aus einer Normalverteilung mit \\(\\mu = 1\\) und \\(\\sigma = 1\\) bekommen) und den Itemparametern \\(\\alpha\\) und \\(\\beta\\) (die hatten wir einfach als Sequenz festgelegt). Lege eine neue Spalte p in sim_dat an, die für jede Person die Wahrscheinlichkeit enthält, dass sie das jeweilige Item richtig beantwortet. Dafür brauchen wir jetzt unsere Funktion calc_2pl, die wir am Anfang definiert haben! Diese nimmt aus jeder Zeile den theta, alpha und beta Wert als input, und berechnet daraus die Wahrscheinlichkeit, dass die Person das Item richtig beantwortet.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nSupereinfach geht das ganze mit der mutate() Funktion aus dem tidyverse.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(p = calc_2pl(a, theta, b))\n\n## Mal nachschauen:\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p\n1      1  0.7533110       1 -3 0.5 0 0.8672265\n2      2  2.0143547       1 -3 0.5 0 0.9246434\n3      3 -0.3551345       1 -3 0.5 0 0.7895862\n4      4  2.0281678       1 -3 0.5 0 0.9251233\n5      5 -2.2168745       1 -3 0.5 0 0.5966588\n6      6  0.7583962       1 -3 0.5 0 0.8675190\n\n\nAuf den ersten Blick sieht das schonmal gut aus. Personen mit niedrigerem \\(\\theta\\) Wert haben auch eine geringere Wahrscheinlichkeit, das Item richtig zu beantworten (vgl. z.B. Zeile 2 und 3).\n\n\n\n\nJetzt sind wir auch schon fast am Ende. Wir müssen lediglich aus den Wahrscheinlichkeiten die tatsächlichen Antworten der Personen simulieren. Nutze die Berechneten Antwortwahrscheinlichkeiten p, um für jede Person und jedes Item einen Wert aus einer Bernoulliverteilung zu ziehen.\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nEine Bernoulliverteilung ist eine Binomialverteilung mit nur einem Versuch. Wir können daher die Funktion rbinom() nutzen, und das size-Argument auf 1 setzen.\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat &lt;- sim_dat %&gt;%\n  mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nhead(sim_dat)\n\n  sub_id      theta item_id  b   a c         p answer\n1      1  0.7533110       1 -3 0.5 0 0.8672265      1\n2      2  2.0143547       1 -3 0.5 0 0.9246434      1\n3      3 -0.3551345       1 -3 0.5 0 0.7895862      0\n4      4  2.0281678       1 -3 0.5 0 0.9251233      1\n5      5 -2.2168745       1 -3 0.5 0 0.5966588      1\n6      6  0.7583962       1 -3 0.5 0 0.8675190      1\n\n\nAuch das sieht erst einmal plausibel aus! Toll!\n\n\n\n\nJetzt wollen wir natürlich noch schauen, ob das Ganze so funktioniert hat, wie wir uns das vorgestellt haben. Wir wollen das TAM Paket, um ein 2PL Modell auf die Itemantworten zu fitten. Wenn alles geklappt hat, sollten wir in etwa unsere Itemparameter wiedererkennen.\n\nZuerst müssen wir unsere Daten dafür noch ein bisschen aufbereiten, sprich ins Wide-Format bringen. Probiere das also mal aus!\n\n\n\n\n\n\n\nTip\n\n\n\n\n\nIch nutze dafür immer deutlich lieber die tidyverse Funktion pivot_wider() als die base-R Funtkion reshape().\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = sub_id)\n\nhead(sim_dat_wide)\n\n# A tibble: 6 × 14\n  sub_id   `1`   `2`   `3`   `4`   `5`   `6`   `7`   `8`   `9`  `10`  `11`  `12`\n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1      1     1     1     1     1     1     0     1     0     1     1     0     0\n2      2     1     1     1     1     1     1     1     1     1     1     1     0\n3      3     0     1     1     1     0     0     0     0     0     1     0     0\n4      4     1     1     1     1     1     1     1     1     0     0     0     0\n5      5     1     1     0     1     0     0     0     0     0     0     0     0\n6      6     1     1     0     1     1     1     0     0     0     0     0     0\n# ℹ 1 more variable: `13` &lt;int&gt;\n\n\nDie Spaltennamen sind jetzt unsere Item-Nummern. Pro Zeile finden sich die Antworten der Personen, entweder hat sie das entsprechende Item richtig (1) oder falsch (0) beantwortet.\n\n\n\n\nJetzt können wir das Modell fitten. Nutze dafür wie angekündigt das TAM Paket, und entferne noch die Spalte sub_id, wir geben nur die Itemantworten in die Funktion. Speichere den Funktionsoutput in dem Object sim_dat_2PL.\n\n\n\n\n\n\n\nTipp\n\n\n\n\n\nWir brauchen die Funktion tam.mml.2pl().\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\n\n\nsim_dat_2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-sub_id), irtmodel = \"2PL\")\n\n....................................................\nProcessing Data      2024-09-20 19:22:33.137996 \n    * Response Data: 100000 Persons and  13 Items \n    * Numerical integration with 21 nodes\n    * Created Design Matrices   ( 2024-09-20 19:22:33.196433 )\n    * Calculated Sufficient Statistics   ( 2024-09-20 19:22:33.296772 )\n....................................................\nIteration 1     2024-09-20 19:22:33.335009\nE Step\nM Step Intercepts   |----\nM Step Slopes       |---\n  Deviance = 1267150.8426\n  Maximum item intercept parameter change: 0.419556\n  Maximum item slope parameter change: 0.209449\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 2     2024-09-20 19:22:33.550578\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1256572.3453 | Absolute change: 10578.5 | Relative change: 0.00841853\n  Maximum item intercept parameter change: 0.142116\n  Maximum item slope parameter change: 0.13129\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 3     2024-09-20 19:22:33.766566\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1255075.8194 | Absolute change: 1496.526 | Relative change: 0.00119238\n  Maximum item intercept parameter change: 0.085173\n  Maximum item slope parameter change: 0.070548\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 4     2024-09-20 19:22:33.952976\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254560.5132 | Absolute change: 515.3062 | Relative change: 0.00041075\n  Maximum item intercept parameter change: 0.064561\n  Maximum item slope parameter change: 0.041601\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 5     2024-09-20 19:22:34.071733\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254359.2843 | Absolute change: 201.2289 | Relative change: 0.00016042\n  Maximum item intercept parameter change: 0.050987\n  Maximum item slope parameter change: 0.030886\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 6     2024-09-20 19:22:34.202771\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254269.9949 | Absolute change: 89.2894 | Relative change: 7.119e-05\n  Maximum item intercept parameter change: 0.04019\n  Maximum item slope parameter change: 0.023359\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 7     2024-09-20 19:22:34.432925\nE Step\nM Step Intercepts   |---\nM Step Slopes       |---\n  Deviance = 1254226.1047 | Absolute change: 43.8902 | Relative change: 3.499e-05\n  Maximum item intercept parameter change: 0.031482\n  Maximum item slope parameter change: 0.017898\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 8     2024-09-20 19:22:34.540102\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254203.2462 | Absolute change: 22.8585 | Relative change: 1.823e-05\n  Maximum item intercept parameter change: 0.02456\n  Maximum item slope parameter change: 0.013847\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 9     2024-09-20 19:22:34.658156\nE Step\nM Step Intercepts   |---\nM Step Slopes       |--\n  Deviance = 1254191.0072 | Absolute change: 12.239 | Relative change: 9.76e-06\n  Maximum item intercept parameter change: 0.019126\n  Maximum item slope parameter change: 0.01079\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 10     2024-09-20 19:22:34.791916\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254184.3636 | Absolute change: 6.6436 | Relative change: 5.3e-06\n  Maximum item intercept parameter change: 0.014893\n  Maximum item slope parameter change: 0.008455\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 11     2024-09-20 19:22:34.886319\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254180.7248 | Absolute change: 3.6388 | Relative change: 2.9e-06\n  Maximum item intercept parameter change: 0.011608\n  Maximum item slope parameter change: 0.006653\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 12     2024-09-20 19:22:35.104815\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254178.7154 | Absolute change: 2.0093 | Relative change: 1.6e-06\n  Maximum item intercept parameter change: 0.009062\n  Maximum item slope parameter change: 0.005253\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 13     2024-09-20 19:22:35.1993\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254177.5963 | Absolute change: 1.1192 | Relative change: 8.9e-07\n  Maximum item intercept parameter change: 0.007088\n  Maximum item slope parameter change: 0.004157\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 14     2024-09-20 19:22:35.316946\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.967 | Absolute change: 0.6293 | Relative change: 5e-07\n  Maximum item intercept parameter change: 0.005555\n  Maximum item slope parameter change: 0.003297\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 15     2024-09-20 19:22:35.450535\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.6097 | Absolute change: 0.3573 | Relative change: 2.8e-07\n  Maximum item intercept parameter change: 0.004363\n  Maximum item slope parameter change: 0.002619\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 16     2024-09-20 19:22:35.544827\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.4047 | Absolute change: 0.205 | Relative change: 1.6e-07\n  Maximum item intercept parameter change: 0.003433\n  Maximum item slope parameter change: 0.002083\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 17     2024-09-20 19:22:35.671092\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.286 | Absolute change: 0.1188 | Relative change: 9e-08\n  Maximum item intercept parameter change: 0.002706\n  Maximum item slope parameter change: 0.001658\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 18     2024-09-20 19:22:35.801812\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.2165 | Absolute change: 0.0695 | Relative change: 6e-08\n  Maximum item intercept parameter change: 0.002137\n  Maximum item slope parameter change: 0.001321\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 19     2024-09-20 19:22:36.004565\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1755 | Absolute change: 0.041 | Relative change: 3e-08\n  Maximum item intercept parameter change: 0.00169\n  Maximum item slope parameter change: 0.001053\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 20     2024-09-20 19:22:36.099653\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1511 | Absolute change: 0.0244 | Relative change: 2e-08\n  Maximum item intercept parameter change: 0.001338\n  Maximum item slope parameter change: 0.00084\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 21     2024-09-20 19:22:36.21282\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1364 | Absolute change: 0.0146 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.001061\n  Maximum item slope parameter change: 0.00067\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 22     2024-09-20 19:22:36.325525\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1276 | Absolute change: 0.0088 | Relative change: 1e-08\n  Maximum item intercept parameter change: 0.000842\n  Maximum item slope parameter change: 0.000535\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 23     2024-09-20 19:22:36.438725\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1222 | Absolute change: 0.0054 | Relative change: 0\n  Maximum item intercept parameter change: 0.000669\n  Maximum item slope parameter change: 0.000427\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 24     2024-09-20 19:22:36.55673\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1189 | Absolute change: 0.0033 | Relative change: 0\n  Maximum item intercept parameter change: 0.000532\n  Maximum item slope parameter change: 0.000341\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 25     2024-09-20 19:22:36.66921\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1169 | Absolute change: 0.002 | Relative change: 0\n  Maximum item intercept parameter change: 0.000423\n  Maximum item slope parameter change: 0.000272\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 26     2024-09-20 19:22:36.781784\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1156 | Absolute change: 0.0012 | Relative change: 0\n  Maximum item intercept parameter change: 0.000337\n  Maximum item slope parameter change: 0.000218\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 27     2024-09-20 19:22:36.964662\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1149 | Absolute change: 8e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000268\n  Maximum item slope parameter change: 0.000174\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 28     2024-09-20 19:22:37.077341\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1144 | Absolute change: 5e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000214\n  Maximum item slope parameter change: 0.000139\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 29     2024-09-20 19:22:37.171724\nE Step\nM Step Intercepts   |--\nM Step Slopes       |--\n  Deviance = 1254176.1141 | Absolute change: 3e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.00017\n  Maximum item slope parameter change: 0.000111\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 30     2024-09-20 19:22:37.283681\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1139 | Absolute change: 2e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000136\n  Maximum item slope parameter change: 8.9e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 31     2024-09-20 19:22:37.395682\nE Step\nM Step Intercepts   |--\nM Step Slopes       |-\n  Deviance = 1254176.1138 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 0.000108\n  Maximum item slope parameter change: 7.1e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nIteration 32     2024-09-20 19:22:37.509831\nE Step\nM Step Intercepts   |-\nM Step Slopes       |-\n  Deviance = 1254176.1137 | Absolute change: 1e-04 | Relative change: 0\n  Maximum item intercept parameter change: 8.6e-05\n  Maximum item slope parameter change: 5.7e-05\n  Maximum regression parameter change: 0\n  Maximum variance parameter change: 0\n....................................................\nItem Parameters\n   xsi.index xsi.label     est\n1          1         1 -1.5085\n2          2         2 -1.4816\n3          3         3 -1.3370\n4          4         4 -1.1347\n5          5         5 -0.8444\n6          6         6 -0.4600\n7          7         7 -0.0038\n8          8         8  0.5308\n9          9         9  1.1642\n10        10        10  1.8783\n11        11        11  2.6740\n12        12        12  3.4901\n13        13        13  4.4630\n...................................\nRegression Coefficients\n     [,1]\n[1,]    0\n\nVariance:\n     [,1]\n[1,]    1\n\n\nEAP Reliability:\n[1] 0.626\n\n-----------------------------\nStart:  2024-09-20 19:22:33.134783\nEnd:  2024-09-20 19:22:37.867532 \nTime difference of 4.732749 secs\n\n\n\n\n\n\nSchau dir die Itemparameter an, die das Modell geschätzt hat. Sie finden sich unter sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")]. Vergleiche mit den ursprünglichen Itemparametern, die wir in items festgelegt haben. Was fällt dir auf?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nitems_2pl &lt;- apply(sim_dat_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\nitem_comparison &lt;- cbind(items_2pl, items[, c(\"a\", \"b\")])\n\nitem_comparison\n\n   alpha  beta         a    b\n1   0.52 -2.92 0.5000000 -3.0\n2   0.59 -2.53 0.5833333 -2.5\n3   0.66 -2.04 0.6666667 -2.0\n4   0.75 -1.52 0.7500000 -1.5\n5   0.84 -1.01 0.8333333 -1.0\n6   0.92 -0.50 0.9166667 -0.5\n7   1.00  0.00 1.0000000  0.0\n8   1.09  0.49 1.0833333  0.5\n9   1.17  1.00 1.1666667  1.0\n10  1.24  1.52 1.2500000  1.5\n11  1.35  1.97 1.3333333  2.0\n12  1.38  2.52 1.4166667  2.5\n13  1.47  3.03 1.5000000  3.0\n\n\n\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nggplot(data=item_comparison, \n       aes(x = b, y = beta)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() + ## Ein anderes Theme festlegen\n  xlab(TeX(\"\\\\beta\")) + ## Latex Syntax für die Achsenbeschriftung nutzen\n  ylab(TeX(\"\\\\hat{\\\\beta}\"))\n\n\n\n\n\n\n\n\nggplot(data=item_comparison, \n       aes(x = a, y = alpha)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, colour = \"grey\") +\n  theme_bw() +\n  xlab(TeX(\"\\\\alpha\")) +\n  ylab(TeX(\"\\\\hat{\\\\alpha}\"))\n\n\n\n\n\n\n\nDas sieht super aus, die Werte stimmen gut überein. Dadurch, dass wir so viele Personen simuliert haben, sehen wir also, dass unsere Simulation gut funktioniert. Wir können das Gerüst dieses Simplen Modells jetzt nutzen, um uns noch spannendere Fragestellungen anzuschauen."
  },
  {
    "objectID": "exercises/index.html",
    "href": "exercises/index.html",
    "title": "Übungen",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nInvalid Date\n\n\n3) Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells\n\n\nNicklas Hafiz\n\n\n\n\nInvalid Date\n\n\nIRT Voraussetzungen\n\n\nNicklas Hafiz\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#voraussetzungen-der-item-response-theory",
    "href": "slides/Vorraussetzung/index.html#voraussetzungen-der-item-response-theory",
    "title": "Linking",
    "section": "Voraussetzungen der Item Response Theory",
    "text": "Voraussetzungen der Item Response Theory\n\nEindimmensionalität\nLokal Stochastische Unabhänigkeit (https://files.eric.ed.gov/fulltext/EJf1224232.pdf)."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#eindimmensionalität",
    "href": "slides/Vorraussetzung/index.html#eindimmensionalität",
    "title": "Linking",
    "section": "Eindimmensionalität",
    "text": "Eindimmensionalität\n\nWenn nicht gegeben:\n\nSEM\nDependency Matrix"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#lokal-stochastische-unabhängigkeit",
    "href": "slides/Vorraussetzung/index.html#lokal-stochastische-unabhängigkeit",
    "title": "Linking",
    "section": "Lokal stochastische Unabhängigkeit",
    "text": "Lokal stochastische Unabhängigkeit\nNach Kontrolle für die Personenfähigkeit korrelieren die Items nicht mehr. Der einzige Grund dafür, dass die Items zusammenhängen, ist also, dass die Antwort von diesem Konstrukt beeinflusst wird. Durch die Kontrolle für die Personenfähigkeit halten wir also den Fähigkeitswert konstant (alle Personen haben die gleiche Fähigkeit),\n\nAbbildung\nEinordnung: Lokale Unabhängigkeit, weitere Begriffe?\nBeispiel"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#section",
    "href": "slides/Vorraussetzung/index.html#section",
    "title": "Linking",
    "section": "",
    "text": "Linking\n\n\n\n\nFoto von Bryson Hammer auf Unsplash."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#problem",
    "href": "slides/Vorraussetzung/index.html#problem",
    "title": "Linking",
    "section": "Problem",
    "text": "Problem\n\n\nDas Problem\nInvarianz-Eigenschaft von IRT: Itemparameter sind gleich über verschiedene Gruppen. Die Wahrscheinlichkeit für eine korrekte Antwort auf ein Item hängt also nur von \\(\\theta\\) ab. Nicht von anderen Personen in der Stichprobe. Wie schaffen wir das aber, wenn wir anhand von verschiedenen Gruppen kalibrieren?\n\nDie Lösung\nWir müssen die Werte, die wir aus diesen Kalibrierungen bekommen, irgendwie in einen Zusammenhang setzen."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#wiederholung-kalibrierung",
    "href": "slides/Vorraussetzung/index.html#wiederholung-kalibrierung",
    "title": "Linking",
    "section": "Wiederholung: Kalibrierung",
    "text": "Wiederholung: Kalibrierung\nDie kalibrierten Itemparameter und Personenfähigkeiten gelten erst einmal nur für diese bestimmte Kombintation aus Items und Personen.\nWARUM?"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#wiederholung-kalibrierung-1",
    "href": "slides/Vorraussetzung/index.html#wiederholung-kalibrierung-1",
    "title": "Linking",
    "section": "Wiederholung: Kalibrierung",
    "text": "Wiederholung: Kalibrierung\n\nSkala der Latenten Variable wird arbiträr festgelegt (meist auf einen Mittelwert von 0 und eine SD von 1)\nModell? sonst nicht idenfiziert.\nItemparameter dadurch nicht auf der selben Skala.\nSie können also nicht direkt miteinander verglichen werden."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#beispiel",
    "href": "slides/Vorraussetzung/index.html#beispiel",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nSie hängen ja von den latenten Variablen in der Stichprobe ab. Wenn wir eine sehr gute Stichprobe haben, und eine sehr schwache, dann werden trotzdem bei beiden der Mittelwert der Latenten Variable 0 und die SD 1 sein. Mittelschwere Items werden aber in der schwachen Gruppe eher positive Schwierigkeiten haben, in der starken Gruppe eher negative. (Beispiel nochmal genauer ausführen, evtl. mit Grafik, Ich hatte dazu etwas im ersten Buch, dass ich gelesen habe)."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#beispiel-1",
    "href": "slides/Vorraussetzung/index.html#beispiel-1",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nGroup 1: \\(\\theta \\sim N(0,1)\\) Group 2: \\(\\theta \\sim N(1, 1.4)\\)\nFür die Kalibrierung legen wir jetzt aber fest, dass gilt: Group 1: \\(\\theta \\sim N(0,1)\\) Group 2: \\(\\theta \\sim N(0,1)\\)"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#beispiel-2",
    "href": "slides/Vorraussetzung/index.html#beispiel-2",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#simulieren-von-irt-daten",
    "href": "slides/Vorraussetzung/index.html#simulieren-von-irt-daten",
    "title": "Linking",
    "section": "Simulieren von IRT Daten",
    "text": "Simulieren von IRT Daten\n\n\nJetzt ist ein guter Zeitpunkt, und uns ein sehr mächtiges Werkzeug anzuschauen: Datensimulation.\n\nEinerseits hilft es hoffentlich, die Konzepte hinter IRT und Linking noch besser zu verstehen.\nHilfreich, z.B. für Poweranalysen\n\n\n\nErstellt mit Bing Bild-Ersteller."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#lets-take-a-step-back",
    "href": "slides/Vorraussetzung/index.html#lets-take-a-step-back",
    "title": "Linking",
    "section": "Let’s take a step back!",
    "text": "Let’s take a step back!\nGeht zur Übung und probiert euch aus!"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#warum-das-ganze",
    "href": "slides/Vorraussetzung/index.html#warum-das-ganze",
    "title": "Linking",
    "section": "Warum das Ganze?",
    "text": "Warum das Ganze?\nAn diesem Grundgerüst können wir jetzt verschiedene Anpassungen vornehmen, um ein paar Eigenschaften von Linking zu untersuchen.\nWir erinnern uns zurück: die Fähigkeitsverteilung wird bei der Kalibrierung auf eine Standardnormalverteilung gesetzt (\\(\\theta \\sim N(0, 1)\\)).\nSo hatten wir das auch in der Übung bereits simuliert. Wir können eine zweite Gruppe mit der selben Fähigkeitsverteilung simulieren, und uns anschauen, wie die Itemparameter \\(\\alpha\\) und \\(\\beta\\) geschätzt werden."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#zwei-gruppen",
    "href": "slides/Vorraussetzung/index.html#zwei-gruppen",
    "title": "Linking",
    "section": "Zwei Gruppen",
    "text": "Zwei Gruppen\nDas Vorgehen bleibt genauso wie in der Übung. Der einzige Unterschied ist: Wir simulieren noch eine neue Gruppe hinzu, und setzten dort die \\(\\theta\\) Verteilung auf $N(1, 1).\n\n\nCode zeigen\nlibrary(TAM)\nlibrary(latex2exp) # Erlaubt es, Latex Syntax in ggplot zu nutzen\n\nset.seed(123)\n\n## 2PL Funktion\ncalc_2pl &lt;- function(a, theta, xi){\n  p &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(p) \n}\n\nitems &lt;- data.frame(\n    item_id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 1.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nn_subj &lt;- 100000 ## Als Objekt speichern, da so leichter Änderbar\n\n## Diesmal nehmen wir einfach 2 Gruppen\nsubjects_1 &lt;- data.frame(\n    sub_id = 1:n_subj,\n    theta = c(rnorm(n_subj, 0, 1)), \n    group = rep(\"1\", n_subj)\n)\n\nsubjects_2 &lt;- data.frame(\n    sub_id = n_subj+1:n_subj*2, ## Andere Personen, deshalb andere ID\n    theta = c(rnorm(n_subj, 1, 1)), \n    group = rep(\"2\", n_subj)\n)\n\nsubjects &lt;- rbind(subjects_1, subjects_2)\n\nsim_dat &lt;- merge(subjects, items) %&gt;%\n    mutate(p = calc_2pl(a, theta, b)) %&gt;%\n    mutate(answer = rbinom(n = nrow(.), size = 1, prob = p))\n\nsim_dat_2 &lt;- sim_dat %&gt;%\n    select(item_id, sub_id, answer, group) %&gt;%\n    pivot_wider(names_from = item_id, values_from = answer, id_cols = c(\"group\", \"sub_id\"))\n\n## Jetzt kalibrieren wir sie getrennt, als ob wir zwei verschiedene Sample hätten. \n\n## Zuerst vorbereiten der Daten, d.h. die nicht benötigten Spalten entfernen und einen Datensatz pro Gruppe erzeugen. \ngroup_1_prep &lt;- sim_dat_2 %&gt;% \n  filter(group == \"1\") %&gt;% \n  select(-group, -sub_id)\n\ngroup_2_prep &lt;- sim_dat_2 %&gt;%\n  filter(group == \"2\") %&gt;% \n  select(-group, -sub_id)\n\n## Kalibrieren der beiden Gruppen getrennt\ngroup_1_2PL &lt;- tam.mml.2pl(group_1_prep, irtmodel = \"2PL\")\ngroup_2_2PL &lt;- tam.mml.2pl(group_2_prep, irtmodel = \"2PL\")\n\n# ## Extrahieren der Itemparameter\nitempars_1 &lt;- as.data.frame(apply(group_1_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\nitempars_2 &lt;- as.data.frame(apply(group_2_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(itempars_2) &lt;- c(\"alpha_2\", \"beta_2\")"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#plotten",
    "href": "slides/Vorraussetzung/index.html#plotten",
    "title": "Linking",
    "section": "Plotten",
    "text": "Plotten\n\n\nCode zeigen\n## Plotten\nparameters &lt;- cbind(itempars_1, itempars_2)\n\n## Und weil ich das gleich noch ein paar mal brauche bastel ich mir mal eine Funktion draus:\nplot_group_pars &lt;- function(dat, x, y){\n  ylab_char &lt;- gsub(\"_2\", \"\", deparse(substitute(y))) ## Automatically produce ylabel\n  \n  ggplot(data = dat, aes(x = {{x}}, y = {{y}})) +\n    geom_point() +\n    geom_abline(intercept = 0, slope = 1) +\n    xlim(-4, 4) +\n    ylim(-4, 4) +\n    theme_bw() +\n    xlab(TeX(paste0(\"\\\\hat{\\\\\", deparse(substitute(x)), \"}_1\"))) + \n    ylab(TeX(paste0(\"\\\\hat{\\\\\", ylab_char, \"}_2\")))\n}\n\nplot_group_pars(parameters, beta, beta_2) +\n  labs(title = \"Itemschwierigkeiten für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(1, 1)\"))"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#warum",
    "href": "slides/Vorraussetzung/index.html#warum",
    "title": "Linking",
    "section": "Warum??",
    "text": "Warum??"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#diskriminationsparameter",
    "href": "slides/Vorraussetzung/index.html#diskriminationsparameter",
    "title": "Linking",
    "section": "Diskriminationsparameter",
    "text": "Diskriminationsparameter\n\n\nCode zeigen\nplot_group_pars(parameters, alpha, alpha_2) +\n  labs(title = \"Diskriminationsparameter für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(1, 1)\"))"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#simirt",
    "href": "slides/Vorraussetzung/index.html#simirt",
    "title": "Linking",
    "section": "SimIRT",
    "text": "SimIRT\nÜbringes: es gibt natürlich auch schon R Pakete, die die Simulationsarbeit für uns übernehmen. Aus didaktischen Gründen haben wir das bisher selber gemacht, aber können uns jetzt ein bisschen Arbeit ersparen, und das ganze von dem Paket catIrt übernehmen lassen. Hier nochmal die gleiche Simulation, aber mit\n\nlibrary(catIrt)\n\ngroup_1 &lt;- simIrt(theta =rnorm(100000, 0, 1), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\ngroup_2 &lt;- simIrt(theta =rnorm(100000, 0, 1.5), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\n\n## Kalibrieren der beiden Gruppen getrennt\ngroup_1_2PL &lt;- tam.mml.2pl(group_1$resp, irtmodel = \"2PL\")\ngroup_2_2PL &lt;- tam.mml.2pl(group_2$resp, irtmodel = \"2PL\")\n\n## Extrahieren der Itemparameter\nitempars_1 &lt;- as.data.frame(apply(group_1_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\nitempars_2 &lt;- as.data.frame(apply(group_2_2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(itempars_2) &lt;- c(\"alpha_2\", \"beta_2\")"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#plots-zeigen",
    "href": "slides/Vorraussetzung/index.html#plots-zeigen",
    "title": "Linking",
    "section": "Plots zeigen",
    "text": "Plots zeigen\n\n\nCode zeigen\nparameters &lt;- cbind(itempars_1, itempars_2)\n\nplot_group_pars(parameters, alpha, alpha_2) +\n  labs(title = \"Diskriminationsparameter für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(0, 1.5)\"))"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#schwierigkeit",
    "href": "slides/Vorraussetzung/index.html#schwierigkeit",
    "title": "Linking",
    "section": "Schwierigkeit",
    "text": "Schwierigkeit\n\n\nCode zeigen\nplot_group_pars(parameters, beta, beta_2) +\n  labs(title = \"Itemschwierigkeiten für zwei Gruppen\", \n       caption = TeX(\"\\\\theta_1 \\\\sim N(0,1), \\\\theta_2 \\\\sim N(0, 1.5)\"))"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#schlusfolgerung",
    "href": "slides/Vorraussetzung/index.html#schlusfolgerung",
    "title": "Linking",
    "section": "Schlusfolgerung",
    "text": "Schlusfolgerung\n\nWir brauchen also einen Referenzrahmen um unsere Testergebnisse interpretieren zu können.\nDas bedeutet auch, dass wir die Werte aus verschiedenen Kalibrierungen nicht direkt miteinander vergleichen können.\nLösung: Linking"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#identifizirbarkeit",
    "href": "slides/Vorraussetzung/index.html#identifizirbarkeit",
    "title": "Linking",
    "section": "Identifizirbarkeit",
    "text": "Identifizirbarkeit"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#beispiel-3",
    "href": "slides/Vorraussetzung/index.html#beispiel-3",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#linkingequating",
    "href": "slides/Vorraussetzung/index.html#linkingequating",
    "title": "Linking",
    "section": "Linking/Equating",
    "text": "Linking/Equating\n\nSzenario: Wir haben verschiedene Testformen, und wollen die Scores auf eine gemeinsame Skala bringen.\nDafür haben wir zwei Möglichkeiten:\n\nGemeinsame Items\nGemeinsame Personen\n\n\nAbbildung z.B. mit Verteilung von theta scores, die nochmal zeigt was das Problem ist. Dann kann man bestimmte Items markieren, und die Verteilungen entsprechend dieser markierten Items verschieben.\nEmbretson 2000, S. 253\n\nItem Parameter werden in beiden Tests geschätzt, und dann anhand der Ankeritems durch eine geeignete Transformation auf eine gemeinsame Skala gebracht."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#beispiel-4",
    "href": "slides/Vorraussetzung/index.html#beispiel-4",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\n\nSchulvergleichsstudien über die Jahre:\nItempools von Unternehmen, die Einstellungstests anbieten."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#ankeritems",
    "href": "slides/Vorraussetzung/index.html#ankeritems",
    "title": "Linking",
    "section": "Ankeritems",
    "text": "Ankeritems\n\n\n\nGemeinsame Items, die in beiden Testformen vorhanden sind.\nSollten keinen DIF haben.Genauer recherchieren: How to choose anchor items."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#ankeritems-1",
    "href": "slides/Vorraussetzung/index.html#ankeritems-1",
    "title": "Linking",
    "section": "Ankeritems",
    "text": "Ankeritems\n\nKallibrierungen der Parameterschätzer aus zwei verschiedenen Testformen werden auf eine gemeinsame Skala gebracht.\nWir müssen also die theta (\\(\\theta\\)) scores des einen Tests so transformieren, dass sie auf einer gemeinsamen Skala mit den Scores des anderen Tests liegen:\n\n\\[\n\\theta_Y = A \\theta_X + B\n\\]"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#ankerpersonen",
    "href": "slides/Vorraussetzung/index.html#ankerpersonen",
    "title": "Linking",
    "section": "Ankerpersonen",
    "text": "Ankerpersonen\nPersonen bearbeiten beide Tests. Personenfähigkeit wird basierend auf einem Referenztest geschätzt, und dann fixiert und konstant gehalten, wenn andere Testformen bearbeitet werden. Die Fähigkeitswerte werden dann genutzt, um Itemparameter auf beiden Testformen zu schätzen."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#linking",
    "href": "slides/Vorraussetzung/index.html#linking",
    "title": "Linking",
    "section": "Linking",
    "text": "Linking\n\\[\n\\theta* = x\\theta+y\n\\]\n…"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#linking-1",
    "href": "slides/Vorraussetzung/index.html#linking-1",
    "title": "Linking",
    "section": "Linking",
    "text": "Linking\nZiel: “Linking constants” \\(x\\) und \\(y\\) findend, welche die Item parameter aus den beiden Gruppen auf der selben Skala plazieren. Deutlich machen, für welche Art Modell nutzbar! Nochmal mit dem neueren Buch rübergehen, das geht noch mehr in die Tiefe.\n\nZwei häufige Methoden:\n\nmean-sigma:\n\nAnnahme: Gemeinsame Ankeritems, oder Zwei Gruppen haben den genau gleichen Test bearbeitet. \\[\nB_B^* = x\\beta_b=y\n\\]\n\n\n\n\\[\nx = \\frac{\\sigma_A}{\\sigma_B}\n\\]\n\\[\ny = \\overline{\\beta}_A - x(\\overline{\\beta}_B)\n\\]\nUnd dann einsetzen in \\[\n\\theta* = x\\theta+y\n\\]\netc.\nmal ausprobieren!"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#mean-sigma",
    "href": "slides/Vorraussetzung/index.html#mean-sigma",
    "title": "Linking",
    "section": "mean-sigma",
    "text": "mean-sigma\nProbleme: linking constants können stark von Outliern beeinflusst werden, und von den differential standards errors of the item difficutly estimates - Robust procedures exist.\nNur die item difficulty parameters werden zur berechnung der Linking constants genutzt.\nAlternative: Characteristic curve methods"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#characteristic-curve-methods",
    "href": "slides/Vorraussetzung/index.html#characteristic-curve-methods",
    "title": "Linking",
    "section": "Characteristic curve methods",
    "text": "Characteristic curve methods\nVersuch, die Linking constants so zu berechnen, dass die test charctersitic curves so ähnlich wie möglich sind. Nutzen daher alle item parameter um die Linking constants zu finden. computationally more expensive. Empirical research zeigt keine großen Unterschide zwischen beiden Methoden? Nochmal selber recherchiereen."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#gibt-es-neuere-methoden-z.b.-multi-group-irt-cfa-framework",
    "href": "slides/Vorraussetzung/index.html#gibt-es-neuere-methoden-z.b.-multi-group-irt-cfa-framework",
    "title": "Linking",
    "section": "Gibt es neuere methoden? Z.B. Multi-group IRT, CFA framework …?",
    "text": "Gibt es neuere methoden? Z.B. Multi-group IRT, CFA framework …?"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#beispiel-5",
    "href": "slides/Vorraussetzung/index.html#beispiel-5",
    "title": "Linking",
    "section": "Beispiel",
    "text": "Beispiel\nIm Embretson machen sie eine kleine Simulation. Könnten wir auch machen, entweder als aufgabe oder demonstrieren. - Man könnte die Linking constants setzen, gukcen was das mit den schwierikeiten macht, und die Simulierten Werte wieder rekapitulieren."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#das-problem",
    "href": "slides/Vorraussetzung/index.html#das-problem",
    "title": "Linking",
    "section": "Das Problem",
    "text": "Das Problem\n\nFunktionieren die Items in verschiedenen Gruppen (z.B. Geschlecht, Kultur, Fähigkeit …) auf dieselbe Art und Weise?\nGibt es also echte Mittelwertsunterschiede zwischen beiden Gruppen, oder sind die Unterschiede auf Besondere Interaktionen zwischen Items und Gruppen zurückzuführen?"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#dif",
    "href": "slides/Vorraussetzung/index.html#dif",
    "title": "Linking",
    "section": "DIF",
    "text": "DIF\n\nWenn wir das auf bestimmte Items anwenden, sprechen wir von Differential Item Functioning.\n\nRaschtrees vorstellen? Ansonsten Embretson ab Linking auch gut."
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#was-wird-überprüft",
    "href": "slides/Vorraussetzung/index.html#was-wird-überprüft",
    "title": "Linking",
    "section": "Was wird Überprüft?",
    "text": "Was wird Überprüft?"
  },
  {
    "objectID": "slides/Vorraussetzung/index.html#beispiel-was-bei-nichtbeachtung-passiert",
    "href": "slides/Vorraussetzung/index.html#beispiel-was-bei-nichtbeachtung-passiert",
    "title": "Linking",
    "section": "Beispiel was bei nichtbeachtung passiert",
    "text": "Beispiel was bei nichtbeachtung passiert\n\n\n\n  \n\n   \n      \n   \n\n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                                                                                                    \n                           \n\n\n    \n  \n  \n  \n\n\nhttps://nickhaf.github.io/IRT_workshop/slides/"
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Folien",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nInvalid Date\n\n\nEinführung in R\n\n\nNicklas Hafiz\n\n\n\n\nInvalid Date\n\n\nLinking\n\n\n \n\n\n\n\nInvalid Date\n\n\nAlgemeines Linear Gemischtes Modell (ALGM)\n\n\nNicklas Hafiz\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/linking_simulation.html",
    "href": "notes/linking_simulation.html",
    "title": "IRT",
    "section": "",
    "text": "calc_2pl &lt;- function(a, theta, xi){\n  psi &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(psi) \n}\n\n\ntheta_data &lt;- data.frame(\n    person = 1:20000,\n    theta = c(rnorm(10000, 0, 1), rnorm(10000, 1, 2)),\n    group = c(rep(\"1\", 10000), rep(\"2\", 10000))\n)\n\nitems &lt;- data.frame(\n    id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 1.5, length.out = 13), \n    c = rep(0, 13)\n)\n\nsim_dat &lt;- merge(theta_data, items) %&gt;%\n    mutate(prop = calc_2pl(a, theta, b)) %&gt;%\n    mutate(Answer = rbinom(n = nrow(.), size = 1, prob = prop))\n\n## could also try sim_irt\n\n## With sim_irt\nlibrary(catIrt)\n\nsimirt_dat &lt;- simIrt(theta =rnorm(100000, 0, 1), params = as.matrix(items[, c(\"a\", \"b\", \"c\")]), mod = \"brm\")\n## Analyze with a package to see if everything worked. \nlibrary(mirt)\nlibrary(TAM)\n\n## Into wide format\nsim_dat_wide &lt;- sim_dat %&gt;%\n    filter(group == \"1\") %&gt;%\n    select(id, Answer, theta, person) %&gt;%\n    pivot_wider(names_from = id, values_from = Answer, id_cols = person)\n\nfit2PL &lt;- tam.mml.2pl(sim_dat_wide %&gt;% select(-person), irtmodel = \"2PL\")\n# saveRDS(fit2PL, file = \"./slides/Vorraussetzung/dat/fit2PL.RDS\")\nfit2PL &lt;- readRDS(file = \"./slides/Vorraussetzung/dat/fit2PL.RDS\")\n\napply(fit2PL$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\n# Actually worked! \n\n\nfit2PL_2 &lt;- tam.mml.2pl(as.data.frame(simirt_dat$resp), irtmodel = \"2PL\")\n# saveRDS(fit2PL_2, file = \"./slides/Vorraussetzung/dat/fit2PL_simfun.RDS\")\nfit2PL_2 &lt;- readRDS(file = \"./slides/Vorraussetzung/dat/fit2PL_simfun.RDS\")\n\napply(fit2PL_2$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)\n# This worked fairly well\n\nfit2PL &lt;- mirt(data = sim_dat_wide %&gt;% select(-person), \n               itemtype = \"2PL\", \n               verbose = FALSE)\n\nparams2PL &lt;- coef(fit2PL, IRTpars = TRUE, simplify = TRUE)"
  },
  {
    "objectID": "notes/linking_simulation.html#kalibrierte-parameter-für-2-gleiche-gruppen",
    "href": "notes/linking_simulation.html#kalibrierte-parameter-für-2-gleiche-gruppen",
    "title": "IRT",
    "section": "Kalibrierte Parameter für 2 GLEICHE Gruppen",
    "text": "Kalibrierte Parameter für 2 GLEICHE Gruppen\n\nlibrary(TAM)\n\ncalc_2pl &lt;- function(a, theta, xi){\n  psi &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(psi) \n}\n\nitems &lt;- data.frame(\n    id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 3.5, by = 0.25), \n    c = rep(0, 13)\n)\n\ntheta_data &lt;- data.frame(\n    person = 1:20000,\n    theta = c(rnorm(10000, 0, 1), rnorm(10000, 0, 1)),\n    group = c(rep(\"1\", 10000), rep(\"2\", 10000))\n)\n\nsim_dat &lt;- merge(theta_data, items) %&gt;%\n    mutate(prop = calc_2pl(a, theta, b)) %&gt;%\n    mutate(Answer = rbinom(n = nrow(.), size = 1, prob = prop))\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(id, Answer, theta, person, group) %&gt;%\n    pivot_wider(names_from = id, values_from = Answer, id_cols = c(\"person\", \"group\"))\n\n\nsim_data_1 &lt;- sim_dat_wide %&gt;% filter(group == \"1\") %&gt;% select(-group)\nsim_data_2 &lt;- sim_dat_wide %&gt;% filter(group == \"2\") %&gt;% select(-group)\n\nfit2PL_1 &lt;- tam.mml.2pl(sim_data_1 %&gt;% select(-person), irtmodel = \"2PL\")\nfit2PL_2 &lt;- tam.mml.2pl(sim_data_2 %&gt;% select(-person), irtmodel = \"2PL\")"
  },
  {
    "objectID": "notes/linking_simulation.html#plot",
    "href": "notes/linking_simulation.html#plot",
    "title": "IRT",
    "section": "Plot",
    "text": "Plot\n\npar_1 &lt;- as.data.frame(apply(fit2PL_1$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)) \npar_2 &lt;- as.data.frame(apply(fit2PL_2$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(par_2) &lt;- c(\"alpha_2\", \"beta_2\")\n\nparameters &lt;- cbind(par_1, par_2)\n\nggplot(data = parameters, aes(x = beta, y = beta_2)) +\n    geom_point() +\n    geom_abline(intercept = 0, slope = 1) +\n    xlab(\"Group 1\") +\n    ylab(\"Group 2\") +\n    xlim(-4, 4) +\n    ylim(-4, 4) \n\n\n## Nice, this worked!"
  },
  {
    "objectID": "notes/linking_simulation.html#kalibrierte-parameter-für-2-versch.-gruppen",
    "href": "notes/linking_simulation.html#kalibrierte-parameter-für-2-versch.-gruppen",
    "title": "IRT",
    "section": "Kalibrierte Parameter für 2 versch. Gruppen",
    "text": "Kalibrierte Parameter für 2 versch. Gruppen\n\nlibrary(TAM)\n\ncalc_2pl &lt;- function(a, theta, xi){\n  psi &lt;- (exp(a*(theta - xi)))/(1 + exp(a*(theta - xi))) \n  return(psi) \n}\n\nitems &lt;- data.frame(\n    id = 1:13, \n    b = seq(-3, 3, by = 0.5), \n    a = seq(0.5, 3.5, by = 0.25), \n    c = rep(0, 13)\n)\n\ntheta_data &lt;- data.frame(\n    person = 1:20000,\n    theta = c(rnorm(10000, 0, 1), rnorm(10000, 1, 1.3)),\n    group = c(rep(\"1\", 10000), rep(\"2\", 10000))\n)\n\nsim_dat &lt;- merge(theta_data, items) %&gt;%\n    mutate(prop = calc_2pl(a, theta, b)) %&gt;%\n    mutate(Answer = rbinom(n = nrow(.), size = 1, prob = prop))\n\nsim_dat_wide &lt;- sim_dat %&gt;%\n    select(id, Answer, theta, person, group) %&gt;%\n    pivot_wider(names_from = id, values_from = Answer, id_cols = c(\"person\", \"group\"))\n\n\nsim_data_1 &lt;- sim_dat_wide %&gt;% filter(group == \"1\") %&gt;% select(-group)\nsim_data_2 &lt;- sim_dat_wide %&gt;% filter(group == \"2\") %&gt;% select(-group)\n\nfit2PL_1 &lt;- tam.mml.2pl(sim_data_1 %&gt;% select(-person), irtmodel = \"2PL\")\nfit2PL_2 &lt;- tam.mml.2pl(sim_data_2 %&gt;% select(-person), irtmodel = \"2PL\")"
  },
  {
    "objectID": "notes/linking_simulation.html#plot-1",
    "href": "notes/linking_simulation.html#plot-1",
    "title": "IRT",
    "section": "Plot",
    "text": "Plot\n\npar_1 &lt;- as.data.frame(apply(fit2PL_1$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2)) \npar_2 &lt;- as.data.frame(apply(fit2PL_2$item_irt[, c(\"alpha\", \"beta\")], 2, round, 2))\ncolnames(par_2) &lt;- c(\"alpha_2\", \"beta_2\")\n\nparameters &lt;- cbind(par_1, par_2)\n\nggplot(data = parameters, aes(x = beta, y = beta_2)) +\n    geom_point() +\n    geom_abline(intercept = 0, slope = 1) +\n    xlab(\"Group 1\") +\n    ylab(\"Group 2\") +\n    xlim(-4, 4) +\n    ylim(-4, 4) \n\n## Looks good. Possibly some interaction with the discrimination parameter, look that up. \n\n\nggplot(data = parameters, aes(x = alpha, y = alpha_2)) +\n    geom_point() +\n    geom_abline(intercept = 0, slope = 1) +\n    xlab(\"Group 1\") +\n    ylab(\"Group 2\") +\n    xlim(0, 4) +\n    ylim(0, 4) \n\n## Also looks great!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IRT Workshop",
    "section": "",
    "text": "Theoretische Einführung in die Modellierung latenter Variablen in Klassischer Testtheorie und Item Response Theory (IRT) (90 min.; SW)\nEinführung in die R-Programmierumgebung. Datenaufbereitung für IRT-Analysen. (90 min.; NH)\n\n\n\n\n\nÜbung: einfacher IRT-Modelle in TAM. Theoretische Unterscheidung zwischen JML, CML and MML (SW).\nTheoretische Einführung und praktische Illustration: Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells (Generalized Linear Mixed Model, GLMM) mit fixierten Effekten auf der Item- und zufälligen Effekten auf der Personenseite (NH + SW).\nReliabilität, Validität, lokale stochastische Unabhängigkeit (Diag-Folien!)\n\n\n\n\n\n\n\n\nVoraussetzungen: Verlinkte Items, lokale stochastische Unabhängigkeit, Messinvarianz (90 min.; NH)\nDie Bedeutung von Testdesigns. Was kann schiefgehen, wenn Testdesigns ungeeignet sind? (SW)\n\n\n\n\n\nHöher parametrisierte Modelle: 2pl, 3pl, partial credit (NH)\n\nMaybe use Grit-Scale or the psychometrics data for illustration.\n\nLängsschnittliche Designs: Wiederholte Messungen für Individuen, Kohorten oder Populationen (SW)\n\n\n\n\n\n\n\n\nPraktische Überlegungen: Welches Modell für welche Forschungsfrage? Wieviele Personen sind notwendig für welches Forschungsdesign? Theoretische Überlegungen und praktische Empfehlungen (90 min., SW + NH)\n\n\n\n\n\nDas ganze Bild: Vollständige “Schritt für Schritt”-Analyse von Forschungsdaten: Datenaufbereitung, Kalibrierung, Plausibilitätsprüfungen, Messinvarianz, Beantworten von Forschungsfragen (180 Min., SW/NH)"
  },
  {
    "objectID": "index.html#tag-1",
    "href": "index.html#tag-1",
    "title": "IRT Workshop",
    "section": "",
    "text": "Theoretische Einführung in die Modellierung latenter Variablen in Klassischer Testtheorie und Item Response Theory (IRT) (90 min.; SW)\nEinführung in die R-Programmierumgebung. Datenaufbereitung für IRT-Analysen. (90 min.; NH)\n\n\n\n\n\nÜbung: einfacher IRT-Modelle in TAM. Theoretische Unterscheidung zwischen JML, CML and MML (SW).\nTheoretische Einführung und praktische Illustration: Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells (Generalized Linear Mixed Model, GLMM) mit fixierten Effekten auf der Item- und zufälligen Effekten auf der Personenseite (NH + SW).\nReliabilität, Validität, lokale stochastische Unabhängigkeit (Diag-Folien!)"
  },
  {
    "objectID": "index.html#tag-2",
    "href": "index.html#tag-2",
    "title": "IRT Workshop",
    "section": "",
    "text": "Voraussetzungen: Verlinkte Items, lokale stochastische Unabhängigkeit, Messinvarianz (90 min.; NH)\nDie Bedeutung von Testdesigns. Was kann schiefgehen, wenn Testdesigns ungeeignet sind? (SW)\n\n\n\n\n\nHöher parametrisierte Modelle: 2pl, 3pl, partial credit (NH)\n\nMaybe use Grit-Scale or the psychometrics data for illustration.\n\nLängsschnittliche Designs: Wiederholte Messungen für Individuen, Kohorten oder Populationen (SW)"
  },
  {
    "objectID": "index.html#tag-3",
    "href": "index.html#tag-3",
    "title": "IRT Workshop",
    "section": "",
    "text": "Praktische Überlegungen: Welches Modell für welche Forschungsfrage? Wieviele Personen sind notwendig für welches Forschungsdesign? Theoretische Überlegungen und praktische Empfehlungen (90 min., SW + NH)\n\n\n\n\n\nDas ganze Bild: Vollständige “Schritt für Schritt”-Analyse von Forschungsdaten: Datenaufbereitung, Kalibrierung, Plausibilitätsprüfungen, Messinvarianz, Beantworten von Forschungsfragen (180 Min., SW/NH)"
  },
  {
    "objectID": "slides/GLM/index.html#überblick",
    "href": "slides/GLM/index.html#überblick",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Überblick",
    "text": "Überblick\n\nGeneralized Linear Modell (GLM)\nLinear Mixed Model (LMM)\nÜbertragung auf IRT Kontext"
  },
  {
    "objectID": "slides/GLM/index.html#generalized-linear-model",
    "href": "slides/GLM/index.html#generalized-linear-model",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Generalized Linear Model",
    "text": "Generalized Linear Model\n\\[\ny = Xb+e\n\\]\n\\[\nE(y) = \\mu = g^{-1}(Xb)\n\\]\n\nmit \\(g\\) als Link Funktion\n\nVarianzfunktion auch zeigen?"
  },
  {
    "objectID": "slides/GLM/index.html#irt-modell-als-glm",
    "href": "slides/GLM/index.html#irt-modell-als-glm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "IRT Modell als GLM",
    "text": "IRT Modell als GLM\n\\[\ng(\\mu) = ln(\\frac{\\mu}{1-\\mu}) = Xb\n\\]"
  },
  {
    "objectID": "slides/GLM/index.html#irt-modell-als-glm-1",
    "href": "slides/GLM/index.html#irt-modell-als-glm-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "IRT Modell als GLM",
    "text": "IRT Modell als GLM\n\nLogistische Regression: Modellierung der Wahrscheinlichkeit einer korrekten Antwort.\nZusammenhang der Variablen linear. Muss dann noch auf die logit-scale gebracht werden (Link Funktion)."
  },
  {
    "objectID": "slides/GLM/index.html#section",
    "href": "slides/GLM/index.html#section",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "",
    "text": "Linear Mixed Models\n\n\n\nFoto von Mauro Lima auf Unsplash."
  },
  {
    "objectID": "slides/GLM/index.html#llm",
    "href": "slides/GLM/index.html#llm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "LLM",
    "text": "LLM\n\nlibrary(tidyverse)\n\n## Daten laden\nload(here::here(\"raw_data\", \"multilevel_data.rda\"))\n\n## Überblick\nstr(stud_data)\n\ntibble [7,185 × 5] (S3: tbl_df/tbl/data.frame)\n $ school  : chr [1:7185] \"1224\" \"1224\" \"1224\" \"1224\" ...\n $ minority: Factor w/ 2 levels \"No\",\"Yes\": 1 1 1 1 1 1 1 1 1 1 ...\n $ sex     : Factor w/ 2 levels \"Male\",\"Female\": 2 2 1 1 1 1 2 1 2 1 ...\n $ ses     : num [1:7185] -1.528 -0.588 -0.528 -0.668 -0.158 ...\n $ mathach : num [1:7185] 5.88 19.71 20.35 8.78 17.9 ...\n\n\n\n\nDaten aus diesem Tutorial"
  },
  {
    "objectID": "slides/GLM/index.html#option-1-ignorieren",
    "href": "slides/GLM/index.html#option-1-ignorieren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 1: Ignorieren",
    "text": "Option 1: Ignorieren"
  },
  {
    "objectID": "slides/GLM/index.html#option-1-ignorieren-1",
    "href": "slides/GLM/index.html#option-1-ignorieren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 1: Ignorieren",
    "text": "Option 1: Ignorieren\nGenerell eher keine gute Idee:\n\nDie genestete Struktur kann von Interesse sein!\nWir tun so, als ob wir mehr Informationen hätten, als wir letztendlich haben. Das liegt daran, dass Abhängigkeiten zwischen den Daten bestehen. Konsequenz:\n\nStandardfehler werden unterschätzt, unsere Inferenzstatistischen Tests werden eher signifikant."
  },
  {
    "objectID": "slides/GLM/index.html#option-2-aggregieren",
    "href": "slides/GLM/index.html#option-2-aggregieren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 2: Aggregieren",
    "text": "Option 2: Aggregieren"
  },
  {
    "objectID": "slides/GLM/index.html#option-2-aggregieren-1",
    "href": "slides/GLM/index.html#option-2-aggregieren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 2: Aggregieren",
    "text": "Option 2: Aggregieren"
  },
  {
    "objectID": "slides/GLM/index.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren",
    "href": "slides/GLM/index.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren",
    "text": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren\nVerstehe noch nicht so ganz, wie das grafisch aussehen würde. https://www.cambridge.org/core/journals/political-science-research-and-methods/article/abs/should-i-use-fixed-or-random-effects/12DFCB222123587A37163F2226E85C67\nrandom effect models reduce bias, but can reduce the variance of estimates of coefficients of interest. some sort of regularization\nWird schnell unübersichtlich, lm z.B. gibt uns viele Infos raus, die uns eigentlich gar nicht interssieren. An sich müsste die Grafik ähnlich aussehen wie im nächsten Beispiel? Die Berechnungen sind aber ein bisscehn anders, v.a. wegen Partial pooling."
  },
  {
    "objectID": "slides/GLM/index.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren-1",
    "href": "slides/GLM/index.html#option-3-disaggregiert-analyse-mit-gruppen-als-prädiktoren-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren",
    "text": "Option 3: Disaggregiert Analyse mit Gruppen als Prädiktoren"
  },
  {
    "objectID": "slides/GLM/index.html#option-4-multilevel-modell",
    "href": "slides/GLM/index.html#option-4-multilevel-modell",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Option 4: Multilevel-Modell",
    "text": "Option 4: Multilevel-Modell"
  },
  {
    "objectID": "slides/GLM/index.html#notizen",
    "href": "slides/GLM/index.html#notizen",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Notizen",
    "text": "Notizen\nRein Optisch betrachtet scheint es recht wichtig zu sein, auf welche Schule man geht. Die Abweichung von Mittelwert des GesamtSES hat auch einen Einfluss."
  },
  {
    "objectID": "slides/GLM/index.html#level-1-gleichung",
    "href": "slides/GLM/index.html#level-1-gleichung",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Level 1 Gleichung",
    "text": "Level 1 Gleichung\nFür jede Gruppe j: \\[\ny_{ij} = \\beta_{0j} + \\beta_{1j}x_{ij} + e_{ij}\n\\]\nAbbildung"
  },
  {
    "objectID": "slides/GLM/index.html#level-2-gleichung",
    "href": "slides/GLM/index.html#level-2-gleichung",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Level-2 Gleichung",
    "text": "Level-2 Gleichung\n\\[\n\\beta_{0j} = \\beta_{0}+\\zeta_{0j}\n\\]\n\\[\n\\beta_{1j} = \\beta_1 + \\zeta_{1j}\n\\]\nAbbildung"
  },
  {
    "objectID": "slides/GLM/index.html#das-gemischte-modell",
    "href": "slides/GLM/index.html#das-gemischte-modell",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Das gemischte Modell",
    "text": "Das gemischte Modell\nJetzt müssen wir nur noch einsetzen:\n\\[\ny_{ij} = \\beta_{0j} + \\beta_{1j}x_{ij} + e_{ij}\n\\] \\[\n\\beta_{0j} = \\beta_{0}+\\zeta_{0j}\n\\]\n\\[\n\\beta_{1j} = \\beta_1 + \\zeta_{1j}\n\\]\n\\[\ny_{ij} = \\beta_{0}+\\beta_1x_{ij} + \\zeta_{0j} + \\zeta_{1j}x_{ij} + e_{ij}\n\\]"
  },
  {
    "objectID": "slides/GLM/index.html#section-1",
    "href": "slides/GLM/index.html#section-1",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "",
    "text": "Random effects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFixed effects"
  },
  {
    "objectID": "slides/GLM/index.html#random-und-fixed-effects",
    "href": "slides/GLM/index.html#random-und-fixed-effects",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Random und Fixed effects",
    "text": "Random und Fixed effects\n\n\nRandom Effects\n\nAnnahme eines zugrundeliegenden Gesamtmittelwerts. Von diesem weichen die Gruppen random ab.\nBei Wiederholung würden wir andere Gruppen ziehen.\nPartial Pooling: Regularisierung der Extremen Werte in Richtung Gruppenmittelwert. \n\n\nFixed Effects\n\nHier machen wir diese Annahme einfach nicht.\nUns interessieren die tatsächlichen Gruppen, bei Wiederholung würden wird die gleichen ziehen."
  },
  {
    "objectID": "slides/GLM/index.html#beispiel",
    "href": "slides/GLM/index.html#beispiel",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Beispiel",
    "text": "Beispiel\nWir untersuchen den Erfolg von Verhaltenstherapie und Psychoanalyse anhand der Rückfallquote nach einem Jahr.\nPatientinnen müssen hier nach Therapeutinnen genested werden. Dabei können wir die Therapeutinnen als random effects betrachten, wir haben sie ja schließlich nur als Mittel zum Zweck aus der Population an Therapeutinnen gezogen. Die Behandlungsform (Verhaltenstherapie, Psychoanalyse) ist hingegen ein fixed effect, da wir nur diese beiden Behandlungsformen untersuchen wollen.\nAnders würde das Ganze aussehen, wenn uns die Erfolgsquote speziell dieser Therapeut*innen interessieren würde. Dann könnten wir sie ebenfalls als fixed effect im Modell mit aufnehmen."
  },
  {
    "objectID": "slides/GLM/index.html#lme4",
    "href": "slides/GLM/index.html#lme4",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "lme4",
    "text": "lme4\n\nlibrary(lme4)\n\nmod1 &lt;- lmer(mathach ~ ses_cent + (1|school), data = illustration_dat) \nsummary(mod1)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: mathach ~ ses_cent + (1 | school)\n   Data: illustration_dat\n\nREML criterion at convergence: 2091\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.52568 -0.67053 -0.06796  0.74859  2.79564 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n school   (Intercept)  8.778   2.963   \n Residual             34.699   5.891   \nNumber of obs: 325, groups:  school, 9\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)  13.1169     1.0447  12.555\nses_cent      2.6255     0.5285   4.968\n\nCorrelation of Fixed Effects:\n         (Intr)\nses_cent -0.016"
  },
  {
    "objectID": "slides/GLM/index.html#raschmodell-als-spezialfall-von-lmm",
    "href": "slides/GLM/index.html#raschmodell-als-spezialfall-von-lmm",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Raschmodell als Spezialfall von LMM",
    "text": "Raschmodell als Spezialfall von LMM\nDafür müssen wir zwei Dinge beachten: - Link Funktion.\n- Entscheidung über Annahme von fixed/random effects von Personen und Items.\n\n\n\nDe Boeck and Wilson (2004)\nDoran et al. (2007)"
  },
  {
    "objectID": "slides/GLM/index.html#link-funktion",
    "href": "slides/GLM/index.html#link-funktion",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Link Funktion",
    "text": "Link Funktion"
  },
  {
    "objectID": "slides/GLM/index.html#fixed-und-random-effects",
    "href": "slides/GLM/index.html#fixed-und-random-effects",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Fixed und Random Effects",
    "text": "Fixed und Random Effects\n\nEntwicklung Fragebogen um diesen an verschiedenen Stichproben zu nutzen: Person als random, Items als fixed\nEntwicklung von Items für einen großen Fragenkatalog: Items ebenfalls als random"
  },
  {
    "objectID": "slides/GLM/index.html#exercise",
    "href": "slides/GLM/index.html#exercise",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Exercise",
    "text": "Exercise\n\nDirekt übertragen auf den IRT-KOntext? Also sagen: Nehmt die Daten aus dem letzten Beispiel und fittet ein LLM Modell.\nDann Vergleich mit TAM."
  },
  {
    "objectID": "slides/GLM/index.html#prädiktoren",
    "href": "slides/GLM/index.html#prädiktoren",
    "title": "Algemeines Linear Gemischtes Modell (ALGM)",
    "section": "Prädiktoren",
    "text": "Prädiktoren\n\nBeispiel aufgreifen, zeigen, wass man mit diesen Modell noch machen kann."
  },
  {
    "objectID": "slides/IntroR/index.html#einführung",
    "href": "slides/IntroR/index.html#einführung",
    "title": "Einführung in R",
    "section": "Einführung",
    "text": "Einführung\nHier gleich Daten aufbereiten, die wir später auch nutzen können!"
  },
  {
    "objectID": "exercises/3-GLM.html",
    "href": "exercises/3-GLM.html",
    "title": "3) Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Ziel dieser übung ist es, Daten für ein einfachs Raschmodell zu simulieren. Warum? Weil wir so die Datengenerierenden Prozesse besser verstehen können. Also, let’s get started.\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse"
  },
  {
    "objectID": "exercises/3-GLM.html#simulation",
    "href": "exercises/3-GLM.html#simulation",
    "title": "3) Das Raschmodell als eine Spezialfall des Allgemeinen Linearen Gemischten Modells",
    "section": "",
    "text": "Ziel dieser übung ist es, Daten für ein einfachs Raschmodell zu simulieren. Warum? Weil wir so die Datengenerierenden Prozesse besser verstehen können. Also, let’s get started.\n\n\n\n\n\n\n\n\nHint\n\n\n\n\n\nUse"
  }
]