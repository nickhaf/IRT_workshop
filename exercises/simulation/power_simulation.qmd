---
title: "Stichprobenplanung durch Simulation: Vorbereitung"
subtitle: "Übung"
format: html
bibliography: references.bib
about:
  id: sim-heading
  template: marquee
  image: images/surf.jpg
---

:::{#sim-heading}

In dieser Übung wollen wir das Gründgerüst für die Simulation legen, indem wir erst einmal ohne Wiederholung ein Datensatz simulieren. Vieles wird dir vermutlich schon aus der Simulationsübung zu [Höher Parametrisierten Modellen] bekannt vorkommen. 

:::

::: aside
Foto von <a href="https://unsplash.com/de/@markusspiske?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Markus Spiske</a> auf <a href="https://unsplash.com/de/fotos/ein-mann-reitet-auf-einer-welle-auf-einem-surfbrett-Xr0vgXXZ91A?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash">Unsplash</a>
:::

:::{.callout-note}
## Benötigte Pakete
```{r}
#| message: false
library(TAM)
library(tidyverse)
library(catIrt)
```

:::

```{r}
#| echo: false
n_items <- 20
source(here::here("R", "plot_functions.R"))
```

# Das Grundgerüst
Als erstes wollen wir Schritt für Schritt das Grundgerüst für unsere Simulation aufbauen, das wir dann je nach Fragestellung erweitern können. 

## Die Items
Als erstes definieren wir unsere wahren Itemparameter, aus denen dann die Daten simuliert werden.   
Erstelle dafür einen `data.frame`, der pro Item eine Zeile mit den entsprechenden Itemparamtern $\alpha$, $\beta$ und $\gamma$ enthält. 

- Wir wollen `r n_items` Items simulieren.
- $\alpha$ ist der Diskriminationsparameter und soll aus einer Normalverteilung $N(1, 0.1)$ simuliert werden. So ist er noch klein genug, um ein sinnvolles 1PL-Modell ausprobieren zu können. 
- $\beta$ ist der Schwierigkeitsparameter und soll den gesamten erwartete Schwierigkeitsbereich abdecken. Die Range soll von -2 bis 2 gehen, und Itemschwierigkeiten in gleichmäßigen Abständen enthalten. 
- $\gamma$ ist der Rate-Parameter, und wird für alle Items auf 0 gesetzt. 

1PL und 2PL Modelle sollten hier also beide gut funktionieren. 

:::{.callout-tip collapse="true"}
## Tipp
Aus einer Normalverteilung können wir mit `rnorm()` samplen.   
Die Schwierigkeitsparamter lassen sich mit `seq()` erzeugen.  
Schaue dir gegebenenfalls die Hilfen an. 
:::

:::{.callout-caution collapse="true"}
## Lösung
```{r}
set.seed(42) ## Setze den gleichen Seed, um exakt die selben Ergebnisse zu bekommen

n_items <- 20 ## So kann ich die Itemzahl im Nachhinein leicht anpassen
n_sub <- 500

item_pars <- data.frame(
  item_id = 1:n_items,
  alpha = rnorm(n_items, 1, 0.1),
  beta = seq(-2, 2, length.out = n_items),
  gamma = rep(0, n_items)
)
```

:::

## Die Antworten

Perfekt, jetzt können wir die Antworten simulieren. Nutze dafür diesmal die Funktion `simIRT()` aus `catIrt`. Andere Pakete wie `mirt` haben aber äquivalente Funktionen, und wir haben ja sogar schon [gelernt](), wie man das ganz manuell machen kann. 

Wir müssen neben den Parametern auch die $\theta$-Werte angeben. Diese sollen aus einer Normalverteilung $N(0,1)$ stammen. Hier haben wir natürlich Spielraum: Wenn wir erwarten, dass die Stichprobe, die wir untersuchen wollen, besonders leistungsstark ist, könnten wir auch eine Normalverteilung mit höherem Mittelwert wählen. 

Wir simulieren in diesem ersten Schritt $\theta$-Werte für `n_sub` Personen. Später variieren wir das natürlich, um mehrere Möglichkeiten auszuprobieren. 

:::{.callout-tip collapse="true"}

## Tipp
Die Parameter müssen als [`Matrix`](https://nickhaf.github.io/IRT_workshop/slides/IntroR/introR.html#/datenstrukturen) dem Funktionsargument `params` an `simIrt()` übergeben werden. 

:::

:::{.callout-caution collapse="true"}

## Lösung
```{r}
n_subj <- 500

sim_2PL_dat <- simIrt(
  theta = rnorm(n_subj, 0, 1),
  params = as.matrix(item_pars[, c("alpha", "beta", "gamma")]),
  mod = "brm"
)
```

:::

## Das Modell
Jetzt können wir das Modell schätzen. Wir geben uns jetzt erst einmal mit einem 1PL-Modell zufrieden. Fitte also ein 1PL-Modell auf die simulierten Daten (z.B. mit `TAM`). 

:::{.callout-tip collapse="true"}
## Tipp
Um an die simulierten Antworten zu kommen, können wir uns einmal die Struktur von dem simulierten Objekt anschauen:

```{r}
str(sim_2PL_dat)
```

Die responses können wir also mit `sim_2PL_dat$resp` extrahieren.

:::


:::{.callout-caution collapse="true"}

## Lösung
```{r}
tam_1PL <- tam(sim_2PL_dat$resp, verbose = FALSE)
```

:::

## Der Vergleich
Jetzt können wir unsere tatsächlichen Schwierigkeitsparameter mit den duch `TAM` geschätzten Schwierigkeitsparamtern vergleichen. Mach das einmal indem du die Differenz bildest. Fällt dir etwas auf?

:::{.callout-note}
Obwohl wir eigentlich ein 2PL Modell simuliert haben (wir haben ja Diskriminationsparamter verschieden von 1 gezogen), haben wir nur ein 1PL Modell gefittet. Das dient einfach dazu zu zeigen, dass die Modellschätzung in Fällen, in denen die Diskriminationsparamter nicht zu verschieden von 1 sind, hinreichend gut funktionieren kann. In echten Daten werden die Diskriminationsparamter ja auch nie 1 sein, deshalb können wir so mal schauen, wie sich unser Modell unter dieser Annahme von geringen Abweichungen von 1 verhält. 
:::

:::{.callout-tip collapse="true"}
## Tipp

Der Output von `TAM` ist ziemlich groß. Beim Anschauen der Struktur sehen wir nach einigem Suchen, dass die Paramter sich wahrscheinlich in `tam_1PL$item_irt` verstecken:

```{r}
str(tam_1PL)
```

:::


:::{.callout-caution collapse="true"}
## Lösung

```{r}
result <- data.frame(
  "b_true" = item_pars$beta,
  "b_est" = tam_1PL$item_irt[, "beta"]
) %>%
  mutate(b_diff = b_est - b_true)

## Plotten der Differenz zwischen geschätzten und echten Parametern gegen die echten Parameter
ggplot(data = result, aes(x = b_true, y = abs(b_diff))) +
  geom_point(color = "#F4BA02") +
  theme_bg() 
```

Wir können vor allem anhand des Plots gut erkennen, dass die Differenz zwischen den wahren und den geschätzten Werten an den Rändern zunimmt. Besonders schwere oder besonders leichte Items werden also schlechter geschätzt. Das ist ganz normal, da dies Items relativ wenig Informationen enthalten: Entweder benantworten (fast) alle sie richtig oder (fast) alle sie falsch. Es gibt hier also wenig Variation, die für die Schätzung genutzt werden kann. 

:::

Im nächsten Schritt packen wir das alles in einen loop. 
