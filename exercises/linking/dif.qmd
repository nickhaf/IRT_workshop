---
title: "Differential Item Functioning"
subtitle: "Übung"
author: "Nicklas Hafiz"
format: html
---

# 1. Vorbereitung

## 1.1 Daten laden

Lade die Datei `q_a_wirt.rds` von [GitHub](https://github.com/nickhaf/IRT_workshop/tree/main/raw_data) herunter (am besten in einen eigenen Daten-Ordner in deinem Projektordner) und in dein R-Skript ein.

:::{.callout-note}
Die Daten stammen aus dem [SPIEGEL-Studentenpisa-Test](https://search.gesis.org/research_data/ZA6268?doi=10.4232/1.13780) von 2009 und beinhaltet Fragen zu Allgemeinwissen in den Themengebieten Politik, Geschichte, Wirtschaft, Kultur und Naturwissenschaften. Insgesamt haben fast 700.000 Personen den Test bearbeitet. Wir haben die Daten bereits etwas aufbereitet und nur ein Subset an Fragen (Thema Wirtschaft) für diese Übung ausgewählt. 
:::

:::{.callout-caution collapse="true"}
## Lösung

```{r}
qa_dat <- readRDS(here::here("raw_data", "q_a_wirt.rds"))
```


:::

## 1.2 Überblick
Verschaffe dir einen [Überblick]() über die Daten. In welchem Formt liegen sie vor? Was könnten die verschiedenen Spalten bedeuten? 

:::{.callout-caution collapse="true"}

## Lösung

Durch Inspektion der Struktur können wir schnell feststellen, dass die Daten im [long-Format](https://nickhaf.github.io/IRT_workshop/slides/IntroR/introR.html#/long-format) vorliegen (jede Person hat pro Itemantwort eine eigene Zeile). Wir müssen sie also gleich ins [wide-Format umformen](https://nickhaf.github.io/IRT_workshop/slides/IntroR/introR.html#/von-long-zu-wide). 

```{r}
str(qa_dat)
```

Außerdem scheint der Datensatz folgende Variablen zu beinhalten:

- `T1`: Personen-ID (aber komisch benannt)
- `gender`: Geschlecht
- `answer`: Antwort auf die Frage
- `question_code`: Fragen-ID
- `varLabel`: Frage (aber komisch benannt)

:::

## 1.3 Spalten umbenennen 
Hmm, die Spaltennamen sind teilweise noch nicht ganz eindeutig. Benenne `T1` in `ID` und `varLabel` in `question` um. Klare Benennung hilft uns (und anderen) den Überblick zu behalten. 

:::{.callout-tip collapse="true"}

## Tipp
Ich nutze jetzt einfach mal `tidyverse` Funktionen dafür, aber es gibt immer mehrere Wege zum Ziel. Im `tidyverse` gibt es beispielsweise die Funktion `rename()`. 

:::

:::{.callout-caution collapse="true"}

## Lösung

```{r}
library(tidyverse)
qa_dat_renamed <- qa_dat %>%
  rename(ID = T1, question = varLabel)
```

:::

## 1.4 Umformen
Forme jetzt die Daten ins [wide-Format um](https://nickhaf.github.io/IRT_workshop/slides/IntroR/introR.html#/von-long-zu-wide).

:::{.callout-caution collapse="true"}
## Tipp
Das Ganze ist einfacher, wenn du vorher die Spalte `question` entfernst. Außerdem müssen `ID` und `gender` in `pivot_wider` als `id_cols` definiert werden: `..., id_cols = c(ID, gender), ...`.

:::

:::{.callout-caution collapse="true"}
## Lösung
```{r}
qa_dat_wide <- qa_dat_renamed %>%
  pivot_wider(
    id_cols = c(ID, gender),
    names_from = question_code,
    values_from = answer
  )
```

Jetzt können wir mal testweise schauen ob das geklappt hat:

```{r}
head(qa_dat_wide)
```


Yaay, sieht gut aus. 
:::

## Mantel-Haenszel DIF statistic
```{r}
#| eval: false
library(difR)
mantelHaenszel(qa_dat_wide[, 2:ncol(qa_dat_wide)], member = qa_dat_wide %>% mutate(gender = case_match(qa_dat_wide$gender, 2 ~ 1, 1 ~ 0)) %>% pull(gender))
```


## TAM
```{r}
library(TAM)
FIMSdata <- read.csv("C:/Users/hafiznij/Downloads/FIMS_AUS_TestA.csv")
raw_resp <- FIMSdata[, 2:15]
key <- c(1, 3, 1, 4, 1, 3, 3, 1, 5, 1, 1, 4, 1, 1)
scored <- sapply(seq(1, length(key)), FUN = function(ii) {
  1 * (raw_resp[, ii] == key[ii])
})

#         Line 14 runs an IRT analysis with MML estimation.
mod1 <- tam(scored)

# Results of the IRT analysis can be show using R command "summary(mod1)".

# Line 17 extracts values of the gender variable into a variable called "gender".
gender <- FIMSdata[, 1]

# Line 20 computes the test score for each student by calculating the row sum of each student's scored responses.
raw_score <- rowSums(scored)

formulaA <- ~ item + gender + item * gender
facets <- as.data.frame(gender)
mod2 <- tam.mml.mfr(resp = scored, facets = facets, formulaA = formulaA)

summary(mod2)

# 
#  A quick significance test can be conducted by dividing the interatcion estimate by its standard error. For example, for item 5, calculate -0.332/0.030= -11. Compare this with a z-statistic (within -2 and 2?)
# 
# The second way is to consider the effect size of DIF. For item 5, the difference in item difficulty between the two gender groups is 2x0.332 = 0.66. How siginificant in real terms is this magnitude? 
```


# 2. Waldtest
Wir werden zuerst einen [Waldtest]() durchführen. 
Es gibt diverse Pakete, mit denen dies möglich ist. Für diese Übung werden wir mit [equateIRT](https://cran.r-project.org/web/packages/equateIRT/vignettes/equateIRT_tutorial.html) arbeiten.  

:::{.callout-note}
## Alternativen
- [TAM](https://www.edmeasurementsurveys.com/TAM/Tutorials/7DIF.htm)  
- [eRm](https://bookdown.org/chua/new_rasch_demo2/DIF.html) 
- [mirt](https://philchalmers.github.io/mirt/html/DIF.html)
:::

## 2.1 Kalibrierung
Zuerst müssen wir die Daten kalibrieren (andere Pakete ermöglichen es auch, beides direkt in einer Funktion zu kombinieren).  
Dafür nutzen wir diesmal [mirt](https://cran.r-project.org/web/packages/mirt/index.html). Wir können unseren Datensatz in die Gruppen (uns interessiert übrigens geschlecht) aufteilen, die wir vergleichen wollen und dann auf jeden Subdatensatz unser IRT-Modell fitten (wie gesagt, andere Pakete ermöglichen das auch in einem Schritt).

### 2.1.1 Subgruppen herstellen
Erstelle 2 Dataframes, einen nur mit Frauen (1) und einen nur mit Männern (2). Weitere Kategorien gibt es in diesem Datensatz nicht:

```{r}
unique(qa_dat_wide$gender)
```

:::{.callout-caution collapse="true"}

## Lösung
```{r}
qa_dat_f <- qa_dat_wide %>%
  filter(gender == 1)
qa_dat_f <- qa_dat_f[1:500, ]


qa_dat_m <- qa_dat_wide %>%
  filter(gender == 2)
qa_dat_m <- qa_dat_m[1:500, ]
```
:::

### 2.1.2 Kalibrieren
Fitte jetzt mit `mirt` ein Raschmodell auf beide Subgruppen. Der Datensatz darf nur die Itemspalten enthalten. 

```{r}
library(mirt)

m_f <- qa_dat_f %>%
  select(-ID, -gender) %>%
  mirt(itemtype = "Rasch", SE = TRUE) ## Durch die Pipe wird der Datensatz automatisch übergeben. Wir müssen ihn also nicht nochmal in die mirt-Funktion schreiben

m_m <- qa_dat_m %>%
  select(-ID, -gender) %>%
  mirt(itemtype = "Rasch", SE = TRUE)

summary(m_m)
## SE = TRUE setzen?
```



### 2.1.3 Modellfit
Eigentlich sollten wir uns noch anschauen, wie das Modell fittet. Aus Zeitgründen verzichten wir jetzt erstmal darauf. 

## 2.2 Waldtest
Nutze jetzt die Funktion `dif.test()` aus dem Paket `equateIRT` um den Waldtest durchzuführen. Nutze Haebara Linking. Welche Items zeigen laut Waldtest DIF?

```{r}
library(equateIRT)

dif_test <- dif.test(est.mods = list(m_f, m_m), method = "Haebara", purification = TRUE)
```

Mit purification wird iterativ gefittet. 

## Evaluation 
- Plot? (https://www.researchgate.net/publication/347337364_Manual_ability_in_hand_surgery_patients_Validation_of_the_ABILHAND_scale_in_four_diagnostic_groups/figures?lo=1)
- Stärke des DIFs beurteilen. Das finde ich hier nen bisschen doof, so eine richtige Effektstärke kommt hier nicht raus? 
- Praktische Tipps



Gerade für DIF Stärke ist vielleicht das TAM ding doch besser? 
Wenn ich ein Paper dazu habe, vielleicht auch i.o. so. Könnte man dann odds ratios berechnen? 



```{r}
#| eval: false

## Diese Plots sind super, die nehem ich jetzt einfach!

### eRm Waldtest
# Auch in [TAM möglich](https://www.edmeasurementsurveys.com/TAM/Tutorials/7DIF.htm).


## Annehmen, dass eine Thematische Dimension unidimensional ist!
## Evtl. nur die Berliner Studierenden nehmen, damit die Stichprobengröße realistischer wird.

## Wir haben also unterschiedliche domänen, müssen die gesondert analysiert werden?
## Ja, wahrscheinlihc schon?

## Außerdem: Nur eine Subgruppe nehmen, und da dann alle?



## 2 ganz interessant, weil kein DIF so wirklich. Item 3 ist hiuer noch mit am auffälligsten, und war auch im Paper von
## STrobl auffällig (aber in Interaktion mit age, und sie hatten nur studierende aus bayern genommen).
## 5 zeigt ein bisschen was Richtung Bestimmung von Vögeln, wie z.B. im anderen Paper.
## 3 hat glaube ich die Frage mit dem Autochef, ansonsten grünes Biosiegel.
## 4 hat wieder nichts

qa_answers_na <- qa_dat_wide %>%
  drop_na(gender)

library(eRm)

m1 <- RM(select(qa_answers_na, -gender))
m1_na <- RM(select(qa_answers_na, -gender, -ID))

summary(m1_na)


## Andersen's LR test
gender_difs <- LRtest(m1_na, splitcr = qa_answers_na$gender)
plotDIF(gender_difs)

gender_diffs <- Waldtest(m1_na, splitcr = qa_answers_na$gender)

## Sooooo, wurde denn vorher gelinkt? Hat das Programm das under the hood direkt gemacht?
## Oder wie genau funktioniert das? Weil ich da ja so ein großes aufheben drum mache.
## Jaa, steht irgendwo, die Funktion übernimmt das. 


## Very Big, make a lesson about sample sizes and p values out of it.

gender_1_diffs <- gender_diffs$betapar1
gender_2_diffs <- gender_diffs$betapar2

comparisons <- as.data.frame(gender_diffs$coef.table)


m1_f <- RM(select(qa_dat_f, -gender, -ID))
m1_m <- RM(select(qa_dat_m, -gender, -ID))

## Okay, irgendwie würde ich erwarten, dass die Itemparameter sich in etwa so unterscheiden, wie in dem Plot weiter unten. Dem ist aber überhaupt nicht so.  

graphics.off()
min.y <- ifelse(ceiling(min(comparisons$`z-statistic`)) > -3, -3,
  ceiling(min(comparisons$`z-statistic`))
)

max.y <- ifelse(ceiling(max(comparisons$`z-statistic`)) < 3, 3,
  ceiling(max(comparisons$`z-statistic`))
)

plot(comparisons$`z-statistic`,
  ylim = c(min.y, max.y),
  ylab = "Z", xlab = "Item", main = "Test Statistics for Item Comparisons \nbetween gender 1 and gender 2"
)
abline(h = 2, col = "red", lty = 2)
abline(h = -2, col = "red", lty = 2)

legend("topright", c("Z Statistic", "Boundaries for Significant Difference"),
  pch = c(1, NA), lty = c(NA, 2), col = c("black", "red"), cex = .7
)



### DIF Scatterplots:

## First, calculate values for constructing the confidence bands:

mean.1.2 <- ((gender_1_diffs - mean(gender_1_diffs)) / 2 * sd(gender_1_diffs) +
  (gender_2_diffs - mean(gender_2_diffs)) / 2 * sd(gender_2_diffs))

joint.se <- sqrt((gender_diffs$se.beta1^2 / sd(gender_1_diffs)) +
  (gender_diffs$se.beta2^2 / sd(gender_2_diffs)))


upper.group.1 <- mean(gender_1_diffs) + ((mean.1.2 - joint.se) * sd(gender_1_diffs))
upper.group.2 <- mean(gender_2_diffs) + ((mean.1.2 + joint.se) * sd(gender_2_diffs))

lower.group.1 <- mean(gender_1_diffs) + ((mean.1.2 + joint.se) * sd(gender_1_diffs))
lower.group.2 <- mean(gender_2_diffs) + ((mean.1.2 - joint.se) * sd(gender_2_diffs))


upper <- cbind.data.frame(upper.group.1, upper.group.2)
upper <- upper[order(upper$upper.group.1, decreasing = FALSE), ]


lower <- cbind.data.frame(lower.group.1, lower.group.2)
lower <- lower[order(lower$lower.group.1, decreasing = FALSE), ]

## make the scatterplot:

plot(gender_1_diffs, gender_2_diffs,
  xlim = c(-2, 2), ylim = c(-2, 2),
  xlab = "Group 1", ylab = "Group 2", main = "Group 1 Measures \n plotted against \n Group 2 Measures"
)
abline(a = 0, b = 1, col = "purple")

par(new = T)

lines(upper$upper.group.1, upper$upper.group.2, lty = 2, col = "red")

lines(lower$lower.group.1, lower$lower.group.2, lty = 2, col = "red")

legend("bottomright", c("Item Location", "Identity Line", "95% Confidence Band"),
  pch = c(1, NA, NA), lty = c(NA, 1, 2), col = c("black", "purple", "red")
)



### Bar plot of item differences:

# First, calculate difference in difficulty between subgroups
# Note that I multiplied by -1 to reflect item difficulty rather than easiness (eRm quirk):
item_dif <- (gender_1_diffs * -1) - (gender_2_diffs * -1)


# Code to use different colors to highlight items with differences >= .5 logits:
colors <- NULL

for (item.number in 1:30) {
  colors[item.number] <- ifelse(abs(item_dif[item.number]) > .5, "dark blue", "light green")
}

# Bar plot code:
item_dif <- as.vector(item_dif)

x <- barplot(item_dif,
  horiz = TRUE, xlim = c(-2, 2),
  col = colors,
  ylim = c(1, 40),
  xlab = "Logit Difference"
)

# code to add labels to the plot:

dif_labs <- NULL

for (i in 1:length(subgroup_1_diffs)) {
  dif_labs[i] <- ifelse(item_dif[i] < 0, item_dif[i] - .2,
    item_dif[i] + .2
  )
}

text(dif_labs, x,
  labels = c(1:length(subgroup_1_diffs)),
  xlim = c(-1.5, 1.5), cex = .8
)

# add vertical lines to highlight .5 logit differences:
abline(v = .5, lty = 3)
abline(v = -.5, lty = 3)

# add additional text to help with interpretation:

text(-1, 40, "Easier to Endorse for Group 1", cex = .8)
text(1, 40, "Easier to Endorse for Group 2", cex = .8)

legend("bottomright", c("Diff >= .5 logits", "Diff < .5 logits"),
  pch = 15, col = c("dark blue", "light green"), cex = .7
)




## Wir könnten jetzt das stärkste DIF Item entfernen und die Analyse nochmal durchführen. Ist das wirklich So?! Oder splitted das paket schon nach Items? Lassen wir aber, let's take a quick look at rasch trees!
```
