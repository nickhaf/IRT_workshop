---
title: "3. Differential Item Functioning"
subtitle: "Übung"
author: "Nicklas Hafiz"
format: html
---

```{r}
source(here::here("R", "plot_functions.R"))
```

```{r}
qa_dat_wide <- readRDS(here::here("raw_data", "qa_dat_wide.rds"))
```


```{r}
#| echo: false
#| message: false

library(tidyverse)
library(TAM)

qa_f <- qa_dat_wide %>%
  filter(gender == 1)
qa_m <- qa_dat_wide %>%
  filter(gender == 2)

tam_f <- tam(qa_f[, 6:ncol(qa_f)], verbose = FALSE)
tam_m <- tam(qa_m[, 6:ncol(qa_m)], verbose = FALSE)

tam_link <- tam.linking(list(tam_m, tam_f), type = "SL")

difficulty_link_f <- tam_link$parameters_list[[1]]$xsi
difficulty_link_m <- tam_link$parameters_list[[2]]$xsi
```


# Waldtest
Wir werden einen [Waldtest]() durchführen, einfach weil man hier das Grundlegende Vorgehen ganz gut sehen kann. Wie im [Theorieteil]() besprochen gibt es aber viele verschiedene Optionen, implementiert in diversen Paketen. Für diese Übung werden wir mit [mirt](https://cran.r-project.org/web/packages/mirt/index.html) und [equateIRT](https://cran.r-project.org/web/packages/equateIRT/vignettes/equateIRT_tutorial.html) arbeiten.  

:::{.callout-note}
## Alternativen für DIF Analysen
- [TAM](https://www.edmeasurementsurveys.com/TAM/Tutorials/7DIF.htm)  
- [eRm](https://bookdown.org/chua/new_rasch_demo2/DIF.html) 
- [mirt](https://philchalmers.github.io/mirt/html/DIF.html)

Und viele mehr. 
:::

## Kalibrierung
Zuerst müssen wir die Daten noch einmal kalibrieren (andere Pakete ermöglichen es auch, beides direkt in einer Funktion zu kombinieren).  
Dafür nutzen wir diesmal aber [mirt](https://cran.r-project.org/web/packages/mirt/index.html), weil `equateIRT` den Output daraus verarbeiten kann. 

Fitte jetzt mit `mirt` ein Raschmodell auf beide Subgruppen seperat (männlich und weiblich). Der Datensatz darf nur die Itemspalten enthalten. Setze `SE = TRUE` um die Modell-Informationsmatrix zu berechnen, das ist gleich für den Waldtest nötig. 

```{r}
library(mirt)
library(tidyverse)

m_f <- qa_f %>%
  select(-ID, -gender, -bundeslandStudium, -spiegelReadingfreq, -age) %>%
  mirt(itemtype = "Rasch", SE = TRUE)


m_m <- qa_m %>%
  select(-ID, -gender, -bundeslandStudium, -spiegelReadingfreq, -age) %>%
  mirt(itemtype = "Rasch", SE = TRUE)
```



## Waldtest
Nutze jetzt die Funktion `dif.test()` aus dem Paket `equateIRT` um den Waldtest durchzuführen. Nutze, wie in der vorherigen Übung, die Stocking-Lord Methode zum linken. Welche Items zeigen laut Waldtest DIF?


:::{.callout-caution collapse="true"}
```{r}
library(equateIRT)

dif_test <- dif.test(est.mods = list(m_f, m_m), method = "Stocking-Lord", purification = FALSE)

dif_test
```

:::{.callout-note}
Mit `purification = TRUE` würde ein iteratives Vorgehen verwendet werden, bei dem nacheinander DIF Items entfernt werden, um die Personenfähigkeit ohne die komprimierenden Items zu schätzen. Weil wir aber gleich die Ergebnisse mit unserem Manuellen Vorgehen vergleichen wollen, verzichten wir darauf. 
:::

Zuerst einmal zeigen laut Waldtest viele der Items bei einem Signifikanzniveau von 0.05 DIF. Das ist aber auch nicht weiter verwunderlich, da der Test sicherlich nicht in Hinblick auf die Vermeidung von DIF konstruiert wurde.
:::

## Vergleich mit manuellem Linking
Da in `dif.test()` jetzt genauso gelinkt wurde, können wir jetzt einmal die Ergebnisse aus diesem Vorgehen mit dem aus dem manuellen Linking vergleichen. 

So sehen die Itemparameter aus, die von `dif.test()` berechnete wurden: 
```{r}
dif_test$coef_trasf
```

Und das hier waren die Parameter, die wir mit TAM gelinkt haben:  


```{r}
difficulty_link_f
difficulty_link_m
```

Was fällt auf?

:::{.callout-caution collapse = "true"}
## Lösung

Zuerst einmal scheinen die Vorzeichen der Itemschwierigkeiten vertauscht zu sein. Wir habne in `dif.test()` also die Itemleichtigkeiten geschätzt. Das ist aber leicht durch eine Multiplikation mit `-1` zu beheben.  
Ansonsten scheinen `mirt` und `tam` die gleichen Ergebnisse bei der Kalibrierung bekommen zu haben. Das Linking ist auch ähnlich, allerdings nicht exakt, obwohl wir die gleiche Mehtode verwendet haben. Wir könnten jetzt noch auf die Suche gehen, was genau beide Funktionen per Default anders machen, aber für uns soll das erst einmal reichen. 

::: 

## Beurteilung
Wir haben jetzt also gesehen, was die `dif.test()` Funktion unter der Haub macht und Signifikanzwerte erhalten, die uns potenziellen DIF anzeigen. 

:::{.callout-importang}
Natürlich treffen auch hier die üblichen Caveats zu Signifikanztests zu. Bei größer werdender Stichprobe werden so gut wie alle Gruppenunterschiede signifikant. Wir sollten daher auf keinen Fall nur auf die Signifikanz schauen, sondern auch die Effektstärke (z.B. Unterschied in Itemschwierigkeit ziwschen den Gruppen) und unbedingt auch inhaltliche Kriterien in die Beurteilung mit einfließen lassen. Wichtig ist einfach, alles zu kommunizieren, damit nachvollziebar bleibt, was warum getan wurde. 
:::

Es gibt also einige Items, die für eine weiter DIF-Analyse in Frage kommen.
Wir schauen uns jetzt mal die Unterschiede grafisch an, um auch ein Gefühl für das Ausmaß des DIF zu bekommen. 


```{r}
#| code-fold: true

## Für die Fragen benötigt
qa_dat <- readRDS(here::here("raw_data", "q_a_wirt_b.rds"))

group_difference <- as.vector(dif_test$coef_trasf[[1]] * -1) - as.vector(dif_test$coef_trasf[[2]] * -1)

questions <- qa_dat %>%
  select(question_code, varLabel) %>%
  unique() %>%
  mutate(varLabel = stringr::str_wrap(varLabel, 20))

## Prepare Data for
dif_dat <- data.frame(
  item = colnames(qa_f[, 6:ncol(qa_f)]),
  group_difference = group_difference,
  group_favour = ifelse(group_difference > 0, "m", "f"),
  p_value = dif_test$test[, "p.value"]
) %>%
  mutate(label_x = abs(group_difference) + 0.25) %>%
  mutate(significance = ifelse(p_value < 0.05, "Significant", "Not Significant")) %>%
  left_join(questions, join_by("item" == "question_code"))


ggplot(data = dif_dat, aes(x = abs(group_difference), y = item)) +
  # Add vertical line at x = 0
  geom_vline(xintercept = 0, linetype = "dashed", color = "darkgray") +

  # Add lines from 0 to the points
  geom_segment(aes(x = 0, xend = abs(group_difference), y = item, yend = item),
    linewidth = 0.75, colour = "grey"
  ) +

  # Add the points
  geom_point(aes(colour = group_favour, shape = significance), size = 3) +
  geom_label(aes(x = label_x, label = varLabel), size = 2) +
  # Optional: Customize the theme
  theme_bg() +
  scale_colour_manual(values = c("#01364C", "#9B1B34", "#F4BA02")) +
  xlim(0, 1.75) +
  labs(x = "Gruppenunterschied in Itemschwierigkeit", y = "Item")
```

Von Interesse ist vielleicht noch bei Item `3401` von wem dort die Rede ist. Es geht um Dieter Zetsche, den ehemaligen Vorstandsvorsitzenden der Daimler AG (Mercedes-Benz-Group). 

![](./images/zetsche.jpg)[^1]
  
[^1] Bild von Matti Blume, heruntergeladen von [Wikipedia](https://commons.wikimedia.org/wiki/File:Daimler_press_conference,_GIMS_2018,_Le_Grand-Saconnex_(1X7A0769)_(cropped).jpg). 

Wie würdest du den DIF beurteilen?
